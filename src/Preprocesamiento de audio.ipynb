{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.3.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting TBB\n",
      "  Using cached tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.15.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached torch-2.3.1-cp311-cp311-win_amd64.whl (159.8 MB)\n",
      "Using cached tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading filelock-3.15.1-py3-none-any.whl (15 kB)\n",
      "Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "   ---------------------------------------- 0.0/176.9 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 41.0/176.9 kB 991.0 kB/s eta 0:00:01\n",
      "   -------------------- ------------------- 92.2/176.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 176.9/176.9 kB 1.3 MB/s eta 0:00:00\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.7 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.4/1.7 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.8/1.7 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.1/1.7 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.4/1.7 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "   ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/5.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/5.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.4/5.7 MB 3.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.4/5.7 MB 3.0 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.4/5.7 MB 3.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.6/5.7 MB 2.4 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.6/5.7 MB 2.1 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.7/5.7 MB 1.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.8/5.7 MB 2.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.9/5.7 MB 2.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.9/5.7 MB 2.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.9/5.7 MB 2.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.9/5.7 MB 2.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.9/5.7 MB 2.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.9/5.7 MB 2.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.0/5.7 MB 1.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.0/5.7 MB 1.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.1/5.7 MB 1.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.2/5.7 MB 1.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.2/5.7 MB 1.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.2/5.7 MB 1.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.2/5.7 MB 1.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.2/5.7 MB 1.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.2/5.7 MB 1.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.2/5.7 MB 1.4 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.4/5.7 MB 1.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.4/5.7 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 1.5/5.7 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.6/5.7 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 1.8/5.7 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 1.9/5.7 MB 1.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.1/5.7 MB 1.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.2/5.7 MB 1.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.3/5.7 MB 1.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.5/5.7 MB 1.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.6/5.7 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 2.7/5.7 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.9/5.7 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.1/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.2/5.7 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.4/5.7 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.6/5.7 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.7/5.7 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.9/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.1/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.3/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.5/5.7 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.7/5.7 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.8/5.7 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.0/5.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.2/5.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.4/5.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.7/5.7 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.7/5.7 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl (17 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 174.1/536.2 kB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 337.9/536.2 kB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 536.2/536.2 kB 4.2 MB/s eta 0:00:00\n",
      "Installing collected packages: TBB, mpmath, intel-openmp, typing-extensions, sympy, networkx, mkl, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-2.1.1 TBB-0.2 filelock-3.15.1 fsspec-2023.4.0 intel-openmp-2021.4.0 jinja2-3.1.2 mkl-2021.4.0 mpmath-1.3.0 networkx-3.1 sympy-1.11.1 torch-2.3.1 typing-extensions-4.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2024.6.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install torch --ignore-installed TBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lyes_\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Wav2Vec2ForSequenceClassification\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import noisereduce as nr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf45581d9e740638c43e876e81ec61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/158 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601fb4d1952b424f86bea538583852bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3bf53d9153438388572d1776603ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56422ff67e4c4cc19aafaced705aedbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6e3026b0bb453e852195d321e2308d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0844c1d16f8c49e39da9dfc7c90bc118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-large-960h-lv60-self were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.masked_spec_embed', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelos y procesadores\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de preprocesamiento de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(file_path, target_sr=16000):\n",
    "    audio, sr = librosa.load(file_path, sr=target_sr, mono=True)\n",
    "    return audio, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio(audio):\n",
    "    max_amp = np.max(np.abs(audio))\n",
    "    normalized_audio = audio / max_amp\n",
    "    return normalized_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_audio(audio, sr):\n",
    "    reduced_noise = nr.reduce_noise(y=audio, sr=sr)\n",
    "    return reduced_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_audio(audio, sr, segment_length=5):\n",
    "    segments = []\n",
    "    total_duration = librosa.get_duration(audio, sr)\n",
    "    for start in range(0, int(total_duration), segment_length):\n",
    "        end = start + segment_length\n",
    "        segment = audio[start*sr:end*sr]\n",
    "        segments.append(segment)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función de transcripción de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in /Users/ehsc1997/.local/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ehsc1997/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ehsc1997/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a3ea4eb0764395b48508a22268b215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/158 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450e3f7d4dec45cd90b4cb958e702258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44742750a4724575aa4467b70fa99e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24547d2d158546f7a7edcd20c953b631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b58fa1672646d5bfd5d96cf5052f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd8f0d478fe4c968bbcfd4020b435d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-large-960h-lv60-self were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DOGS ARE SITTING BY THE DOOR'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from voice_to_text import transcribe_audio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
    "file_path = '../Data/Audios/Audio (1).wav'\n",
    "transcribe_audio(file_path, processor, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función de análisis de tono (placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_tone(transcription):\n",
    "    # Placeholder para el análisis de tono basado en la transcripción\n",
    "    if \"angry\" in transcription.lower():\n",
    "        return \"angry\"\n",
    "    elif \"happy\" in transcription.lower():\n",
    "        return \"happy\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función de análisis de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text, tone):\n",
    "    # Placeholder para el análisis de texto\n",
    "    analysis = f\"Análisis del texto con tono {tone}\"\n",
    "    return analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
