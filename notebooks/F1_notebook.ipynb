{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import keras\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib.pyplot import specgram\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, Activation, Dropout, Flatten, Dense, Input, BatchNormalization\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from librosa.util import lazy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "#Codigo para crear mas fuentes de audio ligeramente modificadas a partir de las originales:\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "# Ruta al directorio con los archivos de audio\n",
    "data_dir = 'RawData'\n",
    "augmented_dir = 'RawData_Aug'\n",
    "\n",
    "# Crear el directorio de datos aumentados si no existe\n",
    "os.makedirs(augmented_dir, exist_ok=True)\n",
    "\n",
    "# Función para cambiar el tono\n",
    "def pitch_shift(audio, sampling_rate, n_steps):\n",
    "    return librosa.effects.pitch_shift(audio, sr=sampling_rate, n_steps=n_steps)\n",
    "\n",
    "# Función para agregar ruido\n",
    "def add_noise(audio, noise_factor=0.001):\n",
    "    noise = np.random.randn(len(audio))\n",
    "    augmented_audio = audio + noise_factor * noise\n",
    "    augmented_audio = augmented_audio.astype(type(audio[0]))\n",
    "    return augmented_audio\n",
    "\n",
    "# Función para desplazar en el tiempo\n",
    "#def time_shift(audio, shift_max, shift_direction):\n",
    "#    shift = np.random.randint(shift_max)\n",
    "#    if shift_direction == 'right':\n",
    "#        shift = -shift\n",
    "#    augmented_audio = np.roll(audio, shift)\n",
    "    \n",
    "# Función para desplazar en el tiempo\n",
    "def time_shift(audio, shift, shift_direction):\n",
    "    if shift_direction == 'right':\n",
    "        shift = -shift\n",
    "    augmented_audio = np.roll(audio, shift)\n",
    "    return augmented_audio\n",
    "\n",
    "# Iterar sobre cada archivo de audio en el directorio\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.wav'):\n",
    "        # Cargar el archivo de audio\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "        # Aplicar cambios de tono a mas\n",
    "        augmented_audio = pitch_shift(audio, sr, n_steps=2)\n",
    "        output_path = os.path.join(augmented_dir, f'{os.path.splitext(filename)[0]}_pitch1.wav')\n",
    "        sf.write(output_path, augmented_audio, sr)\n",
    "\n",
    "        # Aplicar cambios de tono a menos\n",
    "        augmented_audio = pitch_shift(audio, sr, n_steps=-2)\n",
    "        output_path = os.path.join(augmented_dir, f'{os.path.splitext(filename)[0]}_pitch2.wav')\n",
    "        sf.write(output_path, augmented_audio, sr)\n",
    "\n",
    "        # Agregar ruido\n",
    "        augmented_audio = add_noise(audio)\n",
    "        output_path = os.path.join(augmented_dir, f'{os.path.splitext(filename)[0]}_noise.wav')\n",
    "        sf.write(output_path, augmented_audio, sr)\n",
    "\n",
    "        # Cambiar la velocidad a más\n",
    "        augmented_audio = librosa.effects.time_stretch(audio, rate=1.2)\n",
    "        output_path = os.path.join(augmented_dir, f'{os.path.splitext(filename)[0]}_stretch1.wav')\n",
    "        sf.write(output_path, augmented_audio, sr)\n",
    "\n",
    "        # Cambiar la velocidad a menos\n",
    "        augmented_audio = librosa.effects.time_stretch(audio, rate=0.8)\n",
    "        output_path = os.path.join(augmented_dir, f'{os.path.splitext(filename)[0]}_stretch2.wav')\n",
    "        sf.write(output_path, augmented_audio, sr)\n",
    "\n",
    "        # Desplazamiento temporal derecha\n",
    "        SH=int(0.1*len(audio))\n",
    "        augmented_audio = time_shift(audio, shift=SH, shift_direction='right')\n",
    "        output_path = os.path.join(augmented_dir, f'{os.path.splitext(filename)[0]}_shift_right.wav')\n",
    "        sf.write(output_path, augmented_audio, sr)\n",
    "        \n",
    "        # Desplazamiento temporal izquierda\n",
    "        augmented_audio = time_shift(audio, shift=SH, shift_direction='left')\n",
    "        output_path = os.path.join(augmented_dir, f'{os.path.splitext(filename)[0]}_shift_left.wav')\n",
    "        sf.write(output_path, augmented_audio, sr)\n",
    "\n",
    "print(\"Data augmentation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['03-01-01-01-01-01-01_noise.wav',\n",
       " '03-01-01-01-01-01-01_pitch1.wav',\n",
       " '03-01-01-01-01-01-01_pitch2.wav',\n",
       " '03-01-01-01-01-01-01_shift_left.wav',\n",
       " '03-01-01-01-01-01-01_shift_right.wav',\n",
       " '03-01-01-01-01-01-01_stretch1.wav',\n",
       " '03-01-01-01-01-01-01_stretch2.wav',\n",
       " '03-01-01-01-01-01-02_noise.wav',\n",
       " '03-01-01-01-01-01-02_pitch1.wav',\n",
       " '03-01-01-01-01-01-02_pitch2.wav',\n",
       " '03-01-01-01-01-01-02_shift_left.wav',\n",
       " '03-01-01-01-01-01-02_shift_right.wav',\n",
       " '03-01-01-01-01-01-02_stretch1.wav',\n",
       " '03-01-01-01-01-01-02_stretch2.wav',\n",
       " '03-01-01-01-01-01-03_noise.wav',\n",
       " '03-01-01-01-01-01-03_pitch1.wav',\n",
       " '03-01-01-01-01-01-03_pitch2.wav',\n",
       " '03-01-01-01-01-01-03_shift_left.wav',\n",
       " '03-01-01-01-01-01-03_shift_right.wav',\n",
       " '03-01-01-01-01-01-03_stretch1.wav',\n",
       " '03-01-01-01-01-01-03_stretch2.wav',\n",
       " '03-01-01-01-01-01-04_noise.wav',\n",
       " '03-01-01-01-01-01-04_pitch1.wav',\n",
       " '03-01-01-01-01-01-04_pitch2.wav',\n",
       " '03-01-01-01-01-01-04_shift_left.wav',\n",
       " '03-01-01-01-01-01-04_shift_right.wav',\n",
       " '03-01-01-01-01-01-04_stretch1.wav',\n",
       " '03-01-01-01-01-01-04_stretch2.wav',\n",
       " '03-01-01-01-01-01-05_noise.wav',\n",
       " '03-01-01-01-01-01-05_pitch1.wav',\n",
       " '03-01-01-01-01-01-05_pitch2.wav',\n",
       " '03-01-01-01-01-01-05_shift_left.wav',\n",
       " '03-01-01-01-01-01-05_shift_right.wav',\n",
       " '03-01-01-01-01-01-05_stretch1.wav',\n",
       " '03-01-01-01-01-01-05_stretch2.wav',\n",
       " '03-01-01-01-01-01-06_noise.wav',\n",
       " '03-01-01-01-01-01-06_pitch1.wav',\n",
       " '03-01-01-01-01-01-06_pitch2.wav',\n",
       " '03-01-01-01-01-01-06_shift_left.wav',\n",
       " '03-01-01-01-01-01-06_shift_right.wav',\n",
       " '03-01-01-01-01-01-06_stretch1.wav',\n",
       " '03-01-01-01-01-01-06_stretch2.wav',\n",
       " '03-01-01-01-01-01-07_noise.wav',\n",
       " '03-01-01-01-01-01-07_pitch1.wav',\n",
       " '03-01-01-01-01-01-07_pitch2.wav',\n",
       " '03-01-01-01-01-01-07_shift_left.wav',\n",
       " '03-01-01-01-01-01-07_shift_right.wav',\n",
       " '03-01-01-01-01-01-07_stretch1.wav',\n",
       " '03-01-01-01-01-01-07_stretch2.wav',\n",
       " '03-01-01-01-01-01-08_noise.wav',\n",
       " '03-01-01-01-01-01-08_pitch1.wav',\n",
       " '03-01-01-01-01-01-08_pitch2.wav',\n",
       " '03-01-01-01-01-01-08_shift_left.wav',\n",
       " '03-01-01-01-01-01-08_shift_right.wav',\n",
       " '03-01-01-01-01-01-08_stretch1.wav',\n",
       " '03-01-01-01-01-01-08_stretch2.wav',\n",
       " '03-01-01-01-01-01-09_noise.wav',\n",
       " '03-01-01-01-01-01-09_pitch1.wav',\n",
       " '03-01-01-01-01-01-09_pitch2.wav',\n",
       " '03-01-01-01-01-01-09_shift_left.wav',\n",
       " '03-01-01-01-01-01-09_shift_right.wav',\n",
       " '03-01-01-01-01-01-09_stretch1.wav',\n",
       " '03-01-01-01-01-01-09_stretch2.wav',\n",
       " '03-01-01-01-01-01-10_noise.wav',\n",
       " '03-01-01-01-01-01-10_pitch1.wav',\n",
       " '03-01-01-01-01-01-10_pitch2.wav',\n",
       " '03-01-01-01-01-01-10_shift_left.wav',\n",
       " '03-01-01-01-01-01-10_shift_right.wav',\n",
       " '03-01-01-01-01-01-10_stretch1.wav',\n",
       " '03-01-01-01-01-01-10_stretch2.wav',\n",
       " '03-01-01-01-01-01-11_noise.wav',\n",
       " '03-01-01-01-01-01-11_pitch1.wav',\n",
       " '03-01-01-01-01-01-11_pitch2.wav',\n",
       " '03-01-01-01-01-01-11_shift_left.wav',\n",
       " '03-01-01-01-01-01-11_shift_right.wav',\n",
       " '03-01-01-01-01-01-11_stretch1.wav',\n",
       " '03-01-01-01-01-01-11_stretch2.wav',\n",
       " '03-01-01-01-01-01-12_noise.wav',\n",
       " '03-01-01-01-01-01-12_pitch1.wav',\n",
       " '03-01-01-01-01-01-12_pitch2.wav',\n",
       " '03-01-01-01-01-01-12_shift_left.wav',\n",
       " '03-01-01-01-01-01-12_shift_right.wav',\n",
       " '03-01-01-01-01-01-12_stretch1.wav',\n",
       " '03-01-01-01-01-01-12_stretch2.wav',\n",
       " '03-01-01-01-01-01-13_noise.wav',\n",
       " '03-01-01-01-01-01-13_pitch1.wav',\n",
       " '03-01-01-01-01-01-13_pitch2.wav',\n",
       " '03-01-01-01-01-01-13_shift_left.wav',\n",
       " '03-01-01-01-01-01-13_shift_right.wav',\n",
       " '03-01-01-01-01-01-13_stretch1.wav',\n",
       " '03-01-01-01-01-01-13_stretch2.wav',\n",
       " '03-01-01-01-01-01-14_noise.wav',\n",
       " '03-01-01-01-01-01-14_pitch1.wav',\n",
       " '03-01-01-01-01-01-14_pitch2.wav',\n",
       " '03-01-01-01-01-01-14_shift_left.wav',\n",
       " '03-01-01-01-01-01-14_shift_right.wav',\n",
       " '03-01-01-01-01-01-14_stretch1.wav',\n",
       " '03-01-01-01-01-01-14_stretch2.wav',\n",
       " '03-01-01-01-01-01-15_noise.wav',\n",
       " '03-01-01-01-01-01-15_pitch1.wav',\n",
       " '03-01-01-01-01-01-15_pitch2.wav',\n",
       " '03-01-01-01-01-01-15_shift_left.wav',\n",
       " '03-01-01-01-01-01-15_shift_right.wav',\n",
       " '03-01-01-01-01-01-15_stretch1.wav',\n",
       " '03-01-01-01-01-01-15_stretch2.wav',\n",
       " '03-01-01-01-01-01-16_noise.wav',\n",
       " '03-01-01-01-01-01-16_pitch1.wav',\n",
       " '03-01-01-01-01-01-16_pitch2.wav',\n",
       " '03-01-01-01-01-01-16_shift_left.wav',\n",
       " '03-01-01-01-01-01-16_shift_right.wav',\n",
       " '03-01-01-01-01-01-16_stretch1.wav',\n",
       " '03-01-01-01-01-01-16_stretch2.wav',\n",
       " '03-01-01-01-01-01-17_noise.wav',\n",
       " '03-01-01-01-01-01-17_pitch1.wav',\n",
       " '03-01-01-01-01-01-17_pitch2.wav',\n",
       " '03-01-01-01-01-01-17_shift_left.wav',\n",
       " '03-01-01-01-01-01-17_shift_right.wav',\n",
       " '03-01-01-01-01-01-17_stretch1.wav',\n",
       " '03-01-01-01-01-01-17_stretch2.wav',\n",
       " '03-01-01-01-01-01-18_noise.wav',\n",
       " '03-01-01-01-01-01-18_pitch1.wav',\n",
       " '03-01-01-01-01-01-18_pitch2.wav',\n",
       " '03-01-01-01-01-01-18_shift_left.wav',\n",
       " '03-01-01-01-01-01-18_shift_right.wav',\n",
       " '03-01-01-01-01-01-18_stretch1.wav',\n",
       " '03-01-01-01-01-01-18_stretch2.wav',\n",
       " '03-01-01-01-01-01-19_noise.wav',\n",
       " '03-01-01-01-01-01-19_pitch1.wav',\n",
       " '03-01-01-01-01-01-19_pitch2.wav',\n",
       " '03-01-01-01-01-01-19_shift_left.wav',\n",
       " '03-01-01-01-01-01-19_shift_right.wav',\n",
       " '03-01-01-01-01-01-19_stretch1.wav',\n",
       " '03-01-01-01-01-01-19_stretch2.wav',\n",
       " '03-01-01-01-01-01-20_noise.wav',\n",
       " '03-01-01-01-01-01-20_pitch1.wav',\n",
       " '03-01-01-01-01-01-20_pitch2.wav',\n",
       " '03-01-01-01-01-01-20_shift_left.wav',\n",
       " '03-01-01-01-01-01-20_shift_right.wav',\n",
       " '03-01-01-01-01-01-20_stretch1.wav',\n",
       " '03-01-01-01-01-01-20_stretch2.wav',\n",
       " '03-01-01-01-01-01-21_noise.wav',\n",
       " '03-01-01-01-01-01-21_pitch1.wav',\n",
       " '03-01-01-01-01-01-21_pitch2.wav',\n",
       " '03-01-01-01-01-01-21_shift_left.wav',\n",
       " '03-01-01-01-01-01-21_shift_right.wav',\n",
       " '03-01-01-01-01-01-21_stretch1.wav',\n",
       " '03-01-01-01-01-01-21_stretch2.wav',\n",
       " '03-01-01-01-01-01-22_noise.wav',\n",
       " '03-01-01-01-01-01-22_pitch1.wav',\n",
       " '03-01-01-01-01-01-22_pitch2.wav',\n",
       " '03-01-01-01-01-01-22_shift_left.wav',\n",
       " '03-01-01-01-01-01-22_shift_right.wav',\n",
       " '03-01-01-01-01-01-22_stretch1.wav',\n",
       " '03-01-01-01-01-01-22_stretch2.wav',\n",
       " '03-01-01-01-01-01-23_noise.wav',\n",
       " '03-01-01-01-01-01-23_pitch1.wav',\n",
       " '03-01-01-01-01-01-23_pitch2.wav',\n",
       " '03-01-01-01-01-01-23_shift_left.wav',\n",
       " '03-01-01-01-01-01-23_shift_right.wav',\n",
       " '03-01-01-01-01-01-23_stretch1.wav',\n",
       " '03-01-01-01-01-01-23_stretch2.wav',\n",
       " '03-01-01-01-01-01-24_noise.wav',\n",
       " '03-01-01-01-01-01-24_pitch1.wav',\n",
       " '03-01-01-01-01-01-24_pitch2.wav',\n",
       " '03-01-01-01-01-01-24_shift_left.wav',\n",
       " '03-01-01-01-01-01-24_shift_right.wav',\n",
       " '03-01-01-01-01-01-24_stretch1.wav',\n",
       " '03-01-01-01-01-01-24_stretch2.wav',\n",
       " '03-01-01-01-01-02-01_noise.wav',\n",
       " '03-01-01-01-01-02-01_pitch1.wav',\n",
       " '03-01-01-01-01-02-01_pitch2.wav',\n",
       " '03-01-01-01-01-02-01_shift_left.wav',\n",
       " '03-01-01-01-01-02-01_shift_right.wav',\n",
       " '03-01-01-01-01-02-01_stretch1.wav',\n",
       " '03-01-01-01-01-02-01_stretch2.wav',\n",
       " '03-01-01-01-01-02-02_noise.wav',\n",
       " '03-01-01-01-01-02-02_pitch1.wav',\n",
       " '03-01-01-01-01-02-02_pitch2.wav',\n",
       " '03-01-01-01-01-02-02_shift_left.wav',\n",
       " '03-01-01-01-01-02-02_shift_right.wav',\n",
       " '03-01-01-01-01-02-02_stretch1.wav',\n",
       " '03-01-01-01-01-02-02_stretch2.wav',\n",
       " '03-01-01-01-01-02-03_noise.wav',\n",
       " '03-01-01-01-01-02-03_pitch1.wav',\n",
       " '03-01-01-01-01-02-03_pitch2.wav',\n",
       " '03-01-01-01-01-02-03_shift_left.wav',\n",
       " '03-01-01-01-01-02-03_shift_right.wav',\n",
       " '03-01-01-01-01-02-03_stretch1.wav',\n",
       " '03-01-01-01-01-02-03_stretch2.wav',\n",
       " '03-01-01-01-01-02-04_noise.wav',\n",
       " '03-01-01-01-01-02-04_pitch1.wav',\n",
       " '03-01-01-01-01-02-04_pitch2.wav',\n",
       " '03-01-01-01-01-02-04_shift_left.wav',\n",
       " '03-01-01-01-01-02-04_shift_right.wav',\n",
       " '03-01-01-01-01-02-04_stretch1.wav',\n",
       " '03-01-01-01-01-02-04_stretch2.wav',\n",
       " '03-01-01-01-01-02-05_noise.wav',\n",
       " '03-01-01-01-01-02-05_pitch1.wav',\n",
       " '03-01-01-01-01-02-05_pitch2.wav',\n",
       " '03-01-01-01-01-02-05_shift_left.wav',\n",
       " '03-01-01-01-01-02-05_shift_right.wav',\n",
       " '03-01-01-01-01-02-05_stretch1.wav',\n",
       " '03-01-01-01-01-02-05_stretch2.wav',\n",
       " '03-01-01-01-01-02-06_noise.wav',\n",
       " '03-01-01-01-01-02-06_pitch1.wav',\n",
       " '03-01-01-01-01-02-06_pitch2.wav',\n",
       " '03-01-01-01-01-02-06_shift_left.wav',\n",
       " '03-01-01-01-01-02-06_shift_right.wav',\n",
       " '03-01-01-01-01-02-06_stretch1.wav',\n",
       " '03-01-01-01-01-02-06_stretch2.wav',\n",
       " '03-01-01-01-01-02-07_noise.wav',\n",
       " '03-01-01-01-01-02-07_pitch1.wav',\n",
       " '03-01-01-01-01-02-07_pitch2.wav',\n",
       " '03-01-01-01-01-02-07_shift_left.wav',\n",
       " '03-01-01-01-01-02-07_shift_right.wav',\n",
       " '03-01-01-01-01-02-07_stretch1.wav',\n",
       " '03-01-01-01-01-02-07_stretch2.wav',\n",
       " '03-01-01-01-01-02-08_noise.wav',\n",
       " '03-01-01-01-01-02-08_pitch1.wav',\n",
       " '03-01-01-01-01-02-08_pitch2.wav',\n",
       " '03-01-01-01-01-02-08_shift_left.wav',\n",
       " '03-01-01-01-01-02-08_shift_right.wav',\n",
       " '03-01-01-01-01-02-08_stretch1.wav',\n",
       " '03-01-01-01-01-02-08_stretch2.wav',\n",
       " '03-01-01-01-01-02-09_noise.wav',\n",
       " '03-01-01-01-01-02-09_pitch1.wav',\n",
       " '03-01-01-01-01-02-09_pitch2.wav',\n",
       " '03-01-01-01-01-02-09_shift_left.wav',\n",
       " '03-01-01-01-01-02-09_shift_right.wav',\n",
       " '03-01-01-01-01-02-09_stretch1.wav',\n",
       " '03-01-01-01-01-02-09_stretch2.wav',\n",
       " '03-01-01-01-01-02-10_noise.wav',\n",
       " '03-01-01-01-01-02-10_pitch1.wav',\n",
       " '03-01-01-01-01-02-10_pitch2.wav',\n",
       " '03-01-01-01-01-02-10_shift_left.wav',\n",
       " '03-01-01-01-01-02-10_shift_right.wav',\n",
       " '03-01-01-01-01-02-10_stretch1.wav',\n",
       " '03-01-01-01-01-02-10_stretch2.wav',\n",
       " '03-01-01-01-01-02-11_noise.wav',\n",
       " '03-01-01-01-01-02-11_pitch1.wav',\n",
       " '03-01-01-01-01-02-11_pitch2.wav',\n",
       " '03-01-01-01-01-02-11_shift_left.wav',\n",
       " '03-01-01-01-01-02-11_shift_right.wav',\n",
       " '03-01-01-01-01-02-11_stretch1.wav',\n",
       " '03-01-01-01-01-02-11_stretch2.wav',\n",
       " '03-01-01-01-01-02-12_noise.wav',\n",
       " '03-01-01-01-01-02-12_pitch1.wav',\n",
       " '03-01-01-01-01-02-12_pitch2.wav',\n",
       " '03-01-01-01-01-02-12_shift_left.wav',\n",
       " '03-01-01-01-01-02-12_shift_right.wav',\n",
       " '03-01-01-01-01-02-12_stretch1.wav',\n",
       " '03-01-01-01-01-02-12_stretch2.wav',\n",
       " '03-01-01-01-01-02-13_noise.wav',\n",
       " '03-01-01-01-01-02-13_pitch1.wav',\n",
       " '03-01-01-01-01-02-13_pitch2.wav',\n",
       " '03-01-01-01-01-02-13_shift_left.wav',\n",
       " '03-01-01-01-01-02-13_shift_right.wav',\n",
       " '03-01-01-01-01-02-13_stretch1.wav',\n",
       " '03-01-01-01-01-02-13_stretch2.wav',\n",
       " '03-01-01-01-01-02-14_noise.wav',\n",
       " '03-01-01-01-01-02-14_pitch1.wav',\n",
       " '03-01-01-01-01-02-14_pitch2.wav',\n",
       " '03-01-01-01-01-02-14_shift_left.wav',\n",
       " '03-01-01-01-01-02-14_shift_right.wav',\n",
       " '03-01-01-01-01-02-14_stretch1.wav',\n",
       " '03-01-01-01-01-02-14_stretch2.wav',\n",
       " '03-01-01-01-01-02-15_noise.wav',\n",
       " '03-01-01-01-01-02-15_pitch1.wav',\n",
       " '03-01-01-01-01-02-15_pitch2.wav',\n",
       " '03-01-01-01-01-02-15_shift_left.wav',\n",
       " '03-01-01-01-01-02-15_shift_right.wav',\n",
       " '03-01-01-01-01-02-15_stretch1.wav',\n",
       " '03-01-01-01-01-02-15_stretch2.wav',\n",
       " '03-01-01-01-01-02-16_noise.wav',\n",
       " '03-01-01-01-01-02-16_pitch1.wav',\n",
       " '03-01-01-01-01-02-16_pitch2.wav',\n",
       " '03-01-01-01-01-02-16_shift_left.wav',\n",
       " '03-01-01-01-01-02-16_shift_right.wav',\n",
       " '03-01-01-01-01-02-16_stretch1.wav',\n",
       " '03-01-01-01-01-02-16_stretch2.wav',\n",
       " '03-01-01-01-01-02-17_noise.wav',\n",
       " '03-01-01-01-01-02-17_pitch1.wav',\n",
       " '03-01-01-01-01-02-17_pitch2.wav',\n",
       " '03-01-01-01-01-02-17_shift_left.wav',\n",
       " '03-01-01-01-01-02-17_shift_right.wav',\n",
       " '03-01-01-01-01-02-17_stretch1.wav',\n",
       " '03-01-01-01-01-02-17_stretch2.wav',\n",
       " '03-01-01-01-01-02-18_noise.wav',\n",
       " '03-01-01-01-01-02-18_pitch1.wav',\n",
       " '03-01-01-01-01-02-18_pitch2.wav',\n",
       " '03-01-01-01-01-02-18_shift_left.wav',\n",
       " '03-01-01-01-01-02-18_shift_right.wav',\n",
       " '03-01-01-01-01-02-18_stretch1.wav',\n",
       " '03-01-01-01-01-02-18_stretch2.wav',\n",
       " '03-01-01-01-01-02-19_noise.wav',\n",
       " '03-01-01-01-01-02-19_pitch1.wav',\n",
       " '03-01-01-01-01-02-19_pitch2.wav',\n",
       " '03-01-01-01-01-02-19_shift_left.wav',\n",
       " '03-01-01-01-01-02-19_shift_right.wav',\n",
       " '03-01-01-01-01-02-19_stretch1.wav',\n",
       " '03-01-01-01-01-02-19_stretch2.wav',\n",
       " '03-01-01-01-01-02-20_noise.wav',\n",
       " '03-01-01-01-01-02-20_pitch1.wav',\n",
       " '03-01-01-01-01-02-20_pitch2.wav',\n",
       " '03-01-01-01-01-02-20_shift_left.wav',\n",
       " '03-01-01-01-01-02-20_shift_right.wav',\n",
       " '03-01-01-01-01-02-20_stretch1.wav',\n",
       " '03-01-01-01-01-02-20_stretch2.wav',\n",
       " '03-01-01-01-01-02-21_noise.wav',\n",
       " '03-01-01-01-01-02-21_pitch1.wav',\n",
       " '03-01-01-01-01-02-21_pitch2.wav',\n",
       " '03-01-01-01-01-02-21_shift_left.wav',\n",
       " '03-01-01-01-01-02-21_shift_right.wav',\n",
       " '03-01-01-01-01-02-21_stretch1.wav',\n",
       " '03-01-01-01-01-02-21_stretch2.wav',\n",
       " '03-01-01-01-01-02-22_noise.wav',\n",
       " '03-01-01-01-01-02-22_pitch1.wav',\n",
       " '03-01-01-01-01-02-22_pitch2.wav',\n",
       " '03-01-01-01-01-02-22_shift_left.wav',\n",
       " '03-01-01-01-01-02-22_shift_right.wav',\n",
       " '03-01-01-01-01-02-22_stretch1.wav',\n",
       " '03-01-01-01-01-02-22_stretch2.wav',\n",
       " '03-01-01-01-01-02-23_noise.wav',\n",
       " '03-01-01-01-01-02-23_pitch1.wav',\n",
       " '03-01-01-01-01-02-23_pitch2.wav',\n",
       " '03-01-01-01-01-02-23_shift_left.wav',\n",
       " '03-01-01-01-01-02-23_shift_right.wav',\n",
       " '03-01-01-01-01-02-23_stretch1.wav',\n",
       " '03-01-01-01-01-02-23_stretch2.wav',\n",
       " '03-01-01-01-01-02-24_noise.wav',\n",
       " '03-01-01-01-01-02-24_pitch1.wav',\n",
       " '03-01-01-01-01-02-24_pitch2.wav',\n",
       " '03-01-01-01-01-02-24_shift_left.wav',\n",
       " '03-01-01-01-01-02-24_shift_right.wav',\n",
       " '03-01-01-01-01-02-24_stretch1.wav',\n",
       " '03-01-01-01-01-02-24_stretch2.wav',\n",
       " '03-01-01-01-02-01-01_noise.wav',\n",
       " '03-01-01-01-02-01-01_pitch1.wav',\n",
       " '03-01-01-01-02-01-01_pitch2.wav',\n",
       " '03-01-01-01-02-01-01_shift_left.wav',\n",
       " '03-01-01-01-02-01-01_shift_right.wav',\n",
       " '03-01-01-01-02-01-01_stretch1.wav',\n",
       " '03-01-01-01-02-01-01_stretch2.wav',\n",
       " '03-01-01-01-02-01-02_noise.wav',\n",
       " '03-01-01-01-02-01-02_pitch1.wav',\n",
       " '03-01-01-01-02-01-02_pitch2.wav',\n",
       " '03-01-01-01-02-01-02_shift_left.wav',\n",
       " '03-01-01-01-02-01-02_shift_right.wav',\n",
       " '03-01-01-01-02-01-02_stretch1.wav',\n",
       " '03-01-01-01-02-01-02_stretch2.wav',\n",
       " '03-01-01-01-02-01-03_noise.wav',\n",
       " '03-01-01-01-02-01-03_pitch1.wav',\n",
       " '03-01-01-01-02-01-03_pitch2.wav',\n",
       " '03-01-01-01-02-01-03_shift_left.wav',\n",
       " '03-01-01-01-02-01-03_shift_right.wav',\n",
       " '03-01-01-01-02-01-03_stretch1.wav',\n",
       " '03-01-01-01-02-01-03_stretch2.wav',\n",
       " '03-01-01-01-02-01-04_noise.wav',\n",
       " '03-01-01-01-02-01-04_pitch1.wav',\n",
       " '03-01-01-01-02-01-04_pitch2.wav',\n",
       " '03-01-01-01-02-01-04_shift_left.wav',\n",
       " '03-01-01-01-02-01-04_shift_right.wav',\n",
       " '03-01-01-01-02-01-04_stretch1.wav',\n",
       " '03-01-01-01-02-01-04_stretch2.wav',\n",
       " '03-01-01-01-02-01-05_noise.wav',\n",
       " '03-01-01-01-02-01-05_pitch1.wav',\n",
       " '03-01-01-01-02-01-05_pitch2.wav',\n",
       " '03-01-01-01-02-01-05_shift_left.wav',\n",
       " '03-01-01-01-02-01-05_shift_right.wav',\n",
       " '03-01-01-01-02-01-05_stretch1.wav',\n",
       " '03-01-01-01-02-01-05_stretch2.wav',\n",
       " '03-01-01-01-02-01-06_noise.wav',\n",
       " '03-01-01-01-02-01-06_pitch1.wav',\n",
       " '03-01-01-01-02-01-06_pitch2.wav',\n",
       " '03-01-01-01-02-01-06_shift_left.wav',\n",
       " '03-01-01-01-02-01-06_shift_right.wav',\n",
       " '03-01-01-01-02-01-06_stretch1.wav',\n",
       " '03-01-01-01-02-01-06_stretch2.wav',\n",
       " '03-01-01-01-02-01-07_noise.wav',\n",
       " '03-01-01-01-02-01-07_pitch1.wav',\n",
       " '03-01-01-01-02-01-07_pitch2.wav',\n",
       " '03-01-01-01-02-01-07_shift_left.wav',\n",
       " '03-01-01-01-02-01-07_shift_right.wav',\n",
       " '03-01-01-01-02-01-07_stretch1.wav',\n",
       " '03-01-01-01-02-01-07_stretch2.wav',\n",
       " '03-01-01-01-02-01-08_noise.wav',\n",
       " '03-01-01-01-02-01-08_pitch1.wav',\n",
       " '03-01-01-01-02-01-08_pitch2.wav',\n",
       " '03-01-01-01-02-01-08_shift_left.wav',\n",
       " '03-01-01-01-02-01-08_shift_right.wav',\n",
       " '03-01-01-01-02-01-08_stretch1.wav',\n",
       " '03-01-01-01-02-01-08_stretch2.wav',\n",
       " '03-01-01-01-02-01-09_noise.wav',\n",
       " '03-01-01-01-02-01-09_pitch1.wav',\n",
       " '03-01-01-01-02-01-09_pitch2.wav',\n",
       " '03-01-01-01-02-01-09_shift_left.wav',\n",
       " '03-01-01-01-02-01-09_shift_right.wav',\n",
       " '03-01-01-01-02-01-09_stretch1.wav',\n",
       " '03-01-01-01-02-01-09_stretch2.wav',\n",
       " '03-01-01-01-02-01-10_noise.wav',\n",
       " '03-01-01-01-02-01-10_pitch1.wav',\n",
       " '03-01-01-01-02-01-10_pitch2.wav',\n",
       " '03-01-01-01-02-01-10_shift_left.wav',\n",
       " '03-01-01-01-02-01-10_shift_right.wav',\n",
       " '03-01-01-01-02-01-10_stretch1.wav',\n",
       " '03-01-01-01-02-01-10_stretch2.wav',\n",
       " '03-01-01-01-02-01-11_noise.wav',\n",
       " '03-01-01-01-02-01-11_pitch1.wav',\n",
       " '03-01-01-01-02-01-11_pitch2.wav',\n",
       " '03-01-01-01-02-01-11_shift_left.wav',\n",
       " '03-01-01-01-02-01-11_shift_right.wav',\n",
       " '03-01-01-01-02-01-11_stretch1.wav',\n",
       " '03-01-01-01-02-01-11_stretch2.wav',\n",
       " '03-01-01-01-02-01-12_noise.wav',\n",
       " '03-01-01-01-02-01-12_pitch1.wav',\n",
       " '03-01-01-01-02-01-12_pitch2.wav',\n",
       " '03-01-01-01-02-01-12_shift_left.wav',\n",
       " '03-01-01-01-02-01-12_shift_right.wav',\n",
       " '03-01-01-01-02-01-12_stretch1.wav',\n",
       " '03-01-01-01-02-01-12_stretch2.wav',\n",
       " '03-01-01-01-02-01-13_noise.wav',\n",
       " '03-01-01-01-02-01-13_pitch1.wav',\n",
       " '03-01-01-01-02-01-13_pitch2.wav',\n",
       " '03-01-01-01-02-01-13_shift_left.wav',\n",
       " '03-01-01-01-02-01-13_shift_right.wav',\n",
       " '03-01-01-01-02-01-13_stretch1.wav',\n",
       " '03-01-01-01-02-01-13_stretch2.wav',\n",
       " '03-01-01-01-02-01-14_noise.wav',\n",
       " '03-01-01-01-02-01-14_pitch1.wav',\n",
       " '03-01-01-01-02-01-14_pitch2.wav',\n",
       " '03-01-01-01-02-01-14_shift_left.wav',\n",
       " '03-01-01-01-02-01-14_shift_right.wav',\n",
       " '03-01-01-01-02-01-14_stretch1.wav',\n",
       " '03-01-01-01-02-01-14_stretch2.wav',\n",
       " '03-01-01-01-02-01-15_noise.wav',\n",
       " '03-01-01-01-02-01-15_pitch1.wav',\n",
       " '03-01-01-01-02-01-15_pitch2.wav',\n",
       " '03-01-01-01-02-01-15_shift_left.wav',\n",
       " '03-01-01-01-02-01-15_shift_right.wav',\n",
       " '03-01-01-01-02-01-15_stretch1.wav',\n",
       " '03-01-01-01-02-01-15_stretch2.wav',\n",
       " '03-01-01-01-02-01-16_noise.wav',\n",
       " '03-01-01-01-02-01-16_pitch1.wav',\n",
       " '03-01-01-01-02-01-16_pitch2.wav',\n",
       " '03-01-01-01-02-01-16_shift_left.wav',\n",
       " '03-01-01-01-02-01-16_shift_right.wav',\n",
       " '03-01-01-01-02-01-16_stretch1.wav',\n",
       " '03-01-01-01-02-01-16_stretch2.wav',\n",
       " '03-01-01-01-02-01-17_noise.wav',\n",
       " '03-01-01-01-02-01-17_pitch1.wav',\n",
       " '03-01-01-01-02-01-17_pitch2.wav',\n",
       " '03-01-01-01-02-01-17_shift_left.wav',\n",
       " '03-01-01-01-02-01-17_shift_right.wav',\n",
       " '03-01-01-01-02-01-17_stretch1.wav',\n",
       " '03-01-01-01-02-01-17_stretch2.wav',\n",
       " '03-01-01-01-02-01-18_noise.wav',\n",
       " '03-01-01-01-02-01-18_pitch1.wav',\n",
       " '03-01-01-01-02-01-18_pitch2.wav',\n",
       " '03-01-01-01-02-01-18_shift_left.wav',\n",
       " '03-01-01-01-02-01-18_shift_right.wav',\n",
       " '03-01-01-01-02-01-18_stretch1.wav',\n",
       " '03-01-01-01-02-01-18_stretch2.wav',\n",
       " '03-01-01-01-02-01-19_noise.wav',\n",
       " '03-01-01-01-02-01-19_pitch1.wav',\n",
       " '03-01-01-01-02-01-19_pitch2.wav',\n",
       " '03-01-01-01-02-01-19_shift_left.wav',\n",
       " '03-01-01-01-02-01-19_shift_right.wav',\n",
       " '03-01-01-01-02-01-19_stretch1.wav',\n",
       " '03-01-01-01-02-01-19_stretch2.wav',\n",
       " '03-01-01-01-02-01-20_noise.wav',\n",
       " '03-01-01-01-02-01-20_pitch1.wav',\n",
       " '03-01-01-01-02-01-20_pitch2.wav',\n",
       " '03-01-01-01-02-01-20_shift_left.wav',\n",
       " '03-01-01-01-02-01-20_shift_right.wav',\n",
       " '03-01-01-01-02-01-20_stretch1.wav',\n",
       " '03-01-01-01-02-01-20_stretch2.wav',\n",
       " '03-01-01-01-02-01-21_noise.wav',\n",
       " '03-01-01-01-02-01-21_pitch1.wav',\n",
       " '03-01-01-01-02-01-21_pitch2.wav',\n",
       " '03-01-01-01-02-01-21_shift_left.wav',\n",
       " '03-01-01-01-02-01-21_shift_right.wav',\n",
       " '03-01-01-01-02-01-21_stretch1.wav',\n",
       " '03-01-01-01-02-01-21_stretch2.wav',\n",
       " '03-01-01-01-02-01-22_noise.wav',\n",
       " '03-01-01-01-02-01-22_pitch1.wav',\n",
       " '03-01-01-01-02-01-22_pitch2.wav',\n",
       " '03-01-01-01-02-01-22_shift_left.wav',\n",
       " '03-01-01-01-02-01-22_shift_right.wav',\n",
       " '03-01-01-01-02-01-22_stretch1.wav',\n",
       " '03-01-01-01-02-01-22_stretch2.wav',\n",
       " '03-01-01-01-02-01-23_noise.wav',\n",
       " '03-01-01-01-02-01-23_pitch1.wav',\n",
       " '03-01-01-01-02-01-23_pitch2.wav',\n",
       " '03-01-01-01-02-01-23_shift_left.wav',\n",
       " '03-01-01-01-02-01-23_shift_right.wav',\n",
       " '03-01-01-01-02-01-23_stretch1.wav',\n",
       " '03-01-01-01-02-01-23_stretch2.wav',\n",
       " '03-01-01-01-02-01-24_noise.wav',\n",
       " '03-01-01-01-02-01-24_pitch1.wav',\n",
       " '03-01-01-01-02-01-24_pitch2.wav',\n",
       " '03-01-01-01-02-01-24_shift_left.wav',\n",
       " '03-01-01-01-02-01-24_shift_right.wav',\n",
       " '03-01-01-01-02-01-24_stretch1.wav',\n",
       " '03-01-01-01-02-01-24_stretch2.wav',\n",
       " '03-01-01-01-02-02-01_noise.wav',\n",
       " '03-01-01-01-02-02-01_pitch1.wav',\n",
       " '03-01-01-01-02-02-01_pitch2.wav',\n",
       " '03-01-01-01-02-02-01_shift_left.wav',\n",
       " '03-01-01-01-02-02-01_shift_right.wav',\n",
       " '03-01-01-01-02-02-01_stretch1.wav',\n",
       " '03-01-01-01-02-02-01_stretch2.wav',\n",
       " '03-01-01-01-02-02-02_noise.wav',\n",
       " '03-01-01-01-02-02-02_pitch1.wav',\n",
       " '03-01-01-01-02-02-02_pitch2.wav',\n",
       " '03-01-01-01-02-02-02_shift_left.wav',\n",
       " '03-01-01-01-02-02-02_shift_right.wav',\n",
       " '03-01-01-01-02-02-02_stretch1.wav',\n",
       " '03-01-01-01-02-02-02_stretch2.wav',\n",
       " '03-01-01-01-02-02-03_noise.wav',\n",
       " '03-01-01-01-02-02-03_pitch1.wav',\n",
       " '03-01-01-01-02-02-03_pitch2.wav',\n",
       " '03-01-01-01-02-02-03_shift_left.wav',\n",
       " '03-01-01-01-02-02-03_shift_right.wav',\n",
       " '03-01-01-01-02-02-03_stretch1.wav',\n",
       " '03-01-01-01-02-02-03_stretch2.wav',\n",
       " '03-01-01-01-02-02-04_noise.wav',\n",
       " '03-01-01-01-02-02-04_pitch1.wav',\n",
       " '03-01-01-01-02-02-04_pitch2.wav',\n",
       " '03-01-01-01-02-02-04_shift_left.wav',\n",
       " '03-01-01-01-02-02-04_shift_right.wav',\n",
       " '03-01-01-01-02-02-04_stretch1.wav',\n",
       " '03-01-01-01-02-02-04_stretch2.wav',\n",
       " '03-01-01-01-02-02-05_noise.wav',\n",
       " '03-01-01-01-02-02-05_pitch1.wav',\n",
       " '03-01-01-01-02-02-05_pitch2.wav',\n",
       " '03-01-01-01-02-02-05_shift_left.wav',\n",
       " '03-01-01-01-02-02-05_shift_right.wav',\n",
       " '03-01-01-01-02-02-05_stretch1.wav',\n",
       " '03-01-01-01-02-02-05_stretch2.wav',\n",
       " '03-01-01-01-02-02-06_noise.wav',\n",
       " '03-01-01-01-02-02-06_pitch1.wav',\n",
       " '03-01-01-01-02-02-06_pitch2.wav',\n",
       " '03-01-01-01-02-02-06_shift_left.wav',\n",
       " '03-01-01-01-02-02-06_shift_right.wav',\n",
       " '03-01-01-01-02-02-06_stretch1.wav',\n",
       " '03-01-01-01-02-02-06_stretch2.wav',\n",
       " '03-01-01-01-02-02-07_noise.wav',\n",
       " '03-01-01-01-02-02-07_pitch1.wav',\n",
       " '03-01-01-01-02-02-07_pitch2.wav',\n",
       " '03-01-01-01-02-02-07_shift_left.wav',\n",
       " '03-01-01-01-02-02-07_shift_right.wav',\n",
       " '03-01-01-01-02-02-07_stretch1.wav',\n",
       " '03-01-01-01-02-02-07_stretch2.wav',\n",
       " '03-01-01-01-02-02-08_noise.wav',\n",
       " '03-01-01-01-02-02-08_pitch1.wav',\n",
       " '03-01-01-01-02-02-08_pitch2.wav',\n",
       " '03-01-01-01-02-02-08_shift_left.wav',\n",
       " '03-01-01-01-02-02-08_shift_right.wav',\n",
       " '03-01-01-01-02-02-08_stretch1.wav',\n",
       " '03-01-01-01-02-02-08_stretch2.wav',\n",
       " '03-01-01-01-02-02-09_noise.wav',\n",
       " '03-01-01-01-02-02-09_pitch1.wav',\n",
       " '03-01-01-01-02-02-09_pitch2.wav',\n",
       " '03-01-01-01-02-02-09_shift_left.wav',\n",
       " '03-01-01-01-02-02-09_shift_right.wav',\n",
       " '03-01-01-01-02-02-09_stretch1.wav',\n",
       " '03-01-01-01-02-02-09_stretch2.wav',\n",
       " '03-01-01-01-02-02-10_noise.wav',\n",
       " '03-01-01-01-02-02-10_pitch1.wav',\n",
       " '03-01-01-01-02-02-10_pitch2.wav',\n",
       " '03-01-01-01-02-02-10_shift_left.wav',\n",
       " '03-01-01-01-02-02-10_shift_right.wav',\n",
       " '03-01-01-01-02-02-10_stretch1.wav',\n",
       " '03-01-01-01-02-02-10_stretch2.wav',\n",
       " '03-01-01-01-02-02-11_noise.wav',\n",
       " '03-01-01-01-02-02-11_pitch1.wav',\n",
       " '03-01-01-01-02-02-11_pitch2.wav',\n",
       " '03-01-01-01-02-02-11_shift_left.wav',\n",
       " '03-01-01-01-02-02-11_shift_right.wav',\n",
       " '03-01-01-01-02-02-11_stretch1.wav',\n",
       " '03-01-01-01-02-02-11_stretch2.wav',\n",
       " '03-01-01-01-02-02-12_noise.wav',\n",
       " '03-01-01-01-02-02-12_pitch1.wav',\n",
       " '03-01-01-01-02-02-12_pitch2.wav',\n",
       " '03-01-01-01-02-02-12_shift_left.wav',\n",
       " '03-01-01-01-02-02-12_shift_right.wav',\n",
       " '03-01-01-01-02-02-12_stretch1.wav',\n",
       " '03-01-01-01-02-02-12_stretch2.wav',\n",
       " '03-01-01-01-02-02-13_noise.wav',\n",
       " '03-01-01-01-02-02-13_pitch1.wav',\n",
       " '03-01-01-01-02-02-13_pitch2.wav',\n",
       " '03-01-01-01-02-02-13_shift_left.wav',\n",
       " '03-01-01-01-02-02-13_shift_right.wav',\n",
       " '03-01-01-01-02-02-13_stretch1.wav',\n",
       " '03-01-01-01-02-02-13_stretch2.wav',\n",
       " '03-01-01-01-02-02-14_noise.wav',\n",
       " '03-01-01-01-02-02-14_pitch1.wav',\n",
       " '03-01-01-01-02-02-14_pitch2.wav',\n",
       " '03-01-01-01-02-02-14_shift_left.wav',\n",
       " '03-01-01-01-02-02-14_shift_right.wav',\n",
       " '03-01-01-01-02-02-14_stretch1.wav',\n",
       " '03-01-01-01-02-02-14_stretch2.wav',\n",
       " '03-01-01-01-02-02-15_noise.wav',\n",
       " '03-01-01-01-02-02-15_pitch1.wav',\n",
       " '03-01-01-01-02-02-15_pitch2.wav',\n",
       " '03-01-01-01-02-02-15_shift_left.wav',\n",
       " '03-01-01-01-02-02-15_shift_right.wav',\n",
       " '03-01-01-01-02-02-15_stretch1.wav',\n",
       " '03-01-01-01-02-02-15_stretch2.wav',\n",
       " '03-01-01-01-02-02-16_noise.wav',\n",
       " '03-01-01-01-02-02-16_pitch1.wav',\n",
       " '03-01-01-01-02-02-16_pitch2.wav',\n",
       " '03-01-01-01-02-02-16_shift_left.wav',\n",
       " '03-01-01-01-02-02-16_shift_right.wav',\n",
       " '03-01-01-01-02-02-16_stretch1.wav',\n",
       " '03-01-01-01-02-02-16_stretch2.wav',\n",
       " '03-01-01-01-02-02-17_noise.wav',\n",
       " '03-01-01-01-02-02-17_pitch1.wav',\n",
       " '03-01-01-01-02-02-17_pitch2.wav',\n",
       " '03-01-01-01-02-02-17_shift_left.wav',\n",
       " '03-01-01-01-02-02-17_shift_right.wav',\n",
       " '03-01-01-01-02-02-17_stretch1.wav',\n",
       " '03-01-01-01-02-02-17_stretch2.wav',\n",
       " '03-01-01-01-02-02-18_noise.wav',\n",
       " '03-01-01-01-02-02-18_pitch1.wav',\n",
       " '03-01-01-01-02-02-18_pitch2.wav',\n",
       " '03-01-01-01-02-02-18_shift_left.wav',\n",
       " '03-01-01-01-02-02-18_shift_right.wav',\n",
       " '03-01-01-01-02-02-18_stretch1.wav',\n",
       " '03-01-01-01-02-02-18_stretch2.wav',\n",
       " '03-01-01-01-02-02-19_noise.wav',\n",
       " '03-01-01-01-02-02-19_pitch1.wav',\n",
       " '03-01-01-01-02-02-19_pitch2.wav',\n",
       " '03-01-01-01-02-02-19_shift_left.wav',\n",
       " '03-01-01-01-02-02-19_shift_right.wav',\n",
       " '03-01-01-01-02-02-19_stretch1.wav',\n",
       " '03-01-01-01-02-02-19_stretch2.wav',\n",
       " '03-01-01-01-02-02-20_noise.wav',\n",
       " '03-01-01-01-02-02-20_pitch1.wav',\n",
       " '03-01-01-01-02-02-20_pitch2.wav',\n",
       " '03-01-01-01-02-02-20_shift_left.wav',\n",
       " '03-01-01-01-02-02-20_shift_right.wav',\n",
       " '03-01-01-01-02-02-20_stretch1.wav',\n",
       " '03-01-01-01-02-02-20_stretch2.wav',\n",
       " '03-01-01-01-02-02-21_noise.wav',\n",
       " '03-01-01-01-02-02-21_pitch1.wav',\n",
       " '03-01-01-01-02-02-21_pitch2.wav',\n",
       " '03-01-01-01-02-02-21_shift_left.wav',\n",
       " '03-01-01-01-02-02-21_shift_right.wav',\n",
       " '03-01-01-01-02-02-21_stretch1.wav',\n",
       " '03-01-01-01-02-02-21_stretch2.wav',\n",
       " '03-01-01-01-02-02-22_noise.wav',\n",
       " '03-01-01-01-02-02-22_pitch1.wav',\n",
       " '03-01-01-01-02-02-22_pitch2.wav',\n",
       " '03-01-01-01-02-02-22_shift_left.wav',\n",
       " '03-01-01-01-02-02-22_shift_right.wav',\n",
       " '03-01-01-01-02-02-22_stretch1.wav',\n",
       " '03-01-01-01-02-02-22_stretch2.wav',\n",
       " '03-01-01-01-02-02-23_noise.wav',\n",
       " '03-01-01-01-02-02-23_pitch1.wav',\n",
       " '03-01-01-01-02-02-23_pitch2.wav',\n",
       " '03-01-01-01-02-02-23_shift_left.wav',\n",
       " '03-01-01-01-02-02-23_shift_right.wav',\n",
       " '03-01-01-01-02-02-23_stretch1.wav',\n",
       " '03-01-01-01-02-02-23_stretch2.wav',\n",
       " '03-01-01-01-02-02-24_noise.wav',\n",
       " '03-01-01-01-02-02-24_pitch1.wav',\n",
       " '03-01-01-01-02-02-24_pitch2.wav',\n",
       " '03-01-01-01-02-02-24_shift_left.wav',\n",
       " '03-01-01-01-02-02-24_shift_right.wav',\n",
       " '03-01-01-01-02-02-24_stretch1.wav',\n",
       " '03-01-01-01-02-02-24_stretch2.wav',\n",
       " '03-01-02-01-01-01-01_noise.wav',\n",
       " '03-01-02-01-01-01-01_pitch1.wav',\n",
       " '03-01-02-01-01-01-01_pitch2.wav',\n",
       " '03-01-02-01-01-01-01_shift_left.wav',\n",
       " '03-01-02-01-01-01-01_shift_right.wav',\n",
       " '03-01-02-01-01-01-01_stretch1.wav',\n",
       " '03-01-02-01-01-01-01_stretch2.wav',\n",
       " '03-01-02-01-01-01-02_noise.wav',\n",
       " '03-01-02-01-01-01-02_pitch1.wav',\n",
       " '03-01-02-01-01-01-02_pitch2.wav',\n",
       " '03-01-02-01-01-01-02_shift_left.wav',\n",
       " '03-01-02-01-01-01-02_shift_right.wav',\n",
       " '03-01-02-01-01-01-02_stretch1.wav',\n",
       " '03-01-02-01-01-01-02_stretch2.wav',\n",
       " '03-01-02-01-01-01-03_noise.wav',\n",
       " '03-01-02-01-01-01-03_pitch1.wav',\n",
       " '03-01-02-01-01-01-03_pitch2.wav',\n",
       " '03-01-02-01-01-01-03_shift_left.wav',\n",
       " '03-01-02-01-01-01-03_shift_right.wav',\n",
       " '03-01-02-01-01-01-03_stretch1.wav',\n",
       " '03-01-02-01-01-01-03_stretch2.wav',\n",
       " '03-01-02-01-01-01-04_noise.wav',\n",
       " '03-01-02-01-01-01-04_pitch1.wav',\n",
       " '03-01-02-01-01-01-04_pitch2.wav',\n",
       " '03-01-02-01-01-01-04_shift_left.wav',\n",
       " '03-01-02-01-01-01-04_shift_right.wav',\n",
       " '03-01-02-01-01-01-04_stretch1.wav',\n",
       " '03-01-02-01-01-01-04_stretch2.wav',\n",
       " '03-01-02-01-01-01-05_noise.wav',\n",
       " '03-01-02-01-01-01-05_pitch1.wav',\n",
       " '03-01-02-01-01-01-05_pitch2.wav',\n",
       " '03-01-02-01-01-01-05_shift_left.wav',\n",
       " '03-01-02-01-01-01-05_shift_right.wav',\n",
       " '03-01-02-01-01-01-05_stretch1.wav',\n",
       " '03-01-02-01-01-01-05_stretch2.wav',\n",
       " '03-01-02-01-01-01-06_noise.wav',\n",
       " '03-01-02-01-01-01-06_pitch1.wav',\n",
       " '03-01-02-01-01-01-06_pitch2.wav',\n",
       " '03-01-02-01-01-01-06_shift_left.wav',\n",
       " '03-01-02-01-01-01-06_shift_right.wav',\n",
       " '03-01-02-01-01-01-06_stretch1.wav',\n",
       " '03-01-02-01-01-01-06_stretch2.wav',\n",
       " '03-01-02-01-01-01-07_noise.wav',\n",
       " '03-01-02-01-01-01-07_pitch1.wav',\n",
       " '03-01-02-01-01-01-07_pitch2.wav',\n",
       " '03-01-02-01-01-01-07_shift_left.wav',\n",
       " '03-01-02-01-01-01-07_shift_right.wav',\n",
       " '03-01-02-01-01-01-07_stretch1.wav',\n",
       " '03-01-02-01-01-01-07_stretch2.wav',\n",
       " '03-01-02-01-01-01-08_noise.wav',\n",
       " '03-01-02-01-01-01-08_pitch1.wav',\n",
       " '03-01-02-01-01-01-08_pitch2.wav',\n",
       " '03-01-02-01-01-01-08_shift_left.wav',\n",
       " '03-01-02-01-01-01-08_shift_right.wav',\n",
       " '03-01-02-01-01-01-08_stretch1.wav',\n",
       " '03-01-02-01-01-01-08_stretch2.wav',\n",
       " '03-01-02-01-01-01-09_noise.wav',\n",
       " '03-01-02-01-01-01-09_pitch1.wav',\n",
       " '03-01-02-01-01-01-09_pitch2.wav',\n",
       " '03-01-02-01-01-01-09_shift_left.wav',\n",
       " '03-01-02-01-01-01-09_shift_right.wav',\n",
       " '03-01-02-01-01-01-09_stretch1.wav',\n",
       " '03-01-02-01-01-01-09_stretch2.wav',\n",
       " '03-01-02-01-01-01-10_noise.wav',\n",
       " '03-01-02-01-01-01-10_pitch1.wav',\n",
       " '03-01-02-01-01-01-10_pitch2.wav',\n",
       " '03-01-02-01-01-01-10_shift_left.wav',\n",
       " '03-01-02-01-01-01-10_shift_right.wav',\n",
       " '03-01-02-01-01-01-10_stretch1.wav',\n",
       " '03-01-02-01-01-01-10_stretch2.wav',\n",
       " '03-01-02-01-01-01-11_noise.wav',\n",
       " '03-01-02-01-01-01-11_pitch1.wav',\n",
       " '03-01-02-01-01-01-11_pitch2.wav',\n",
       " '03-01-02-01-01-01-11_shift_left.wav',\n",
       " '03-01-02-01-01-01-11_shift_right.wav',\n",
       " '03-01-02-01-01-01-11_stretch1.wav',\n",
       " '03-01-02-01-01-01-11_stretch2.wav',\n",
       " '03-01-02-01-01-01-12_noise.wav',\n",
       " '03-01-02-01-01-01-12_pitch1.wav',\n",
       " '03-01-02-01-01-01-12_pitch2.wav',\n",
       " '03-01-02-01-01-01-12_shift_left.wav',\n",
       " '03-01-02-01-01-01-12_shift_right.wav',\n",
       " '03-01-02-01-01-01-12_stretch1.wav',\n",
       " '03-01-02-01-01-01-12_stretch2.wav',\n",
       " '03-01-02-01-01-01-13_noise.wav',\n",
       " '03-01-02-01-01-01-13_pitch1.wav',\n",
       " '03-01-02-01-01-01-13_pitch2.wav',\n",
       " '03-01-02-01-01-01-13_shift_left.wav',\n",
       " '03-01-02-01-01-01-13_shift_right.wav',\n",
       " '03-01-02-01-01-01-13_stretch1.wav',\n",
       " '03-01-02-01-01-01-13_stretch2.wav',\n",
       " '03-01-02-01-01-01-14_noise.wav',\n",
       " '03-01-02-01-01-01-14_pitch1.wav',\n",
       " '03-01-02-01-01-01-14_pitch2.wav',\n",
       " '03-01-02-01-01-01-14_shift_left.wav',\n",
       " '03-01-02-01-01-01-14_shift_right.wav',\n",
       " '03-01-02-01-01-01-14_stretch1.wav',\n",
       " '03-01-02-01-01-01-14_stretch2.wav',\n",
       " '03-01-02-01-01-01-15_noise.wav',\n",
       " '03-01-02-01-01-01-15_pitch1.wav',\n",
       " '03-01-02-01-01-01-15_pitch2.wav',\n",
       " '03-01-02-01-01-01-15_shift_left.wav',\n",
       " '03-01-02-01-01-01-15_shift_right.wav',\n",
       " '03-01-02-01-01-01-15_stretch1.wav',\n",
       " '03-01-02-01-01-01-15_stretch2.wav',\n",
       " '03-01-02-01-01-01-16_noise.wav',\n",
       " '03-01-02-01-01-01-16_pitch1.wav',\n",
       " '03-01-02-01-01-01-16_pitch2.wav',\n",
       " '03-01-02-01-01-01-16_shift_left.wav',\n",
       " '03-01-02-01-01-01-16_shift_right.wav',\n",
       " '03-01-02-01-01-01-16_stretch1.wav',\n",
       " '03-01-02-01-01-01-16_stretch2.wav',\n",
       " '03-01-02-01-01-01-17_noise.wav',\n",
       " '03-01-02-01-01-01-17_pitch1.wav',\n",
       " '03-01-02-01-01-01-17_pitch2.wav',\n",
       " '03-01-02-01-01-01-17_shift_left.wav',\n",
       " '03-01-02-01-01-01-17_shift_right.wav',\n",
       " '03-01-02-01-01-01-17_stretch1.wav',\n",
       " '03-01-02-01-01-01-17_stretch2.wav',\n",
       " '03-01-02-01-01-01-18_noise.wav',\n",
       " '03-01-02-01-01-01-18_pitch1.wav',\n",
       " '03-01-02-01-01-01-18_pitch2.wav',\n",
       " '03-01-02-01-01-01-18_shift_left.wav',\n",
       " '03-01-02-01-01-01-18_shift_right.wav',\n",
       " '03-01-02-01-01-01-18_stretch1.wav',\n",
       " '03-01-02-01-01-01-18_stretch2.wav',\n",
       " '03-01-02-01-01-01-19_noise.wav',\n",
       " '03-01-02-01-01-01-19_pitch1.wav',\n",
       " '03-01-02-01-01-01-19_pitch2.wav',\n",
       " '03-01-02-01-01-01-19_shift_left.wav',\n",
       " '03-01-02-01-01-01-19_shift_right.wav',\n",
       " '03-01-02-01-01-01-19_stretch1.wav',\n",
       " '03-01-02-01-01-01-19_stretch2.wav',\n",
       " '03-01-02-01-01-01-20_noise.wav',\n",
       " '03-01-02-01-01-01-20_pitch1.wav',\n",
       " '03-01-02-01-01-01-20_pitch2.wav',\n",
       " '03-01-02-01-01-01-20_shift_left.wav',\n",
       " '03-01-02-01-01-01-20_shift_right.wav',\n",
       " '03-01-02-01-01-01-20_stretch1.wav',\n",
       " '03-01-02-01-01-01-20_stretch2.wav',\n",
       " '03-01-02-01-01-01-21_noise.wav',\n",
       " '03-01-02-01-01-01-21_pitch1.wav',\n",
       " '03-01-02-01-01-01-21_pitch2.wav',\n",
       " '03-01-02-01-01-01-21_shift_left.wav',\n",
       " '03-01-02-01-01-01-21_shift_right.wav',\n",
       " '03-01-02-01-01-01-21_stretch1.wav',\n",
       " '03-01-02-01-01-01-21_stretch2.wav',\n",
       " '03-01-02-01-01-01-22_noise.wav',\n",
       " '03-01-02-01-01-01-22_pitch1.wav',\n",
       " '03-01-02-01-01-01-22_pitch2.wav',\n",
       " '03-01-02-01-01-01-22_shift_left.wav',\n",
       " '03-01-02-01-01-01-22_shift_right.wav',\n",
       " '03-01-02-01-01-01-22_stretch1.wav',\n",
       " '03-01-02-01-01-01-22_stretch2.wav',\n",
       " '03-01-02-01-01-01-23_noise.wav',\n",
       " '03-01-02-01-01-01-23_pitch1.wav',\n",
       " '03-01-02-01-01-01-23_pitch2.wav',\n",
       " '03-01-02-01-01-01-23_shift_left.wav',\n",
       " '03-01-02-01-01-01-23_shift_right.wav',\n",
       " '03-01-02-01-01-01-23_stretch1.wav',\n",
       " '03-01-02-01-01-01-23_stretch2.wav',\n",
       " '03-01-02-01-01-01-24_noise.wav',\n",
       " '03-01-02-01-01-01-24_pitch1.wav',\n",
       " '03-01-02-01-01-01-24_pitch2.wav',\n",
       " '03-01-02-01-01-01-24_shift_left.wav',\n",
       " '03-01-02-01-01-01-24_shift_right.wav',\n",
       " '03-01-02-01-01-01-24_stretch1.wav',\n",
       " '03-01-02-01-01-01-24_stretch2.wav',\n",
       " '03-01-02-01-01-02-01_noise.wav',\n",
       " '03-01-02-01-01-02-01_pitch1.wav',\n",
       " '03-01-02-01-01-02-01_pitch2.wav',\n",
       " '03-01-02-01-01-02-01_shift_left.wav',\n",
       " '03-01-02-01-01-02-01_shift_right.wav',\n",
       " '03-01-02-01-01-02-01_stretch1.wav',\n",
       " '03-01-02-01-01-02-01_stretch2.wav',\n",
       " '03-01-02-01-01-02-02_noise.wav',\n",
       " '03-01-02-01-01-02-02_pitch1.wav',\n",
       " '03-01-02-01-01-02-02_pitch2.wav',\n",
       " '03-01-02-01-01-02-02_shift_left.wav',\n",
       " '03-01-02-01-01-02-02_shift_right.wav',\n",
       " '03-01-02-01-01-02-02_stretch1.wav',\n",
       " '03-01-02-01-01-02-02_stretch2.wav',\n",
       " '03-01-02-01-01-02-03_noise.wav',\n",
       " '03-01-02-01-01-02-03_pitch1.wav',\n",
       " '03-01-02-01-01-02-03_pitch2.wav',\n",
       " '03-01-02-01-01-02-03_shift_left.wav',\n",
       " '03-01-02-01-01-02-03_shift_right.wav',\n",
       " '03-01-02-01-01-02-03_stretch1.wav',\n",
       " '03-01-02-01-01-02-03_stretch2.wav',\n",
       " '03-01-02-01-01-02-04_noise.wav',\n",
       " '03-01-02-01-01-02-04_pitch1.wav',\n",
       " '03-01-02-01-01-02-04_pitch2.wav',\n",
       " '03-01-02-01-01-02-04_shift_left.wav',\n",
       " '03-01-02-01-01-02-04_shift_right.wav',\n",
       " '03-01-02-01-01-02-04_stretch1.wav',\n",
       " '03-01-02-01-01-02-04_stretch2.wav',\n",
       " '03-01-02-01-01-02-05_noise.wav',\n",
       " '03-01-02-01-01-02-05_pitch1.wav',\n",
       " '03-01-02-01-01-02-05_pitch2.wav',\n",
       " '03-01-02-01-01-02-05_shift_left.wav',\n",
       " '03-01-02-01-01-02-05_shift_right.wav',\n",
       " '03-01-02-01-01-02-05_stretch1.wav',\n",
       " '03-01-02-01-01-02-05_stretch2.wav',\n",
       " '03-01-02-01-01-02-06_noise.wav',\n",
       " '03-01-02-01-01-02-06_pitch1.wav',\n",
       " '03-01-02-01-01-02-06_pitch2.wav',\n",
       " '03-01-02-01-01-02-06_shift_left.wav',\n",
       " '03-01-02-01-01-02-06_shift_right.wav',\n",
       " '03-01-02-01-01-02-06_stretch1.wav',\n",
       " '03-01-02-01-01-02-06_stretch2.wav',\n",
       " '03-01-02-01-01-02-07_noise.wav',\n",
       " '03-01-02-01-01-02-07_pitch1.wav',\n",
       " '03-01-02-01-01-02-07_pitch2.wav',\n",
       " '03-01-02-01-01-02-07_shift_left.wav',\n",
       " '03-01-02-01-01-02-07_shift_right.wav',\n",
       " '03-01-02-01-01-02-07_stretch1.wav',\n",
       " '03-01-02-01-01-02-07_stretch2.wav',\n",
       " '03-01-02-01-01-02-08_noise.wav',\n",
       " '03-01-02-01-01-02-08_pitch1.wav',\n",
       " '03-01-02-01-01-02-08_pitch2.wav',\n",
       " '03-01-02-01-01-02-08_shift_left.wav',\n",
       " '03-01-02-01-01-02-08_shift_right.wav',\n",
       " '03-01-02-01-01-02-08_stretch1.wav',\n",
       " '03-01-02-01-01-02-08_stretch2.wav',\n",
       " '03-01-02-01-01-02-09_noise.wav',\n",
       " '03-01-02-01-01-02-09_pitch1.wav',\n",
       " '03-01-02-01-01-02-09_pitch2.wav',\n",
       " '03-01-02-01-01-02-09_shift_left.wav',\n",
       " '03-01-02-01-01-02-09_shift_right.wav',\n",
       " '03-01-02-01-01-02-09_stretch1.wav',\n",
       " '03-01-02-01-01-02-09_stretch2.wav',\n",
       " '03-01-02-01-01-02-10_noise.wav',\n",
       " '03-01-02-01-01-02-10_pitch1.wav',\n",
       " '03-01-02-01-01-02-10_pitch2.wav',\n",
       " '03-01-02-01-01-02-10_shift_left.wav',\n",
       " '03-01-02-01-01-02-10_shift_right.wav',\n",
       " '03-01-02-01-01-02-10_stretch1.wav',\n",
       " '03-01-02-01-01-02-10_stretch2.wav',\n",
       " '03-01-02-01-01-02-11_noise.wav',\n",
       " '03-01-02-01-01-02-11_pitch1.wav',\n",
       " '03-01-02-01-01-02-11_pitch2.wav',\n",
       " '03-01-02-01-01-02-11_shift_left.wav',\n",
       " '03-01-02-01-01-02-11_shift_right.wav',\n",
       " '03-01-02-01-01-02-11_stretch1.wav',\n",
       " '03-01-02-01-01-02-11_stretch2.wav',\n",
       " '03-01-02-01-01-02-12_noise.wav',\n",
       " '03-01-02-01-01-02-12_pitch1.wav',\n",
       " '03-01-02-01-01-02-12_pitch2.wav',\n",
       " '03-01-02-01-01-02-12_shift_left.wav',\n",
       " '03-01-02-01-01-02-12_shift_right.wav',\n",
       " '03-01-02-01-01-02-12_stretch1.wav',\n",
       " '03-01-02-01-01-02-12_stretch2.wav',\n",
       " '03-01-02-01-01-02-13_noise.wav',\n",
       " '03-01-02-01-01-02-13_pitch1.wav',\n",
       " '03-01-02-01-01-02-13_pitch2.wav',\n",
       " '03-01-02-01-01-02-13_shift_left.wav',\n",
       " '03-01-02-01-01-02-13_shift_right.wav',\n",
       " '03-01-02-01-01-02-13_stretch1.wav',\n",
       " '03-01-02-01-01-02-13_stretch2.wav',\n",
       " '03-01-02-01-01-02-14_noise.wav',\n",
       " '03-01-02-01-01-02-14_pitch1.wav',\n",
       " '03-01-02-01-01-02-14_pitch2.wav',\n",
       " '03-01-02-01-01-02-14_shift_left.wav',\n",
       " '03-01-02-01-01-02-14_shift_right.wav',\n",
       " '03-01-02-01-01-02-14_stretch1.wav',\n",
       " '03-01-02-01-01-02-14_stretch2.wav',\n",
       " '03-01-02-01-01-02-15_noise.wav',\n",
       " '03-01-02-01-01-02-15_pitch1.wav',\n",
       " '03-01-02-01-01-02-15_pitch2.wav',\n",
       " '03-01-02-01-01-02-15_shift_left.wav',\n",
       " '03-01-02-01-01-02-15_shift_right.wav',\n",
       " '03-01-02-01-01-02-15_stretch1.wav',\n",
       " '03-01-02-01-01-02-15_stretch2.wav',\n",
       " '03-01-02-01-01-02-16_noise.wav',\n",
       " '03-01-02-01-01-02-16_pitch1.wav',\n",
       " '03-01-02-01-01-02-16_pitch2.wav',\n",
       " '03-01-02-01-01-02-16_shift_left.wav',\n",
       " '03-01-02-01-01-02-16_shift_right.wav',\n",
       " '03-01-02-01-01-02-16_stretch1.wav',\n",
       " '03-01-02-01-01-02-16_stretch2.wav',\n",
       " '03-01-02-01-01-02-17_noise.wav',\n",
       " '03-01-02-01-01-02-17_pitch1.wav',\n",
       " '03-01-02-01-01-02-17_pitch2.wav',\n",
       " '03-01-02-01-01-02-17_shift_left.wav',\n",
       " '03-01-02-01-01-02-17_shift_right.wav',\n",
       " '03-01-02-01-01-02-17_stretch1.wav',\n",
       " '03-01-02-01-01-02-17_stretch2.wav',\n",
       " '03-01-02-01-01-02-18_noise.wav',\n",
       " '03-01-02-01-01-02-18_pitch1.wav',\n",
       " '03-01-02-01-01-02-18_pitch2.wav',\n",
       " '03-01-02-01-01-02-18_shift_left.wav',\n",
       " '03-01-02-01-01-02-18_shift_right.wav',\n",
       " '03-01-02-01-01-02-18_stretch1.wav',\n",
       " '03-01-02-01-01-02-18_stretch2.wav',\n",
       " '03-01-02-01-01-02-19_noise.wav',\n",
       " '03-01-02-01-01-02-19_pitch1.wav',\n",
       " '03-01-02-01-01-02-19_pitch2.wav',\n",
       " '03-01-02-01-01-02-19_shift_left.wav',\n",
       " '03-01-02-01-01-02-19_shift_right.wav',\n",
       " '03-01-02-01-01-02-19_stretch1.wav',\n",
       " '03-01-02-01-01-02-19_stretch2.wav',\n",
       " '03-01-02-01-01-02-20_noise.wav',\n",
       " '03-01-02-01-01-02-20_pitch1.wav',\n",
       " '03-01-02-01-01-02-20_pitch2.wav',\n",
       " '03-01-02-01-01-02-20_shift_left.wav',\n",
       " '03-01-02-01-01-02-20_shift_right.wav',\n",
       " '03-01-02-01-01-02-20_stretch1.wav',\n",
       " '03-01-02-01-01-02-20_stretch2.wav',\n",
       " '03-01-02-01-01-02-21_noise.wav',\n",
       " '03-01-02-01-01-02-21_pitch1.wav',\n",
       " '03-01-02-01-01-02-21_pitch2.wav',\n",
       " '03-01-02-01-01-02-21_shift_left.wav',\n",
       " '03-01-02-01-01-02-21_shift_right.wav',\n",
       " '03-01-02-01-01-02-21_stretch1.wav',\n",
       " '03-01-02-01-01-02-21_stretch2.wav',\n",
       " '03-01-02-01-01-02-22_noise.wav',\n",
       " '03-01-02-01-01-02-22_pitch1.wav',\n",
       " '03-01-02-01-01-02-22_pitch2.wav',\n",
       " '03-01-02-01-01-02-22_shift_left.wav',\n",
       " '03-01-02-01-01-02-22_shift_right.wav',\n",
       " '03-01-02-01-01-02-22_stretch1.wav',\n",
       " '03-01-02-01-01-02-22_stretch2.wav',\n",
       " '03-01-02-01-01-02-23_noise.wav',\n",
       " '03-01-02-01-01-02-23_pitch1.wav',\n",
       " '03-01-02-01-01-02-23_pitch2.wav',\n",
       " '03-01-02-01-01-02-23_shift_left.wav',\n",
       " '03-01-02-01-01-02-23_shift_right.wav',\n",
       " '03-01-02-01-01-02-23_stretch1.wav',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist= os.listdir('RawData_Aug/')\n",
    "mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-04-02-01-02-06_shift_right.wav\n",
      "04\n",
      "06\n"
     ]
    }
   ],
   "source": [
    "print(mylist[4239])\n",
    "print(mylist[4239][6:8])\n",
    "print(mylist[4239][18:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeling_list=[]\n",
    "est_animo=[]\n",
    "# Lista de palabras a seleccionar\n",
    "selected_emotion = [\"neutral\", \"happy\", \"sad\", \"angry\", \"fear\", \"disgust\", \"ps\"]\n",
    "\n",
    "# for item in mylist:\n",
    "\n",
    "#     #Se extrae el estado de animo del titulo del archivo del dataset TESS:\n",
    "#     nombre_base, _ = os.path.splitext(item)\n",
    "#     segundo_guion_posicion = nombre_base.find(\"_\", 4)\n",
    "#     if segundo_guion_posicion != -1:\n",
    "#         est_animo = nombre_base[(segundo_guion_posicion+1):len(nombre_base)]\n",
    "#         # print(est_animo)\n",
    "\n",
    "for item in mylist:\n",
    "\n",
    "    #Se extrae el estado de animo del titulo del archivo del dataset TESS:\n",
    "    nombre_base, _ = os.path.splitext(item)\n",
    "    primer_guion_posicion = nombre_base.find(\"_\") #codigo nuevo\n",
    "    # segundo_guion_posicion = nombre_base.find(\"_\", 4)\n",
    "    segundo_guion_posicion = nombre_base.find(\"_\", primer_guion_posicion + 1) #codigo nuevo\n",
    "    # Encuentra la tercera ocurrencia de '_' //codigo nuevo\n",
    "    tercer_guion_posicion = nombre_base.find(\"_\", segundo_guion_posicion + 1) #codigo nuevo\n",
    "    # if segundo_guion_posicion != -1:\n",
    "    if tercer_guion_posicion != -1: #codigo nuevo\n",
    "    #   est_animo = nombre_base[(segundo_guion_posicion+1):len(nombre_base)]\n",
    "        est_animo = nombre_base[(segundo_guion_posicion + 1):tercer_guion_posicion] #codigo nuevo\n",
    "        # print(est_animo)\n",
    "\n",
    "\n",
    "    #Se asigna los estados de animo del Dataset TESS:\n",
    "    if est_animo == selected_emotion[0]:\n",
    "        feeling_list.append('female_neutral')\n",
    "    elif est_animo == selected_emotion[1]:\n",
    "        feeling_list.append('female_happy')\n",
    "    elif est_animo == selected_emotion[2]:\n",
    "        feeling_list.append('female_sad')\n",
    "    elif est_animo == selected_emotion[3]:\n",
    "        feeling_list.append('female_angry')\n",
    "    elif est_animo == selected_emotion[4]:\n",
    "        feeling_list.append('female_fearful')\n",
    "    elif est_animo == selected_emotion[5]:\n",
    "        feeling_list.append('female_disgust')\n",
    "    elif est_animo == selected_emotion[6]:\n",
    "        feeling_list.append('female_surprised')\n",
    "\n",
    "    #Se asigna los estados de animo del Dataset RAVNESS:\n",
    "    if item[6:8]=='01' and int(item[18:20])%2==0:\n",
    "        feeling_list.append('female_neutral')\n",
    "    elif item[6:8]=='01' and int(item[18:20])%2==1:\n",
    "        feeling_list.append('male_neutral')\n",
    "    elif item[6:8]=='02' and int(item[18:20])%2==0:\n",
    "        feeling_list.append('female_neutral') #Se integra \"neutral\" con \"calm\"\n",
    "    elif item[6:8]=='02' and int(item[18:20])%2==1:\n",
    "        feeling_list.append('male_neutral') #Se integra \"neutral\" con \"calm\"\n",
    "    elif item[6:8]=='03' and int(item[18:20])%2==0:\n",
    "        feeling_list.append('female_happy')\n",
    "    elif item[6:8]=='03' and int(item[18:20])%2==1:\n",
    "        feeling_list.append('male_happy')\n",
    "    elif item[6:8]=='04' and int(item[18:20])%2==0:\n",
    "        feeling_list.append('female_sad')\n",
    "    elif item[6:8]=='04' and int(item[18:20])%2==1:\n",
    "        feeling_list.append('male_sad')\n",
    "    elif item[6:8]=='05' and int(item[18:20])%2==0:\n",
    "        feeling_list.append('female_angry')\n",
    "    elif item[6:8]=='05' and int(item[18:20])%2==1:\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[6:8]=='06' and int(item[18:20])%2==0:\n",
    "        feeling_list.append('female_fearful')\n",
    "    elif item[6:8]=='06' and int(item[18:20])%2==1:\n",
    "        feeling_list.append('male_fearful')\n",
    "    elif item[6:8]=='07' and int(item[18:20])%2==0:\n",
    "        feeling_list.append('female_disgust')\n",
    "    elif item[6:8]=='07' and int(item[18:20])%2==1:\n",
    "        feeling_list.append('male_disgust')\n",
    "    elif item[6:8]=='08' and int(item[18:20])%2==0:\n",
    "        feeling_list.append('female_surprised')\n",
    "    elif item[6:8]=='08' and int(item[18:20])%2==1:\n",
    "        feeling_list.append('male_surprised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'female_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " 'male_neutral',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feeling_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29676</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29677</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29678</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29679</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29680 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Emotions\n",
       "0      male_neutral\n",
       "1      male_neutral\n",
       "2      male_neutral\n",
       "3      male_neutral\n",
       "4      male_neutral\n",
       "...             ...\n",
       "29675    female_sad\n",
       "29676    female_sad\n",
       "29677    female_sad\n",
       "29678    female_sad\n",
       "29679    female_sad\n",
       "\n",
       "[29680 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.DataFrame(feeling_list)\n",
    "labelss=labels.rename(columns={0: 'Emotions'}) #Se renombra el título de la columna\n",
    "labelss[:29680]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de las características de los archivos de audio con Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for index,y in enumerate(mylist):\n",
    "    X, sample_rate = librosa.load('RawData_Aug/'+y, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)   #El número de coeficientes mfcc está relacionado con la frecuencia de muestreo de la señal de audio. Se recomienda extraer un número de coeficientes mfcc igual a un cuarto de la frecuencia de muestreo dividida por 13.29. En nuestro caso, hemos cogido 13 coeficientes MFCC al tratarse de una práctica común y ampliamente utilizada, basada en estudios que sugieren que este número captura adecuadamente la información perceptivamente relevante del espectro de audio para tareas como el reconocimiento de voz y la clasificación de emociones.\n",
    "    feature = mfccs\n",
    "    df.loc[bookmark] = [feature]\n",
    "    bookmark=bookmark+1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-42.579998, -42.40106, -42.63471, -41.658806,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-63.03742, -65.00583, -66.66983, -67.28745, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-63.6462, -65.425, -66.405075, -66.33299, -66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-65.92159, -65.92159, -65.92159, -65.92159, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-61.614525, -57.218075, -53.91826, -55.53662,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>[-14.182665, -17.613264, -26.834442, -28.91544...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29676</th>\n",
       "      <td>[-36.54438, -34.601017, -36.04222, -31.059767,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29677</th>\n",
       "      <td>[-20.612898, -19.055407, -19.209393, -18.69526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29678</th>\n",
       "      <td>[-16.877892, -21.438084, -30.812662, -29.86657...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29679</th>\n",
       "      <td>[-20.721703, -19.064161, -19.507662, -20.96388...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29680 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 feature\n",
       "0      [-42.579998, -42.40106, -42.63471, -41.658806,...\n",
       "1      [-63.03742, -65.00583, -66.66983, -67.28745, -...\n",
       "2      [-63.6462, -65.425, -66.405075, -66.33299, -66...\n",
       "3      [-65.92159, -65.92159, -65.92159, -65.92159, -...\n",
       "4      [-61.614525, -57.218075, -53.91826, -55.53662,...\n",
       "...                                                  ...\n",
       "29675  [-14.182665, -17.613264, -26.834442, -28.91544...\n",
       "29676  [-36.54438, -34.601017, -36.04222, -31.059767,...\n",
       "29677  [-20.612898, -19.055407, -19.209393, -18.69526...\n",
       "29678  [-16.877892, -21.438084, -30.812662, -29.86657...\n",
       "29679  [-20.721703, -19.064161, -19.507662, -20.96388...\n",
       "\n",
       "[29680 rows x 1 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se muestran los resultados agrupados en la columna \"feature\":\n",
    "df[:29680]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-42.579998</td>\n",
       "      <td>-42.401058</td>\n",
       "      <td>-42.634708</td>\n",
       "      <td>-41.658806</td>\n",
       "      <td>-40.756615</td>\n",
       "      <td>-42.452438</td>\n",
       "      <td>-41.612186</td>\n",
       "      <td>-38.970215</td>\n",
       "      <td>-39.890053</td>\n",
       "      <td>-39.281651</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.576973</td>\n",
       "      <td>-40.616489</td>\n",
       "      <td>-42.433720</td>\n",
       "      <td>-41.344578</td>\n",
       "      <td>-40.626751</td>\n",
       "      <td>-40.155827</td>\n",
       "      <td>-39.448544</td>\n",
       "      <td>-42.672073</td>\n",
       "      <td>-40.714092</td>\n",
       "      <td>-41.788750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-63.037418</td>\n",
       "      <td>-65.005829</td>\n",
       "      <td>-66.669830</td>\n",
       "      <td>-67.287453</td>\n",
       "      <td>-68.558067</td>\n",
       "      <td>-67.600204</td>\n",
       "      <td>-64.373993</td>\n",
       "      <td>-65.265434</td>\n",
       "      <td>-66.569328</td>\n",
       "      <td>-66.525711</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.719597</td>\n",
       "      <td>-61.664814</td>\n",
       "      <td>-65.102875</td>\n",
       "      <td>-64.612320</td>\n",
       "      <td>-63.308891</td>\n",
       "      <td>-63.294292</td>\n",
       "      <td>-63.697121</td>\n",
       "      <td>-61.154915</td>\n",
       "      <td>-60.509026</td>\n",
       "      <td>-61.649410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-63.646198</td>\n",
       "      <td>-65.425003</td>\n",
       "      <td>-66.405075</td>\n",
       "      <td>-66.332993</td>\n",
       "      <td>-66.921745</td>\n",
       "      <td>-65.886627</td>\n",
       "      <td>-65.463516</td>\n",
       "      <td>-66.057571</td>\n",
       "      <td>-64.519768</td>\n",
       "      <td>-65.093704</td>\n",
       "      <td>...</td>\n",
       "      <td>-60.843559</td>\n",
       "      <td>-62.265034</td>\n",
       "      <td>-64.428879</td>\n",
       "      <td>-65.732025</td>\n",
       "      <td>-64.407623</td>\n",
       "      <td>-64.002449</td>\n",
       "      <td>-62.538998</td>\n",
       "      <td>-62.779709</td>\n",
       "      <td>-63.208103</td>\n",
       "      <td>-60.739964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.516617</td>\n",
       "      <td>-60.150635</td>\n",
       "      <td>-61.763290</td>\n",
       "      <td>-60.687485</td>\n",
       "      <td>-56.944359</td>\n",
       "      <td>-56.765747</td>\n",
       "      <td>-60.142361</td>\n",
       "      <td>-61.449783</td>\n",
       "      <td>-63.798618</td>\n",
       "      <td>-63.813591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-61.614525</td>\n",
       "      <td>-57.218075</td>\n",
       "      <td>-53.918259</td>\n",
       "      <td>-55.536621</td>\n",
       "      <td>-56.447006</td>\n",
       "      <td>-55.554886</td>\n",
       "      <td>-55.437729</td>\n",
       "      <td>-56.230534</td>\n",
       "      <td>-56.135986</td>\n",
       "      <td>-56.615444</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>-14.182665</td>\n",
       "      <td>-17.613264</td>\n",
       "      <td>-26.834442</td>\n",
       "      <td>-28.915443</td>\n",
       "      <td>-28.501810</td>\n",
       "      <td>-27.867954</td>\n",
       "      <td>-27.804068</td>\n",
       "      <td>-29.921848</td>\n",
       "      <td>-29.119289</td>\n",
       "      <td>-27.622171</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29676</th>\n",
       "      <td>-36.544380</td>\n",
       "      <td>-34.601017</td>\n",
       "      <td>-36.042221</td>\n",
       "      <td>-31.059767</td>\n",
       "      <td>-23.514446</td>\n",
       "      <td>-19.393410</td>\n",
       "      <td>-18.620173</td>\n",
       "      <td>-18.691460</td>\n",
       "      <td>-18.765795</td>\n",
       "      <td>-18.849939</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29677</th>\n",
       "      <td>-20.612898</td>\n",
       "      <td>-19.055407</td>\n",
       "      <td>-19.209393</td>\n",
       "      <td>-18.695263</td>\n",
       "      <td>-16.728975</td>\n",
       "      <td>-15.619523</td>\n",
       "      <td>-17.330921</td>\n",
       "      <td>-19.615959</td>\n",
       "      <td>-20.122488</td>\n",
       "      <td>-24.445810</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29678</th>\n",
       "      <td>-16.877892</td>\n",
       "      <td>-21.438084</td>\n",
       "      <td>-30.812662</td>\n",
       "      <td>-29.866575</td>\n",
       "      <td>-28.868805</td>\n",
       "      <td>-26.216677</td>\n",
       "      <td>-23.669178</td>\n",
       "      <td>-23.294621</td>\n",
       "      <td>-23.804501</td>\n",
       "      <td>-24.265003</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29679</th>\n",
       "      <td>-20.721703</td>\n",
       "      <td>-19.064161</td>\n",
       "      <td>-19.507662</td>\n",
       "      <td>-20.963888</td>\n",
       "      <td>-22.484184</td>\n",
       "      <td>-23.754040</td>\n",
       "      <td>-25.131126</td>\n",
       "      <td>-23.629902</td>\n",
       "      <td>-24.390230</td>\n",
       "      <td>-26.116478</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.251514</td>\n",
       "      <td>-35.639587</td>\n",
       "      <td>-35.569790</td>\n",
       "      <td>-33.625927</td>\n",
       "      <td>-33.024925</td>\n",
       "      <td>-33.598068</td>\n",
       "      <td>-33.984474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29680 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5    \\\n",
       "0     -42.579998 -42.401058 -42.634708 -41.658806 -40.756615 -42.452438   \n",
       "1     -63.037418 -65.005829 -66.669830 -67.287453 -68.558067 -67.600204   \n",
       "2     -63.646198 -65.425003 -66.405075 -66.332993 -66.921745 -65.886627   \n",
       "3     -65.921593 -65.921593 -65.921593 -65.921593 -65.921593 -65.921593   \n",
       "4     -61.614525 -57.218075 -53.918259 -55.536621 -56.447006 -55.554886   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "29675 -14.182665 -17.613264 -26.834442 -28.915443 -28.501810 -27.867954   \n",
       "29676 -36.544380 -34.601017 -36.042221 -31.059767 -23.514446 -19.393410   \n",
       "29677 -20.612898 -19.055407 -19.209393 -18.695263 -16.728975 -15.619523   \n",
       "29678 -16.877892 -21.438084 -30.812662 -29.866575 -28.868805 -26.216677   \n",
       "29679 -20.721703 -19.064161 -19.507662 -20.963888 -22.484184 -23.754040   \n",
       "\n",
       "             6          7          8          9    ...        206        207  \\\n",
       "0     -41.612186 -38.970215 -39.890053 -39.281651  ... -41.576973 -40.616489   \n",
       "1     -64.373993 -65.265434 -66.569328 -66.525711  ... -61.719597 -61.664814   \n",
       "2     -65.463516 -66.057571 -64.519768 -65.093704  ... -60.843559 -62.265034   \n",
       "3     -65.921593 -65.921593 -65.921593 -65.921593  ... -56.516617 -60.150635   \n",
       "4     -55.437729 -56.230534 -56.135986 -56.615444  ... -65.984756 -65.984756   \n",
       "...          ...        ...        ...        ...  ...        ...        ...   \n",
       "29675 -27.804068 -29.921848 -29.119289 -27.622171  ...        NaN        NaN   \n",
       "29676 -18.620173 -18.691460 -18.765795 -18.849939  ...        NaN        NaN   \n",
       "29677 -17.330921 -19.615959 -20.122488 -24.445810  ...        NaN        NaN   \n",
       "29678 -23.669178 -23.294621 -23.804501 -24.265003  ...        NaN        NaN   \n",
       "29679 -25.131126 -23.629902 -24.390230 -26.116478  ... -34.251514 -35.639587   \n",
       "\n",
       "             208        209        210        211        212        213  \\\n",
       "0     -42.433720 -41.344578 -40.626751 -40.155827 -39.448544 -42.672073   \n",
       "1     -65.102875 -64.612320 -63.308891 -63.294292 -63.697121 -61.154915   \n",
       "2     -64.428879 -65.732025 -64.407623 -64.002449 -62.538998 -62.779709   \n",
       "3     -61.763290 -60.687485 -56.944359 -56.765747 -60.142361 -61.449783   \n",
       "4     -65.984756 -65.984756 -65.984756 -65.984756 -65.984756 -65.984756   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "29675        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "29676        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "29677        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "29678        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "29679 -35.569790 -33.625927 -33.024925 -33.598068 -33.984474        NaN   \n",
       "\n",
       "             214        215  \n",
       "0     -40.714092 -41.788750  \n",
       "1     -60.509026 -61.649410  \n",
       "2     -63.208103 -60.739964  \n",
       "3     -63.798618 -63.813591  \n",
       "4     -65.984756 -65.984756  \n",
       "...          ...        ...  \n",
       "29675        NaN        NaN  \n",
       "29676        NaN        NaN  \n",
       "29677        NaN        NaN  \n",
       "29678        NaN        NaN  \n",
       "29679        NaN        NaN  \n",
       "\n",
       "[29680 rows x 216 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se crea la copia \"df2\" del DataFrame de pandas (df) separando individualmente los resultados de la columna \"feature\":\n",
    "df2 = pd.DataFrame(df['feature'].values.tolist())\n",
    "df2[:29680]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-42.579998</td>\n",
       "      <td>-42.401058</td>\n",
       "      <td>-42.634708</td>\n",
       "      <td>-41.658806</td>\n",
       "      <td>-40.756615</td>\n",
       "      <td>-42.452438</td>\n",
       "      <td>-41.612186</td>\n",
       "      <td>-38.970215</td>\n",
       "      <td>-39.890053</td>\n",
       "      <td>-39.281651</td>\n",
       "      <td>...</td>\n",
       "      <td>-40.616489</td>\n",
       "      <td>-42.433720</td>\n",
       "      <td>-41.344578</td>\n",
       "      <td>-40.626751</td>\n",
       "      <td>-40.155827</td>\n",
       "      <td>-39.448544</td>\n",
       "      <td>-42.672073</td>\n",
       "      <td>-40.714092</td>\n",
       "      <td>-41.788750</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-63.037418</td>\n",
       "      <td>-65.005829</td>\n",
       "      <td>-66.669830</td>\n",
       "      <td>-67.287453</td>\n",
       "      <td>-68.558067</td>\n",
       "      <td>-67.600204</td>\n",
       "      <td>-64.373993</td>\n",
       "      <td>-65.265434</td>\n",
       "      <td>-66.569328</td>\n",
       "      <td>-66.525711</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.664814</td>\n",
       "      <td>-65.102875</td>\n",
       "      <td>-64.612320</td>\n",
       "      <td>-63.308891</td>\n",
       "      <td>-63.294292</td>\n",
       "      <td>-63.697121</td>\n",
       "      <td>-61.154915</td>\n",
       "      <td>-60.509026</td>\n",
       "      <td>-61.649410</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-63.646198</td>\n",
       "      <td>-65.425003</td>\n",
       "      <td>-66.405075</td>\n",
       "      <td>-66.332993</td>\n",
       "      <td>-66.921745</td>\n",
       "      <td>-65.886627</td>\n",
       "      <td>-65.463516</td>\n",
       "      <td>-66.057571</td>\n",
       "      <td>-64.519768</td>\n",
       "      <td>-65.093704</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.265034</td>\n",
       "      <td>-64.428879</td>\n",
       "      <td>-65.732025</td>\n",
       "      <td>-64.407623</td>\n",
       "      <td>-64.002449</td>\n",
       "      <td>-62.538998</td>\n",
       "      <td>-62.779709</td>\n",
       "      <td>-63.208103</td>\n",
       "      <td>-60.739964</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>-65.921593</td>\n",
       "      <td>...</td>\n",
       "      <td>-60.150635</td>\n",
       "      <td>-61.763290</td>\n",
       "      <td>-60.687485</td>\n",
       "      <td>-56.944359</td>\n",
       "      <td>-56.765747</td>\n",
       "      <td>-60.142361</td>\n",
       "      <td>-61.449783</td>\n",
       "      <td>-63.798618</td>\n",
       "      <td>-63.813591</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-61.614525</td>\n",
       "      <td>-57.218075</td>\n",
       "      <td>-53.918259</td>\n",
       "      <td>-55.536621</td>\n",
       "      <td>-56.447006</td>\n",
       "      <td>-55.554886</td>\n",
       "      <td>-55.437729</td>\n",
       "      <td>-56.230534</td>\n",
       "      <td>-56.135986</td>\n",
       "      <td>-56.615444</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>-65.984756</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>-14.182665</td>\n",
       "      <td>-17.613264</td>\n",
       "      <td>-26.834442</td>\n",
       "      <td>-28.915443</td>\n",
       "      <td>-28.501810</td>\n",
       "      <td>-27.867954</td>\n",
       "      <td>-27.804068</td>\n",
       "      <td>-29.921848</td>\n",
       "      <td>-29.119289</td>\n",
       "      <td>-27.622171</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29676</th>\n",
       "      <td>-36.544380</td>\n",
       "      <td>-34.601017</td>\n",
       "      <td>-36.042221</td>\n",
       "      <td>-31.059767</td>\n",
       "      <td>-23.514446</td>\n",
       "      <td>-19.393410</td>\n",
       "      <td>-18.620173</td>\n",
       "      <td>-18.691460</td>\n",
       "      <td>-18.765795</td>\n",
       "      <td>-18.849939</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29677</th>\n",
       "      <td>-20.612898</td>\n",
       "      <td>-19.055407</td>\n",
       "      <td>-19.209393</td>\n",
       "      <td>-18.695263</td>\n",
       "      <td>-16.728975</td>\n",
       "      <td>-15.619523</td>\n",
       "      <td>-17.330921</td>\n",
       "      <td>-19.615959</td>\n",
       "      <td>-20.122488</td>\n",
       "      <td>-24.445810</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29678</th>\n",
       "      <td>-16.877892</td>\n",
       "      <td>-21.438084</td>\n",
       "      <td>-30.812662</td>\n",
       "      <td>-29.866575</td>\n",
       "      <td>-28.868805</td>\n",
       "      <td>-26.216677</td>\n",
       "      <td>-23.669178</td>\n",
       "      <td>-23.294621</td>\n",
       "      <td>-23.804501</td>\n",
       "      <td>-24.265003</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29679</th>\n",
       "      <td>-20.721703</td>\n",
       "      <td>-19.064161</td>\n",
       "      <td>-19.507662</td>\n",
       "      <td>-20.963888</td>\n",
       "      <td>-22.484184</td>\n",
       "      <td>-23.754040</td>\n",
       "      <td>-25.131126</td>\n",
       "      <td>-23.629902</td>\n",
       "      <td>-24.390230</td>\n",
       "      <td>-26.116478</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.639587</td>\n",
       "      <td>-35.569790</td>\n",
       "      <td>-33.625927</td>\n",
       "      <td>-33.024925</td>\n",
       "      <td>-33.598068</td>\n",
       "      <td>-33.984474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29680 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3          4          5  \\\n",
       "0     -42.579998 -42.401058 -42.634708 -41.658806 -40.756615 -42.452438   \n",
       "1     -63.037418 -65.005829 -66.669830 -67.287453 -68.558067 -67.600204   \n",
       "2     -63.646198 -65.425003 -66.405075 -66.332993 -66.921745 -65.886627   \n",
       "3     -65.921593 -65.921593 -65.921593 -65.921593 -65.921593 -65.921593   \n",
       "4     -61.614525 -57.218075 -53.918259 -55.536621 -56.447006 -55.554886   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "29675 -14.182665 -17.613264 -26.834442 -28.915443 -28.501810 -27.867954   \n",
       "29676 -36.544380 -34.601017 -36.042221 -31.059767 -23.514446 -19.393410   \n",
       "29677 -20.612898 -19.055407 -19.209393 -18.695263 -16.728975 -15.619523   \n",
       "29678 -16.877892 -21.438084 -30.812662 -29.866575 -28.868805 -26.216677   \n",
       "29679 -20.721703 -19.064161 -19.507662 -20.963888 -22.484184 -23.754040   \n",
       "\n",
       "               6          7          8          9  ...        207        208  \\\n",
       "0     -41.612186 -38.970215 -39.890053 -39.281651  ... -40.616489 -42.433720   \n",
       "1     -64.373993 -65.265434 -66.569328 -66.525711  ... -61.664814 -65.102875   \n",
       "2     -65.463516 -66.057571 -64.519768 -65.093704  ... -62.265034 -64.428879   \n",
       "3     -65.921593 -65.921593 -65.921593 -65.921593  ... -60.150635 -61.763290   \n",
       "4     -55.437729 -56.230534 -56.135986 -56.615444  ... -65.984756 -65.984756   \n",
       "...          ...        ...        ...        ...  ...        ...        ...   \n",
       "29675 -27.804068 -29.921848 -29.119289 -27.622171  ...        NaN        NaN   \n",
       "29676 -18.620173 -18.691460 -18.765795 -18.849939  ...        NaN        NaN   \n",
       "29677 -17.330921 -19.615959 -20.122488 -24.445810  ...        NaN        NaN   \n",
       "29678 -23.669178 -23.294621 -23.804501 -24.265003  ...        NaN        NaN   \n",
       "29679 -25.131126 -23.629902 -24.390230 -26.116478  ... -35.639587 -35.569790   \n",
       "\n",
       "             209        210        211        212        213        214  \\\n",
       "0     -41.344578 -40.626751 -40.155827 -39.448544 -42.672073 -40.714092   \n",
       "1     -64.612320 -63.308891 -63.294292 -63.697121 -61.154915 -60.509026   \n",
       "2     -65.732025 -64.407623 -64.002449 -62.538998 -62.779709 -63.208103   \n",
       "3     -60.687485 -56.944359 -56.765747 -60.142361 -61.449783 -63.798618   \n",
       "4     -65.984756 -65.984756 -65.984756 -65.984756 -65.984756 -65.984756   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "29675        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "29676        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "29677        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "29678        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "29679 -33.625927 -33.024925 -33.598068 -33.984474        NaN        NaN   \n",
       "\n",
       "             215      Emotions  \n",
       "0     -41.788750  male_neutral  \n",
       "1     -61.649410  male_neutral  \n",
       "2     -60.739964  male_neutral  \n",
       "3     -63.813591  male_neutral  \n",
       "4     -65.984756  male_neutral  \n",
       "...          ...           ...  \n",
       "29675        NaN    female_sad  \n",
       "29676        NaN    female_sad  \n",
       "29677        NaN    female_sad  \n",
       "29678        NaN    female_sad  \n",
       "29679        NaN    female_sad  \n",
       "\n",
       "[29680 rows x 217 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se crea un nuevo dataframe \"Newdf\" y se concatena el \"df2\" y el \"labels\":\n",
    "newdf = pd.concat([df2,labelss], axis=1)\n",
    "newdf[:29680]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24520</th>\n",
       "      <td>-16.411951</td>\n",
       "      <td>-19.116829</td>\n",
       "      <td>-28.031155</td>\n",
       "      <td>-27.195835</td>\n",
       "      <td>-27.127241</td>\n",
       "      <td>-27.576952</td>\n",
       "      <td>-26.551523</td>\n",
       "      <td>-25.633757</td>\n",
       "      <td>-26.603895</td>\n",
       "      <td>-25.137882</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20559</th>\n",
       "      <td>-16.377066</td>\n",
       "      <td>-18.169479</td>\n",
       "      <td>-22.099112</td>\n",
       "      <td>-27.042805</td>\n",
       "      <td>-31.882229</td>\n",
       "      <td>-33.745686</td>\n",
       "      <td>-31.700460</td>\n",
       "      <td>-31.396297</td>\n",
       "      <td>-28.736111</td>\n",
       "      <td>-25.150572</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18754</th>\n",
       "      <td>-24.331573</td>\n",
       "      <td>-27.110615</td>\n",
       "      <td>-35.281734</td>\n",
       "      <td>-34.395992</td>\n",
       "      <td>-31.884712</td>\n",
       "      <td>-32.053989</td>\n",
       "      <td>-34.160107</td>\n",
       "      <td>-34.139870</td>\n",
       "      <td>-34.814579</td>\n",
       "      <td>-36.033321</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29527</th>\n",
       "      <td>-27.163368</td>\n",
       "      <td>-28.325182</td>\n",
       "      <td>-31.084551</td>\n",
       "      <td>-31.556446</td>\n",
       "      <td>-31.624052</td>\n",
       "      <td>-30.453524</td>\n",
       "      <td>-30.214128</td>\n",
       "      <td>-30.847429</td>\n",
       "      <td>-29.933256</td>\n",
       "      <td>-30.639559</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>-26.203215</td>\n",
       "      <td>-28.019428</td>\n",
       "      <td>-32.759373</td>\n",
       "      <td>-33.591320</td>\n",
       "      <td>-33.043633</td>\n",
       "      <td>-32.256271</td>\n",
       "      <td>-32.055485</td>\n",
       "      <td>-31.193621</td>\n",
       "      <td>-31.903032</td>\n",
       "      <td>-33.234241</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15950</th>\n",
       "      <td>-17.551826</td>\n",
       "      <td>-18.759905</td>\n",
       "      <td>-23.453548</td>\n",
       "      <td>-24.512520</td>\n",
       "      <td>-23.579237</td>\n",
       "      <td>-22.154610</td>\n",
       "      <td>-23.014402</td>\n",
       "      <td>-24.559498</td>\n",
       "      <td>-24.896383</td>\n",
       "      <td>-25.369307</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16075</th>\n",
       "      <td>-13.202082</td>\n",
       "      <td>-17.642233</td>\n",
       "      <td>-30.207256</td>\n",
       "      <td>-30.159901</td>\n",
       "      <td>-30.258949</td>\n",
       "      <td>-32.175896</td>\n",
       "      <td>-32.549263</td>\n",
       "      <td>-30.332821</td>\n",
       "      <td>-29.921741</td>\n",
       "      <td>-28.735159</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.646793</td>\n",
       "      <td>-27.645739</td>\n",
       "      <td>-28.799168</td>\n",
       "      <td>-28.166622</td>\n",
       "      <td>-27.124346</td>\n",
       "      <td>-22.878021</td>\n",
       "      <td>-19.233665</td>\n",
       "      <td>-21.655403</td>\n",
       "      <td>-28.529062</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9370</th>\n",
       "      <td>-62.494873</td>\n",
       "      <td>-65.332138</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.659279</td>\n",
       "      <td>-66.693207</td>\n",
       "      <td>-63.192284</td>\n",
       "      <td>-59.579689</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.374203</td>\n",
       "      <td>-60.116817</td>\n",
       "      <td>-60.202209</td>\n",
       "      <td>-58.259033</td>\n",
       "      <td>-59.252151</td>\n",
       "      <td>-60.162540</td>\n",
       "      <td>-58.262691</td>\n",
       "      <td>-56.665581</td>\n",
       "      <td>-58.837490</td>\n",
       "      <td>male_surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22583</th>\n",
       "      <td>-13.671846</td>\n",
       "      <td>-17.463348</td>\n",
       "      <td>-34.279453</td>\n",
       "      <td>-35.502281</td>\n",
       "      <td>-36.550846</td>\n",
       "      <td>-37.397804</td>\n",
       "      <td>-36.889462</td>\n",
       "      <td>-36.537369</td>\n",
       "      <td>-37.006874</td>\n",
       "      <td>-38.082981</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29680 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3          4          5  \\\n",
       "24520 -16.411951 -19.116829 -28.031155 -27.195835 -27.127241 -27.576952   \n",
       "20559 -16.377066 -18.169479 -22.099112 -27.042805 -31.882229 -33.745686   \n",
       "18754 -24.331573 -27.110615 -35.281734 -34.395992 -31.884712 -32.053989   \n",
       "29527 -27.163368 -28.325182 -31.084551 -31.556446 -31.624052 -30.453524   \n",
       "12118 -26.203215 -28.019428 -32.759373 -33.591320 -33.043633 -32.256271   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "15950 -17.551826 -18.759905 -23.453548 -24.512520 -23.579237 -22.154610   \n",
       "16075 -13.202082 -17.642233 -30.207256 -30.159901 -30.258949 -32.175896   \n",
       "5967  -38.679691 -38.679691 -38.679691 -38.679691 -38.679691 -38.679691   \n",
       "9370  -62.494873 -65.332138 -69.713181 -69.713181 -69.713181 -69.713181   \n",
       "22583 -13.671846 -17.463348 -34.279453 -35.502281 -36.550846 -37.397804   \n",
       "\n",
       "               6          7          8          9  ...        207        208  \\\n",
       "24520 -26.551523 -25.633757 -26.603895 -25.137882  ...        NaN        NaN   \n",
       "20559 -31.700460 -31.396297 -28.736111 -25.150572  ...        NaN        NaN   \n",
       "18754 -34.160107 -34.139870 -34.814579 -36.033321  ...        NaN        NaN   \n",
       "29527 -30.214128 -30.847429 -29.933256 -30.639559  ...        NaN        NaN   \n",
       "12118 -32.055485 -31.193621 -31.903032 -33.234241  ...        NaN        NaN   \n",
       "...          ...        ...        ...        ...  ...        ...        ...   \n",
       "15950 -23.014402 -24.559498 -24.896383 -25.369307  ...        NaN        NaN   \n",
       "16075 -32.549263 -30.332821 -29.921741 -28.735159  ...        NaN        NaN   \n",
       "5967  -38.679691 -38.679691 -38.679691 -38.679691  ... -30.646793 -27.645739   \n",
       "9370  -69.659279 -66.693207 -63.192284 -59.579689  ... -57.374203 -60.116817   \n",
       "22583 -36.889462 -36.537369 -37.006874 -38.082981  ...        NaN        NaN   \n",
       "\n",
       "             209        210        211        212        213        214  \\\n",
       "24520        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "20559        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "18754        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "29527        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "12118        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "15950        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "16075        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "5967  -28.799168 -28.166622 -27.124346 -22.878021 -19.233665 -21.655403   \n",
       "9370  -60.202209 -58.259033 -59.252151 -60.162540 -58.262691 -56.665581   \n",
       "22583        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "             215          Emotions  \n",
       "24520        NaN    female_neutral  \n",
       "20559        NaN        female_sad  \n",
       "18754        NaN      female_angry  \n",
       "29527        NaN        female_sad  \n",
       "12118        NaN    female_neutral  \n",
       "...          ...               ...  \n",
       "15950        NaN  female_surprised  \n",
       "16075        NaN    female_fearful  \n",
       "5967  -28.529062        male_angry  \n",
       "9370  -58.837490    male_surprised  \n",
       "22583        NaN    female_disgust  \n",
       "\n",
       "[29680 rows x 217 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se realiza una mezcla de todas las muestras aleatoriamente:\n",
    "rnewdf = shuffle(newdf)\n",
    "rnewdf[:29680]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24520</th>\n",
       "      <td>-16.411951</td>\n",
       "      <td>-19.116829</td>\n",
       "      <td>-28.031155</td>\n",
       "      <td>-27.195835</td>\n",
       "      <td>-27.127241</td>\n",
       "      <td>-27.576952</td>\n",
       "      <td>-26.551523</td>\n",
       "      <td>-25.633757</td>\n",
       "      <td>-26.603895</td>\n",
       "      <td>-25.137882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20559</th>\n",
       "      <td>-16.377066</td>\n",
       "      <td>-18.169479</td>\n",
       "      <td>-22.099112</td>\n",
       "      <td>-27.042805</td>\n",
       "      <td>-31.882229</td>\n",
       "      <td>-33.745686</td>\n",
       "      <td>-31.700460</td>\n",
       "      <td>-31.396297</td>\n",
       "      <td>-28.736111</td>\n",
       "      <td>-25.150572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18754</th>\n",
       "      <td>-24.331573</td>\n",
       "      <td>-27.110615</td>\n",
       "      <td>-35.281734</td>\n",
       "      <td>-34.395992</td>\n",
       "      <td>-31.884712</td>\n",
       "      <td>-32.053989</td>\n",
       "      <td>-34.160107</td>\n",
       "      <td>-34.139870</td>\n",
       "      <td>-34.814579</td>\n",
       "      <td>-36.033321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29527</th>\n",
       "      <td>-27.163368</td>\n",
       "      <td>-28.325182</td>\n",
       "      <td>-31.084551</td>\n",
       "      <td>-31.556446</td>\n",
       "      <td>-31.624052</td>\n",
       "      <td>-30.453524</td>\n",
       "      <td>-30.214128</td>\n",
       "      <td>-30.847429</td>\n",
       "      <td>-29.933256</td>\n",
       "      <td>-30.639559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>-26.203215</td>\n",
       "      <td>-28.019428</td>\n",
       "      <td>-32.759373</td>\n",
       "      <td>-33.591320</td>\n",
       "      <td>-33.043633</td>\n",
       "      <td>-32.256271</td>\n",
       "      <td>-32.055485</td>\n",
       "      <td>-31.193621</td>\n",
       "      <td>-31.903032</td>\n",
       "      <td>-33.234241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15950</th>\n",
       "      <td>-17.551826</td>\n",
       "      <td>-18.759905</td>\n",
       "      <td>-23.453548</td>\n",
       "      <td>-24.512520</td>\n",
       "      <td>-23.579237</td>\n",
       "      <td>-22.154610</td>\n",
       "      <td>-23.014402</td>\n",
       "      <td>-24.559498</td>\n",
       "      <td>-24.896383</td>\n",
       "      <td>-25.369307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16075</th>\n",
       "      <td>-13.202082</td>\n",
       "      <td>-17.642233</td>\n",
       "      <td>-30.207256</td>\n",
       "      <td>-30.159901</td>\n",
       "      <td>-30.258949</td>\n",
       "      <td>-32.175896</td>\n",
       "      <td>-32.549263</td>\n",
       "      <td>-30.332821</td>\n",
       "      <td>-29.921741</td>\n",
       "      <td>-28.735159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.646793</td>\n",
       "      <td>-27.645739</td>\n",
       "      <td>-28.799168</td>\n",
       "      <td>-28.166622</td>\n",
       "      <td>-27.124346</td>\n",
       "      <td>-22.878021</td>\n",
       "      <td>-19.233665</td>\n",
       "      <td>-21.655403</td>\n",
       "      <td>-28.529062</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9370</th>\n",
       "      <td>-62.494873</td>\n",
       "      <td>-65.332138</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.659279</td>\n",
       "      <td>-66.693207</td>\n",
       "      <td>-63.192284</td>\n",
       "      <td>-59.579689</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.374203</td>\n",
       "      <td>-60.116817</td>\n",
       "      <td>-60.202209</td>\n",
       "      <td>-58.259033</td>\n",
       "      <td>-59.252151</td>\n",
       "      <td>-60.162540</td>\n",
       "      <td>-58.262691</td>\n",
       "      <td>-56.665581</td>\n",
       "      <td>-58.837490</td>\n",
       "      <td>male_surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22583</th>\n",
       "      <td>-13.671846</td>\n",
       "      <td>-17.463348</td>\n",
       "      <td>-34.279453</td>\n",
       "      <td>-35.502281</td>\n",
       "      <td>-36.550846</td>\n",
       "      <td>-37.397804</td>\n",
       "      <td>-36.889462</td>\n",
       "      <td>-36.537369</td>\n",
       "      <td>-37.006874</td>\n",
       "      <td>-38.082981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29680 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3          4          5  \\\n",
       "24520 -16.411951 -19.116829 -28.031155 -27.195835 -27.127241 -27.576952   \n",
       "20559 -16.377066 -18.169479 -22.099112 -27.042805 -31.882229 -33.745686   \n",
       "18754 -24.331573 -27.110615 -35.281734 -34.395992 -31.884712 -32.053989   \n",
       "29527 -27.163368 -28.325182 -31.084551 -31.556446 -31.624052 -30.453524   \n",
       "12118 -26.203215 -28.019428 -32.759373 -33.591320 -33.043633 -32.256271   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "15950 -17.551826 -18.759905 -23.453548 -24.512520 -23.579237 -22.154610   \n",
       "16075 -13.202082 -17.642233 -30.207256 -30.159901 -30.258949 -32.175896   \n",
       "5967  -38.679691 -38.679691 -38.679691 -38.679691 -38.679691 -38.679691   \n",
       "9370  -62.494873 -65.332138 -69.713181 -69.713181 -69.713181 -69.713181   \n",
       "22583 -13.671846 -17.463348 -34.279453 -35.502281 -36.550846 -37.397804   \n",
       "\n",
       "               6          7          8          9  ...        207        208  \\\n",
       "24520 -26.551523 -25.633757 -26.603895 -25.137882  ...   0.000000   0.000000   \n",
       "20559 -31.700460 -31.396297 -28.736111 -25.150572  ...   0.000000   0.000000   \n",
       "18754 -34.160107 -34.139870 -34.814579 -36.033321  ...   0.000000   0.000000   \n",
       "29527 -30.214128 -30.847429 -29.933256 -30.639559  ...   0.000000   0.000000   \n",
       "12118 -32.055485 -31.193621 -31.903032 -33.234241  ...   0.000000   0.000000   \n",
       "...          ...        ...        ...        ...  ...        ...        ...   \n",
       "15950 -23.014402 -24.559498 -24.896383 -25.369307  ...   0.000000   0.000000   \n",
       "16075 -32.549263 -30.332821 -29.921741 -28.735159  ...   0.000000   0.000000   \n",
       "5967  -38.679691 -38.679691 -38.679691 -38.679691  ... -30.646793 -27.645739   \n",
       "9370  -69.659279 -66.693207 -63.192284 -59.579689  ... -57.374203 -60.116817   \n",
       "22583 -36.889462 -36.537369 -37.006874 -38.082981  ...   0.000000   0.000000   \n",
       "\n",
       "             209        210        211        212        213        214  \\\n",
       "24520   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "20559   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "18754   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "29527   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "12118   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "15950   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "16075   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "5967  -28.799168 -28.166622 -27.124346 -22.878021 -19.233665 -21.655403   \n",
       "9370  -60.202209 -58.259033 -59.252151 -60.162540 -58.262691 -56.665581   \n",
       "22583   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "             215          Emotions  \n",
       "24520   0.000000    female_neutral  \n",
       "20559   0.000000        female_sad  \n",
       "18754   0.000000      female_angry  \n",
       "29527   0.000000        female_sad  \n",
       "12118   0.000000    female_neutral  \n",
       "...          ...               ...  \n",
       "15950   0.000000  female_surprised  \n",
       "16075   0.000000    female_fearful  \n",
       "5967  -28.529062        male_angry  \n",
       "9370  -58.837490    male_surprised  \n",
       "22583   0.000000    female_disgust  \n",
       "\n",
       "[29680 rows x 217 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se rellenan todos los valores nulos (NaN) del DataFrame \"rnewdf\" con el valor 0:\n",
    "rnewdf=rnewdf.fillna(0)\n",
    "rnewdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División de los datos para test y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1 = np.random.rand(len(rnewdf)) < 0.8\n",
    "train = rnewdf[newdf1]\n",
    "test = rnewdf[~newdf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24520</th>\n",
       "      <td>-16.411951</td>\n",
       "      <td>-19.116829</td>\n",
       "      <td>-28.031155</td>\n",
       "      <td>-27.195835</td>\n",
       "      <td>-27.127241</td>\n",
       "      <td>-27.576952</td>\n",
       "      <td>-26.551523</td>\n",
       "      <td>-25.633757</td>\n",
       "      <td>-26.603895</td>\n",
       "      <td>-25.137882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20559</th>\n",
       "      <td>-16.377066</td>\n",
       "      <td>-18.169479</td>\n",
       "      <td>-22.099112</td>\n",
       "      <td>-27.042805</td>\n",
       "      <td>-31.882229</td>\n",
       "      <td>-33.745686</td>\n",
       "      <td>-31.700460</td>\n",
       "      <td>-31.396297</td>\n",
       "      <td>-28.736111</td>\n",
       "      <td>-25.150572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18754</th>\n",
       "      <td>-24.331573</td>\n",
       "      <td>-27.110615</td>\n",
       "      <td>-35.281734</td>\n",
       "      <td>-34.395992</td>\n",
       "      <td>-31.884712</td>\n",
       "      <td>-32.053989</td>\n",
       "      <td>-34.160107</td>\n",
       "      <td>-34.139870</td>\n",
       "      <td>-34.814579</td>\n",
       "      <td>-36.033321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29527</th>\n",
       "      <td>-27.163368</td>\n",
       "      <td>-28.325182</td>\n",
       "      <td>-31.084551</td>\n",
       "      <td>-31.556446</td>\n",
       "      <td>-31.624052</td>\n",
       "      <td>-30.453524</td>\n",
       "      <td>-30.214128</td>\n",
       "      <td>-30.847429</td>\n",
       "      <td>-29.933256</td>\n",
       "      <td>-30.639559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>-26.203215</td>\n",
       "      <td>-28.019428</td>\n",
       "      <td>-32.759373</td>\n",
       "      <td>-33.591320</td>\n",
       "      <td>-33.043633</td>\n",
       "      <td>-32.256271</td>\n",
       "      <td>-32.055485</td>\n",
       "      <td>-31.193621</td>\n",
       "      <td>-31.903032</td>\n",
       "      <td>-33.234241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15950</th>\n",
       "      <td>-17.551826</td>\n",
       "      <td>-18.759905</td>\n",
       "      <td>-23.453548</td>\n",
       "      <td>-24.512520</td>\n",
       "      <td>-23.579237</td>\n",
       "      <td>-22.154610</td>\n",
       "      <td>-23.014402</td>\n",
       "      <td>-24.559498</td>\n",
       "      <td>-24.896383</td>\n",
       "      <td>-25.369307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16075</th>\n",
       "      <td>-13.202082</td>\n",
       "      <td>-17.642233</td>\n",
       "      <td>-30.207256</td>\n",
       "      <td>-30.159901</td>\n",
       "      <td>-30.258949</td>\n",
       "      <td>-32.175896</td>\n",
       "      <td>-32.549263</td>\n",
       "      <td>-30.332821</td>\n",
       "      <td>-29.921741</td>\n",
       "      <td>-28.735159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.646793</td>\n",
       "      <td>-27.645739</td>\n",
       "      <td>-28.799168</td>\n",
       "      <td>-28.166622</td>\n",
       "      <td>-27.124346</td>\n",
       "      <td>-22.878021</td>\n",
       "      <td>-19.233665</td>\n",
       "      <td>-21.655403</td>\n",
       "      <td>-28.529062</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9370</th>\n",
       "      <td>-62.494873</td>\n",
       "      <td>-65.332138</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.659279</td>\n",
       "      <td>-66.693207</td>\n",
       "      <td>-63.192284</td>\n",
       "      <td>-59.579689</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.374203</td>\n",
       "      <td>-60.116817</td>\n",
       "      <td>-60.202209</td>\n",
       "      <td>-58.259033</td>\n",
       "      <td>-59.252151</td>\n",
       "      <td>-60.162540</td>\n",
       "      <td>-58.262691</td>\n",
       "      <td>-56.665581</td>\n",
       "      <td>-58.837490</td>\n",
       "      <td>male_surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22583</th>\n",
       "      <td>-13.671846</td>\n",
       "      <td>-17.463348</td>\n",
       "      <td>-34.279453</td>\n",
       "      <td>-35.502281</td>\n",
       "      <td>-36.550846</td>\n",
       "      <td>-37.397804</td>\n",
       "      <td>-36.889462</td>\n",
       "      <td>-36.537369</td>\n",
       "      <td>-37.006874</td>\n",
       "      <td>-38.082981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>female_disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23615 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3          4          5  \\\n",
       "24520 -16.411951 -19.116829 -28.031155 -27.195835 -27.127241 -27.576952   \n",
       "20559 -16.377066 -18.169479 -22.099112 -27.042805 -31.882229 -33.745686   \n",
       "18754 -24.331573 -27.110615 -35.281734 -34.395992 -31.884712 -32.053989   \n",
       "29527 -27.163368 -28.325182 -31.084551 -31.556446 -31.624052 -30.453524   \n",
       "12118 -26.203215 -28.019428 -32.759373 -33.591320 -33.043633 -32.256271   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "15950 -17.551826 -18.759905 -23.453548 -24.512520 -23.579237 -22.154610   \n",
       "16075 -13.202082 -17.642233 -30.207256 -30.159901 -30.258949 -32.175896   \n",
       "5967  -38.679691 -38.679691 -38.679691 -38.679691 -38.679691 -38.679691   \n",
       "9370  -62.494873 -65.332138 -69.713181 -69.713181 -69.713181 -69.713181   \n",
       "22583 -13.671846 -17.463348 -34.279453 -35.502281 -36.550846 -37.397804   \n",
       "\n",
       "               6          7          8          9  ...        207        208  \\\n",
       "24520 -26.551523 -25.633757 -26.603895 -25.137882  ...   0.000000   0.000000   \n",
       "20559 -31.700460 -31.396297 -28.736111 -25.150572  ...   0.000000   0.000000   \n",
       "18754 -34.160107 -34.139870 -34.814579 -36.033321  ...   0.000000   0.000000   \n",
       "29527 -30.214128 -30.847429 -29.933256 -30.639559  ...   0.000000   0.000000   \n",
       "12118 -32.055485 -31.193621 -31.903032 -33.234241  ...   0.000000   0.000000   \n",
       "...          ...        ...        ...        ...  ...        ...        ...   \n",
       "15950 -23.014402 -24.559498 -24.896383 -25.369307  ...   0.000000   0.000000   \n",
       "16075 -32.549263 -30.332821 -29.921741 -28.735159  ...   0.000000   0.000000   \n",
       "5967  -38.679691 -38.679691 -38.679691 -38.679691  ... -30.646793 -27.645739   \n",
       "9370  -69.659279 -66.693207 -63.192284 -59.579689  ... -57.374203 -60.116817   \n",
       "22583 -36.889462 -36.537369 -37.006874 -38.082981  ...   0.000000   0.000000   \n",
       "\n",
       "             209        210        211        212        213        214  \\\n",
       "24520   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "20559   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "18754   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "29527   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "12118   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "15950   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "16075   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "5967  -28.799168 -28.166622 -27.124346 -22.878021 -19.233665 -21.655403   \n",
       "9370  -60.202209 -58.259033 -59.252151 -60.162540 -58.262691 -56.665581   \n",
       "22583   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "             215          Emotions  \n",
       "24520   0.000000    female_neutral  \n",
       "20559   0.000000        female_sad  \n",
       "18754   0.000000      female_angry  \n",
       "29527   0.000000        female_sad  \n",
       "12118   0.000000    female_neutral  \n",
       "...          ...               ...  \n",
       "15950   0.000000  female_surprised  \n",
       "16075   0.000000    female_fearful  \n",
       "5967  -28.529062        male_angry  \n",
       "9370  -58.837490    male_surprised  \n",
       "22583   0.000000    female_disgust  \n",
       "\n",
       "[23615 rows x 217 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0:23804]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24520</th>\n",
       "      <td>-16.411951</td>\n",
       "      <td>-19.116829</td>\n",
       "      <td>-28.031155</td>\n",
       "      <td>-27.195835</td>\n",
       "      <td>-27.127241</td>\n",
       "      <td>-27.576952</td>\n",
       "      <td>-26.551523</td>\n",
       "      <td>-25.633757</td>\n",
       "      <td>-26.603895</td>\n",
       "      <td>-25.137882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20559</th>\n",
       "      <td>-16.377066</td>\n",
       "      <td>-18.169479</td>\n",
       "      <td>-22.099112</td>\n",
       "      <td>-27.042805</td>\n",
       "      <td>-31.882229</td>\n",
       "      <td>-33.745686</td>\n",
       "      <td>-31.700460</td>\n",
       "      <td>-31.396297</td>\n",
       "      <td>-28.736111</td>\n",
       "      <td>-25.150572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18754</th>\n",
       "      <td>-24.331573</td>\n",
       "      <td>-27.110615</td>\n",
       "      <td>-35.281734</td>\n",
       "      <td>-34.395992</td>\n",
       "      <td>-31.884712</td>\n",
       "      <td>-32.053989</td>\n",
       "      <td>-34.160107</td>\n",
       "      <td>-34.139870</td>\n",
       "      <td>-34.814579</td>\n",
       "      <td>-36.033321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29527</th>\n",
       "      <td>-27.163368</td>\n",
       "      <td>-28.325182</td>\n",
       "      <td>-31.084551</td>\n",
       "      <td>-31.556446</td>\n",
       "      <td>-31.624052</td>\n",
       "      <td>-30.453524</td>\n",
       "      <td>-30.214128</td>\n",
       "      <td>-30.847429</td>\n",
       "      <td>-29.933256</td>\n",
       "      <td>-30.639559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>-26.203215</td>\n",
       "      <td>-28.019428</td>\n",
       "      <td>-32.759373</td>\n",
       "      <td>-33.591320</td>\n",
       "      <td>-33.043633</td>\n",
       "      <td>-32.256271</td>\n",
       "      <td>-32.055485</td>\n",
       "      <td>-31.193621</td>\n",
       "      <td>-31.903032</td>\n",
       "      <td>-33.234241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15950</th>\n",
       "      <td>-17.551826</td>\n",
       "      <td>-18.759905</td>\n",
       "      <td>-23.453548</td>\n",
       "      <td>-24.512520</td>\n",
       "      <td>-23.579237</td>\n",
       "      <td>-22.154610</td>\n",
       "      <td>-23.014402</td>\n",
       "      <td>-24.559498</td>\n",
       "      <td>-24.896383</td>\n",
       "      <td>-25.369307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16075</th>\n",
       "      <td>-13.202082</td>\n",
       "      <td>-17.642233</td>\n",
       "      <td>-30.207256</td>\n",
       "      <td>-30.159901</td>\n",
       "      <td>-30.258949</td>\n",
       "      <td>-32.175896</td>\n",
       "      <td>-32.549263</td>\n",
       "      <td>-30.332821</td>\n",
       "      <td>-29.921741</td>\n",
       "      <td>-28.735159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>-38.679691</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.928692</td>\n",
       "      <td>-30.646793</td>\n",
       "      <td>-27.645739</td>\n",
       "      <td>-28.799168</td>\n",
       "      <td>-28.166622</td>\n",
       "      <td>-27.124346</td>\n",
       "      <td>-22.878021</td>\n",
       "      <td>-19.233665</td>\n",
       "      <td>-21.655403</td>\n",
       "      <td>-28.529062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9370</th>\n",
       "      <td>-62.494873</td>\n",
       "      <td>-65.332138</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.713181</td>\n",
       "      <td>-69.659279</td>\n",
       "      <td>-66.693207</td>\n",
       "      <td>-63.192284</td>\n",
       "      <td>-59.579689</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.442131</td>\n",
       "      <td>-57.374203</td>\n",
       "      <td>-60.116817</td>\n",
       "      <td>-60.202209</td>\n",
       "      <td>-58.259033</td>\n",
       "      <td>-59.252151</td>\n",
       "      <td>-60.162540</td>\n",
       "      <td>-58.262691</td>\n",
       "      <td>-56.665581</td>\n",
       "      <td>-58.837490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22583</th>\n",
       "      <td>-13.671846</td>\n",
       "      <td>-17.463348</td>\n",
       "      <td>-34.279453</td>\n",
       "      <td>-35.502281</td>\n",
       "      <td>-36.550846</td>\n",
       "      <td>-37.397804</td>\n",
       "      <td>-36.889462</td>\n",
       "      <td>-36.537369</td>\n",
       "      <td>-37.006874</td>\n",
       "      <td>-38.082981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23615 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5    \\\n",
       "24520 -16.411951 -19.116829 -28.031155 -27.195835 -27.127241 -27.576952   \n",
       "20559 -16.377066 -18.169479 -22.099112 -27.042805 -31.882229 -33.745686   \n",
       "18754 -24.331573 -27.110615 -35.281734 -34.395992 -31.884712 -32.053989   \n",
       "29527 -27.163368 -28.325182 -31.084551 -31.556446 -31.624052 -30.453524   \n",
       "12118 -26.203215 -28.019428 -32.759373 -33.591320 -33.043633 -32.256271   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "15950 -17.551826 -18.759905 -23.453548 -24.512520 -23.579237 -22.154610   \n",
       "16075 -13.202082 -17.642233 -30.207256 -30.159901 -30.258949 -32.175896   \n",
       "5967  -38.679691 -38.679691 -38.679691 -38.679691 -38.679691 -38.679691   \n",
       "9370  -62.494873 -65.332138 -69.713181 -69.713181 -69.713181 -69.713181   \n",
       "22583 -13.671846 -17.463348 -34.279453 -35.502281 -36.550846 -37.397804   \n",
       "\n",
       "             6          7          8          9    ...        206        207  \\\n",
       "24520 -26.551523 -25.633757 -26.603895 -25.137882  ...   0.000000   0.000000   \n",
       "20559 -31.700460 -31.396297 -28.736111 -25.150572  ...   0.000000   0.000000   \n",
       "18754 -34.160107 -34.139870 -34.814579 -36.033321  ...   0.000000   0.000000   \n",
       "29527 -30.214128 -30.847429 -29.933256 -30.639559  ...   0.000000   0.000000   \n",
       "12118 -32.055485 -31.193621 -31.903032 -33.234241  ...   0.000000   0.000000   \n",
       "...          ...        ...        ...        ...  ...        ...        ...   \n",
       "15950 -23.014402 -24.559498 -24.896383 -25.369307  ...   0.000000   0.000000   \n",
       "16075 -32.549263 -30.332821 -29.921741 -28.735159  ...   0.000000   0.000000   \n",
       "5967  -38.679691 -38.679691 -38.679691 -38.679691  ... -30.928692 -30.646793   \n",
       "9370  -69.659279 -66.693207 -63.192284 -59.579689  ... -56.442131 -57.374203   \n",
       "22583 -36.889462 -36.537369 -37.006874 -38.082981  ...   0.000000   0.000000   \n",
       "\n",
       "             208        209        210        211        212        213  \\\n",
       "24520   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "20559   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "18754   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "29527   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "12118   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "15950   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "16075   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "5967  -27.645739 -28.799168 -28.166622 -27.124346 -22.878021 -19.233665   \n",
       "9370  -60.116817 -60.202209 -58.259033 -59.252151 -60.162540 -58.262691   \n",
       "22583   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "             214        215  \n",
       "24520   0.000000   0.000000  \n",
       "20559   0.000000   0.000000  \n",
       "18754   0.000000   0.000000  \n",
       "29527   0.000000   0.000000  \n",
       "12118   0.000000   0.000000  \n",
       "...          ...        ...  \n",
       "15950   0.000000   0.000000  \n",
       "16075   0.000000   0.000000  \n",
       "5967  -21.655403 -28.529062  \n",
       "9370  -56.665581 -58.837490  \n",
       "22583   0.000000   0.000000  \n",
       "\n",
       "[23615 rows x 216 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se retira la columna \"Emotions\" para entrenar los datos métricos independientemente:\n",
    "trainfeatures = train.iloc[:, :-1]\n",
    "trainfeatures[:23804]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24520</th>\n",
       "      <td>female_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20559</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18754</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29527</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>female_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15950</th>\n",
       "      <td>female_surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16075</th>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9370</th>\n",
       "      <td>male_surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22583</th>\n",
       "      <td>female_disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23615 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Emotions\n",
       "24520    female_neutral\n",
       "20559        female_sad\n",
       "18754      female_angry\n",
       "29527        female_sad\n",
       "12118    female_neutral\n",
       "...                 ...\n",
       "15950  female_surprised\n",
       "16075    female_fearful\n",
       "5967         male_angry\n",
       "9370     male_surprised\n",
       "22583    female_disgust\n",
       "\n",
       "[23615 rows x 1 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se separa la columna \"Emotions\" respectivamente:\n",
    "trainlabel = train.iloc[:, -1:]\n",
    "trainlabel[:23804]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11353</th>\n",
       "      <td>-32.278847</td>\n",
       "      <td>-31.038212</td>\n",
       "      <td>-30.057852</td>\n",
       "      <td>-31.106361</td>\n",
       "      <td>-32.056831</td>\n",
       "      <td>-32.648155</td>\n",
       "      <td>-33.318432</td>\n",
       "      <td>-33.535328</td>\n",
       "      <td>-33.211380</td>\n",
       "      <td>-33.567326</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.799997</td>\n",
       "      <td>-19.680218</td>\n",
       "      <td>-19.471479</td>\n",
       "      <td>-17.847542</td>\n",
       "      <td>-17.750099</td>\n",
       "      <td>-19.108231</td>\n",
       "      <td>-21.121490</td>\n",
       "      <td>-18.144770</td>\n",
       "      <td>-19.312809</td>\n",
       "      <td>-23.176056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11560</th>\n",
       "      <td>-29.502359</td>\n",
       "      <td>-26.698360</td>\n",
       "      <td>-27.915680</td>\n",
       "      <td>-27.179207</td>\n",
       "      <td>-23.408674</td>\n",
       "      <td>-15.322147</td>\n",
       "      <td>-14.682059</td>\n",
       "      <td>-16.942106</td>\n",
       "      <td>-20.528883</td>\n",
       "      <td>-21.470936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>-59.379234</td>\n",
       "      <td>-56.715298</td>\n",
       "      <td>-55.581871</td>\n",
       "      <td>-54.006161</td>\n",
       "      <td>-55.326309</td>\n",
       "      <td>-56.387470</td>\n",
       "      <td>-55.373562</td>\n",
       "      <td>-55.056889</td>\n",
       "      <td>-54.322975</td>\n",
       "      <td>-53.788284</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.100754</td>\n",
       "      <td>-58.241211</td>\n",
       "      <td>-58.005173</td>\n",
       "      <td>-58.161888</td>\n",
       "      <td>-58.175434</td>\n",
       "      <td>-58.245380</td>\n",
       "      <td>-58.169331</td>\n",
       "      <td>-58.132809</td>\n",
       "      <td>-58.220261</td>\n",
       "      <td>-58.108589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>-63.678261</td>\n",
       "      <td>-65.519722</td>\n",
       "      <td>-68.038109</td>\n",
       "      <td>-68.940498</td>\n",
       "      <td>-68.680038</td>\n",
       "      <td>-66.777290</td>\n",
       "      <td>-65.900421</td>\n",
       "      <td>-64.412834</td>\n",
       "      <td>-66.014778</td>\n",
       "      <td>-65.932915</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.143311</td>\n",
       "      <td>-50.431767</td>\n",
       "      <td>-51.595406</td>\n",
       "      <td>-50.232361</td>\n",
       "      <td>-51.723759</td>\n",
       "      <td>-52.557041</td>\n",
       "      <td>-50.826725</td>\n",
       "      <td>-50.555283</td>\n",
       "      <td>-53.217522</td>\n",
       "      <td>-55.987209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>-62.309334</td>\n",
       "      <td>-64.163918</td>\n",
       "      <td>-64.846329</td>\n",
       "      <td>-64.792992</td>\n",
       "      <td>-64.817886</td>\n",
       "      <td>-64.831223</td>\n",
       "      <td>-64.848671</td>\n",
       "      <td>-64.701591</td>\n",
       "      <td>-64.793564</td>\n",
       "      <td>-64.359352</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.157780</td>\n",
       "      <td>-57.370930</td>\n",
       "      <td>-59.771935</td>\n",
       "      <td>-59.867119</td>\n",
       "      <td>-60.586609</td>\n",
       "      <td>-61.340591</td>\n",
       "      <td>-62.275906</td>\n",
       "      <td>-62.124084</td>\n",
       "      <td>-61.474556</td>\n",
       "      <td>-61.143398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19882</th>\n",
       "      <td>-20.325174</td>\n",
       "      <td>-21.911461</td>\n",
       "      <td>-26.770912</td>\n",
       "      <td>-26.880039</td>\n",
       "      <td>-27.298449</td>\n",
       "      <td>-28.805305</td>\n",
       "      <td>-28.835733</td>\n",
       "      <td>-27.055288</td>\n",
       "      <td>-27.355394</td>\n",
       "      <td>-26.752920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21423</th>\n",
       "      <td>-13.232435</td>\n",
       "      <td>-18.184322</td>\n",
       "      <td>-31.162931</td>\n",
       "      <td>-30.990753</td>\n",
       "      <td>-30.680157</td>\n",
       "      <td>-31.863995</td>\n",
       "      <td>-31.496166</td>\n",
       "      <td>-32.610367</td>\n",
       "      <td>-33.688278</td>\n",
       "      <td>-32.240547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25510</th>\n",
       "      <td>-21.016701</td>\n",
       "      <td>-24.620790</td>\n",
       "      <td>-30.300270</td>\n",
       "      <td>-27.958160</td>\n",
       "      <td>-28.085400</td>\n",
       "      <td>-28.047678</td>\n",
       "      <td>-28.041433</td>\n",
       "      <td>-27.498676</td>\n",
       "      <td>-25.904726</td>\n",
       "      <td>-27.575533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>-63.427303</td>\n",
       "      <td>-63.291176</td>\n",
       "      <td>-63.123089</td>\n",
       "      <td>-66.918549</td>\n",
       "      <td>-67.395393</td>\n",
       "      <td>-67.395393</td>\n",
       "      <td>-67.395393</td>\n",
       "      <td>-67.395393</td>\n",
       "      <td>-67.395393</td>\n",
       "      <td>-67.395393</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.206619</td>\n",
       "      <td>-50.588913</td>\n",
       "      <td>-51.267067</td>\n",
       "      <td>-51.096684</td>\n",
       "      <td>-50.855949</td>\n",
       "      <td>-49.809875</td>\n",
       "      <td>-49.322372</td>\n",
       "      <td>-49.508469</td>\n",
       "      <td>-50.587925</td>\n",
       "      <td>-52.469891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>-41.243690</td>\n",
       "      <td>-41.243690</td>\n",
       "      <td>-40.826714</td>\n",
       "      <td>-40.698677</td>\n",
       "      <td>-40.974216</td>\n",
       "      <td>-40.673458</td>\n",
       "      <td>-41.243690</td>\n",
       "      <td>-41.222649</td>\n",
       "      <td>-41.243690</td>\n",
       "      <td>-41.186825</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.623799</td>\n",
       "      <td>-15.922980</td>\n",
       "      <td>-24.410744</td>\n",
       "      <td>-27.715078</td>\n",
       "      <td>-28.329803</td>\n",
       "      <td>-28.874979</td>\n",
       "      <td>-31.020367</td>\n",
       "      <td>-32.256454</td>\n",
       "      <td>-19.693718</td>\n",
       "      <td>-11.521231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5876 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5    \\\n",
       "11353 -32.278847 -31.038212 -30.057852 -31.106361 -32.056831 -32.648155   \n",
       "11560 -29.502359 -26.698360 -27.915680 -27.179207 -23.408674 -15.322147   \n",
       "3190  -59.379234 -56.715298 -55.581871 -54.006161 -55.326309 -56.387470   \n",
       "3740  -63.678261 -65.519722 -68.038109 -68.940498 -68.680038 -66.777290   \n",
       "3984  -62.309334 -64.163918 -64.846329 -64.792992 -64.817886 -64.831223   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "19882 -20.325174 -21.911461 -26.770912 -26.880039 -27.298449 -28.805305   \n",
       "21423 -13.232435 -18.184322 -31.162931 -30.990753 -30.680157 -31.863995   \n",
       "25510 -21.016701 -24.620790 -30.300270 -27.958160 -28.085400 -28.047678   \n",
       "4929  -63.427303 -63.291176 -63.123089 -66.918549 -67.395393 -67.395393   \n",
       "3258  -41.243690 -41.243690 -40.826714 -40.698677 -40.974216 -40.673458   \n",
       "\n",
       "             6          7          8          9    ...        206        207  \\\n",
       "11353 -33.318432 -33.535328 -33.211380 -33.567326  ... -19.799997 -19.680218   \n",
       "11560 -14.682059 -16.942106 -20.528883 -21.470936  ...   0.000000   0.000000   \n",
       "3190  -55.373562 -55.056889 -54.322975 -53.788284  ... -58.100754 -58.241211   \n",
       "3740  -65.900421 -64.412834 -66.014778 -65.932915  ... -51.143311 -50.431767   \n",
       "3984  -64.848671 -64.701591 -64.793564 -64.359352  ... -57.157780 -57.370930   \n",
       "...          ...        ...        ...        ...  ...        ...        ...   \n",
       "19882 -28.835733 -27.055288 -27.355394 -26.752920  ...   0.000000   0.000000   \n",
       "21423 -31.496166 -32.610367 -33.688278 -32.240547  ...   0.000000   0.000000   \n",
       "25510 -28.041433 -27.498676 -25.904726 -27.575533  ...   0.000000   0.000000   \n",
       "4929  -67.395393 -67.395393 -67.395393 -67.395393  ... -50.206619 -50.588913   \n",
       "3258  -41.243690 -41.222649 -41.243690 -41.186825  ... -13.623799 -15.922980   \n",
       "\n",
       "             208        209        210        211        212        213  \\\n",
       "11353 -19.471479 -17.847542 -17.750099 -19.108231 -21.121490 -18.144770   \n",
       "11560   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3190  -58.005173 -58.161888 -58.175434 -58.245380 -58.169331 -58.132809   \n",
       "3740  -51.595406 -50.232361 -51.723759 -52.557041 -50.826725 -50.555283   \n",
       "3984  -59.771935 -59.867119 -60.586609 -61.340591 -62.275906 -62.124084   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "19882   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "21423   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25510   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "4929  -51.267067 -51.096684 -50.855949 -49.809875 -49.322372 -49.508469   \n",
       "3258  -24.410744 -27.715078 -28.329803 -28.874979 -31.020367 -32.256454   \n",
       "\n",
       "             214        215  \n",
       "11353 -19.312809 -23.176056  \n",
       "11560   0.000000   0.000000  \n",
       "3190  -58.220261 -58.108589  \n",
       "3740  -53.217522 -55.987209  \n",
       "3984  -61.474556 -61.143398  \n",
       "...          ...        ...  \n",
       "19882   0.000000   0.000000  \n",
       "21423   0.000000   0.000000  \n",
       "25510   0.000000   0.000000  \n",
       "4929  -50.587925 -52.469891  \n",
       "3258  -19.693718 -11.521231  \n",
       "\n",
       "[5876 rows x 216 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se retira la columna \"Emotions\" para testear los datos métricos independientemente:\n",
    "testfeatures = test.iloc[:, :-1]\n",
    "testfeatures[:5876]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11353</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11560</th>\n",
       "      <td>female_disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19882</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21423</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25510</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5876 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Emotions\n",
       "11353      female_sad\n",
       "11560  female_disgust\n",
       "3190     female_happy\n",
       "3740         male_sad\n",
       "3984       female_sad\n",
       "...               ...\n",
       "19882    female_angry\n",
       "21423    female_happy\n",
       "25510      female_sad\n",
       "4929       male_angry\n",
       "3258     female_happy\n",
       "\n",
       "[5876 rows x 1 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se separa la columna \"Emotions\" respectivamente:\n",
    "testlabel = test.iloc[:, -1:]\n",
    "testlabel[:5876]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Se convierte a arrays de NumPy:\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel)\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel)\n",
    "\n",
    "#Se codifican las etiquetas:\n",
    "lb = LabelEncoder()\n",
    "\n",
    "#Se transforman y categorizan las etiquetas:\n",
    "y_train = to_categorical(lb.fit_transform(y_train))\n",
    "y_test = to_categorical(lb.fit_transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23615, 216)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redimensión del Modelo CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Dropout, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Se define el modelo: #test 22062024 - 2\n",
    "model = Sequential()\n",
    "\n",
    "# Primera capa convolucional\n",
    "model.add(Conv1D(256, 5, padding='same', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Segunda capa convolucional\n",
    "model.add(Conv1D(256, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling1D(pool_size=4))  # pool_size reducido para retener más información\n",
    "\n",
    "# Tercera capa convolucional\n",
    "model.add(Conv1D(256, 5, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Cuarta capa convolucional\n",
    "model.add(Conv1D(256, 7, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(MaxPooling1D(pool_size=4))  # pool_size reducido para retener más información\n",
    "\n",
    "# Quinta capa convolucional\n",
    "model.add(Conv1D(256, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Sexta capa convolucional\n",
    "model.add(Conv1D(256, 5, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Séptima capa convolucional\n",
    "model.add(Conv1D(256, 7, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Octava capa convolucional\n",
    "model.add(Conv1D(256, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPooling1D(pool_size=2))  # pool_size reducido para retener más información\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv1D(128, 5, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))  # Aumentar la cantidad de neuronas\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(14))  # Asegurar que coincide con el número de clases\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model.add(Conv1D(256, 5, padding='same', input_shape=(216, 1))) #original\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv1D(128, 5, padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(MaxPooling1D(pool_size=8))\n",
    "# model.add(Conv1D(128, 5, padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv1D(128, 5, padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv1D(128, 5, padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(14))  # Asegúrate de que coincide con el número de clases\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# Definir el optimizador correctamente\n",
    "#opt = RMSprop(learning_rate=0.00001, decay=1e-6) #test 22062024 - normal formula used\n",
    "#opt = Adam(learning_rate=0.001) #test 22062024 - 2\n",
    "opt = Adam(learning_rate=0.001) #tasa de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_30          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">459,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_35          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">459,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_36          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_39          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,182</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m216\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m1,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_30          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m216\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_33 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m216\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_28 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m216\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m196,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m216\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_34 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m216\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m216\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m327,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_35 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_30 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m459,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_36 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_10 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_31 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m196,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_37 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_32 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m327,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_35          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_38 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_33 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m459,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_36          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_39 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_34 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m196,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_40 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_35 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m163,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_41 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m393,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_39          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_42 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │         \u001b[38;5;34m7,182\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_43 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,741,646</span> (10.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,741,646\u001b[0m (10.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,736,270</span> (10.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,736,270\u001b[0m (10.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> (21.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,376\u001b[0m (21.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se configura el modelo para el proceso train:\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping:\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True) #metricas sobre 'val_loss'. Interesa minimizar este valor al máximo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de la parte Train para evitar innecesarias listas de Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 77ms/step - accuracy: 0.2982 - loss: 2.1510 - val_accuracy: 0.1444 - val_loss: 3.6329\n",
      "Epoch 2/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 89ms/step - accuracy: 0.5608 - loss: 1.2629 - val_accuracy: 0.4368 - val_loss: 1.8898\n",
      "Epoch 3/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 83ms/step - accuracy: 0.6319 - loss: 1.0551 - val_accuracy: 0.5622 - val_loss: 1.2246\n",
      "Epoch 4/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 81ms/step - accuracy: 0.6679 - loss: 0.9551 - val_accuracy: 0.6333 - val_loss: 1.0917\n",
      "Epoch 5/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 82ms/step - accuracy: 0.6828 - loss: 0.9174 - val_accuracy: 0.6112 - val_loss: 1.1034\n",
      "Epoch 6/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 84ms/step - accuracy: 0.7048 - loss: 0.8510 - val_accuracy: 0.5484 - val_loss: 1.2656\n",
      "Epoch 7/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 81ms/step - accuracy: 0.7231 - loss: 0.8051 - val_accuracy: 0.5273 - val_loss: 1.4670\n",
      "Epoch 8/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 83ms/step - accuracy: 0.7383 - loss: 0.7592 - val_accuracy: 0.6712 - val_loss: 0.9583\n",
      "Epoch 9/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 81ms/step - accuracy: 0.7508 - loss: 0.7175 - val_accuracy: 0.6356 - val_loss: 1.0412\n",
      "Epoch 10/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 82ms/step - accuracy: 0.7589 - loss: 0.6949 - val_accuracy: 0.6422 - val_loss: 0.9933\n",
      "Epoch 11/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 83ms/step - accuracy: 0.7734 - loss: 0.6543 - val_accuracy: 0.6712 - val_loss: 0.9427\n",
      "Epoch 12/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 82ms/step - accuracy: 0.7824 - loss: 0.6251 - val_accuracy: 0.5888 - val_loss: 1.1939\n",
      "Epoch 13/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 83ms/step - accuracy: 0.8033 - loss: 0.5675 - val_accuracy: 0.6285 - val_loss: 1.1071\n",
      "Epoch 14/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 83ms/step - accuracy: 0.8045 - loss: 0.5538 - val_accuracy: 0.6963 - val_loss: 0.8719\n",
      "Epoch 15/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.8213 - loss: 0.5065 - val_accuracy: 0.6564 - val_loss: 0.9948\n",
      "Epoch 16/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.8253 - loss: 0.4938 - val_accuracy: 0.7421 - val_loss: 0.7605\n",
      "Epoch 17/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.8374 - loss: 0.4558 - val_accuracy: 0.7195 - val_loss: 0.8691\n",
      "Epoch 18/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.8394 - loss: 0.4485 - val_accuracy: 0.6236 - val_loss: 1.1879\n",
      "Epoch 19/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.8562 - loss: 0.4059 - val_accuracy: 0.7065 - val_loss: 0.8609\n",
      "Epoch 20/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.8659 - loss: 0.3788 - val_accuracy: 0.7238 - val_loss: 0.8617\n",
      "Epoch 21/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.8703 - loss: 0.3731 - val_accuracy: 0.7890 - val_loss: 0.6222\n",
      "Epoch 22/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.8763 - loss: 0.3459 - val_accuracy: 0.7373 - val_loss: 0.7804\n",
      "Epoch 23/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.8882 - loss: 0.3230 - val_accuracy: 0.7749 - val_loss: 0.6699\n",
      "Epoch 24/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.8876 - loss: 0.3142 - val_accuracy: 0.6697 - val_loss: 1.0581\n",
      "Epoch 25/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.8966 - loss: 0.2910 - val_accuracy: 0.6569 - val_loss: 1.0696\n",
      "Epoch 26/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.9037 - loss: 0.2772 - val_accuracy: 0.7378 - val_loss: 0.7864\n",
      "Epoch 27/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.9093 - loss: 0.2566 - val_accuracy: 0.7523 - val_loss: 0.8004\n",
      "Epoch 28/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.9154 - loss: 0.2437 - val_accuracy: 0.7824 - val_loss: 0.6804\n",
      "Epoch 29/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 85ms/step - accuracy: 0.9218 - loss: 0.2279 - val_accuracy: 0.7248 - val_loss: 0.8755\n",
      "Epoch 30/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.9254 - loss: 0.2143 - val_accuracy: 0.7497 - val_loss: 0.8221\n",
      "Epoch 31/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9325 - loss: 0.1971 - val_accuracy: 0.6557 - val_loss: 1.1973\n",
      "Epoch 32/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.9288 - loss: 0.2127 - val_accuracy: 0.7270 - val_loss: 0.9016\n",
      "Epoch 33/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.9342 - loss: 0.1870 - val_accuracy: 0.7327 - val_loss: 0.8759\n",
      "Epoch 34/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.9363 - loss: 0.1873 - val_accuracy: 0.7702 - val_loss: 0.7601\n",
      "Epoch 35/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9386 - loss: 0.1772 - val_accuracy: 0.7354 - val_loss: 0.9411\n",
      "Epoch 36/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.9415 - loss: 0.1726 - val_accuracy: 0.7761 - val_loss: 0.7143\n",
      "Epoch 37/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9414 - loss: 0.1652 - val_accuracy: 0.6852 - val_loss: 1.1552\n",
      "Epoch 38/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9426 - loss: 0.1601 - val_accuracy: 0.7589 - val_loss: 0.8937\n",
      "Epoch 39/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9464 - loss: 0.1523 - val_accuracy: 0.7281 - val_loss: 0.9674\n",
      "Epoch 40/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9517 - loss: 0.1422 - val_accuracy: 0.6493 - val_loss: 1.4320\n",
      "Epoch 41/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.9457 - loss: 0.1552 - val_accuracy: 0.7692 - val_loss: 0.7752\n",
      "Epoch 42/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9537 - loss: 0.1388 - val_accuracy: 0.7748 - val_loss: 0.8570\n",
      "Epoch 43/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9597 - loss: 0.1241 - val_accuracy: 0.7736 - val_loss: 0.8765\n",
      "Epoch 44/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.9586 - loss: 0.1246 - val_accuracy: 0.7502 - val_loss: 0.8575\n",
      "Epoch 45/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.9578 - loss: 0.1232 - val_accuracy: 0.8160 - val_loss: 0.6202\n",
      "Epoch 46/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.9618 - loss: 0.1123 - val_accuracy: 0.7944 - val_loss: 0.7523\n",
      "Epoch 47/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.9593 - loss: 0.1169 - val_accuracy: 0.7769 - val_loss: 0.8165\n",
      "Epoch 48/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9603 - loss: 0.1149 - val_accuracy: 0.8270 - val_loss: 0.5872\n",
      "Epoch 49/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.9664 - loss: 0.1013 - val_accuracy: 0.8137 - val_loss: 0.6861\n",
      "Epoch 50/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 89ms/step - accuracy: 0.9602 - loss: 0.1145 - val_accuracy: 0.7866 - val_loss: 0.7560\n",
      "Epoch 51/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 84ms/step - accuracy: 0.9668 - loss: 0.0987 - val_accuracy: 0.7479 - val_loss: 0.9725\n",
      "Epoch 52/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.9655 - loss: 0.1027 - val_accuracy: 0.7886 - val_loss: 0.8145\n",
      "Epoch 53/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.9665 - loss: 0.1012 - val_accuracy: 0.6387 - val_loss: 1.5356\n",
      "Epoch 54/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9682 - loss: 0.1031 - val_accuracy: 0.7964 - val_loss: 0.7467\n",
      "Epoch 55/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9670 - loss: 0.0977 - val_accuracy: 0.7528 - val_loss: 1.0633\n",
      "Epoch 56/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.9676 - loss: 0.0936 - val_accuracy: 0.7723 - val_loss: 0.8966\n",
      "Epoch 57/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.9679 - loss: 0.0965 - val_accuracy: 0.5927 - val_loss: 1.7088\n",
      "Epoch 58/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.9724 - loss: 0.0846 - val_accuracy: 0.7687 - val_loss: 1.0287\n",
      "Epoch 59/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9695 - loss: 0.0943 - val_accuracy: 0.7660 - val_loss: 0.9686\n",
      "Epoch 60/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.9718 - loss: 0.0834 - val_accuracy: 0.7250 - val_loss: 1.1131\n",
      "Epoch 61/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.9701 - loss: 0.0911 - val_accuracy: 0.8219 - val_loss: 0.6884\n",
      "Epoch 62/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 87ms/step - accuracy: 0.9717 - loss: 0.0856 - val_accuracy: 0.7209 - val_loss: 1.0823\n",
      "Epoch 63/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.9736 - loss: 0.0799 - val_accuracy: 0.8041 - val_loss: 0.7862\n",
      "Epoch 64/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9718 - loss: 0.0836 - val_accuracy: 0.7992 - val_loss: 0.7947\n",
      "Epoch 65/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9765 - loss: 0.0706 - val_accuracy: 0.8244 - val_loss: 0.6912\n",
      "Epoch 66/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9759 - loss: 0.0772 - val_accuracy: 0.7988 - val_loss: 0.7993\n",
      "Epoch 67/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9727 - loss: 0.0825 - val_accuracy: 0.7939 - val_loss: 0.7687\n",
      "Epoch 68/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.9754 - loss: 0.0696 - val_accuracy: 0.8025 - val_loss: 0.7892\n",
      "Epoch 69/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9762 - loss: 0.0741 - val_accuracy: 0.7357 - val_loss: 1.1224\n",
      "Epoch 70/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9765 - loss: 0.0720 - val_accuracy: 0.8130 - val_loss: 0.7383\n",
      "Epoch 71/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9730 - loss: 0.0848 - val_accuracy: 0.8148 - val_loss: 0.7023\n",
      "Epoch 72/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.9729 - loss: 0.0829 - val_accuracy: 0.6569 - val_loss: 1.4760\n",
      "Epoch 73/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 87ms/step - accuracy: 0.9754 - loss: 0.0765 - val_accuracy: 0.8249 - val_loss: 0.6573\n",
      "Epoch 74/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.9810 - loss: 0.0632 - val_accuracy: 0.7678 - val_loss: 1.0164\n",
      "Epoch 75/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.9788 - loss: 0.0650 - val_accuracy: 0.7832 - val_loss: 0.9723\n",
      "Epoch 76/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 85ms/step - accuracy: 0.9742 - loss: 0.0764 - val_accuracy: 0.8297 - val_loss: 0.6372\n",
      "Epoch 77/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.9782 - loss: 0.0657 - val_accuracy: 0.7967 - val_loss: 0.7753\n",
      "Epoch 78/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 85ms/step - accuracy: 0.9787 - loss: 0.0677 - val_accuracy: 0.8406 - val_loss: 0.6109\n",
      "Epoch 79/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9769 - loss: 0.0698 - val_accuracy: 0.8247 - val_loss: 0.6460\n",
      "Epoch 80/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9788 - loss: 0.0674 - val_accuracy: 0.7692 - val_loss: 0.9333\n",
      "Epoch 81/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9786 - loss: 0.0653 - val_accuracy: 0.7843 - val_loss: 0.8499\n",
      "Epoch 82/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.9781 - loss: 0.0658 - val_accuracy: 0.8175 - val_loss: 0.7110\n",
      "Epoch 83/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9801 - loss: 0.0661 - val_accuracy: 0.8326 - val_loss: 0.6288\n",
      "Epoch 84/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.9778 - loss: 0.0628 - val_accuracy: 0.8079 - val_loss: 0.7375\n",
      "Epoch 85/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9825 - loss: 0.0533 - val_accuracy: 0.8274 - val_loss: 0.6758\n",
      "Epoch 86/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9768 - loss: 0.0671 - val_accuracy: 0.7894 - val_loss: 0.8135\n",
      "Epoch 87/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9806 - loss: 0.0640 - val_accuracy: 0.8313 - val_loss: 0.6875\n",
      "Epoch 88/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9812 - loss: 0.0585 - val_accuracy: 0.8071 - val_loss: 0.7589\n",
      "Epoch 89/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9843 - loss: 0.0494 - val_accuracy: 0.7934 - val_loss: 0.8298\n",
      "Epoch 90/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9807 - loss: 0.0597 - val_accuracy: 0.7852 - val_loss: 0.9601\n",
      "Epoch 91/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9806 - loss: 0.0584 - val_accuracy: 0.7754 - val_loss: 0.9965\n",
      "Epoch 92/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 85ms/step - accuracy: 0.9793 - loss: 0.0630 - val_accuracy: 0.7397 - val_loss: 1.1816\n",
      "Epoch 93/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9819 - loss: 0.0561 - val_accuracy: 0.7997 - val_loss: 0.9064\n",
      "Epoch 94/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9807 - loss: 0.0572 - val_accuracy: 0.7362 - val_loss: 1.2328\n",
      "Epoch 95/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9825 - loss: 0.0532 - val_accuracy: 0.8317 - val_loss: 0.6849\n",
      "Epoch 96/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.9810 - loss: 0.0541 - val_accuracy: 0.8053 - val_loss: 0.7725\n",
      "Epoch 97/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.9799 - loss: 0.0577 - val_accuracy: 0.8289 - val_loss: 0.7416\n",
      "Epoch 98/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9836 - loss: 0.0515 - val_accuracy: 0.8335 - val_loss: 0.6536\n",
      "Epoch 99/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.9832 - loss: 0.0531 - val_accuracy: 0.8358 - val_loss: 0.6567\n",
      "Epoch 100/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 86ms/step - accuracy: 0.9834 - loss: 0.0521 - val_accuracy: 0.8224 - val_loss: 0.7747\n",
      "Epoch 101/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.9816 - loss: 0.0525 - val_accuracy: 0.8077 - val_loss: 0.7963\n",
      "Epoch 102/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9859 - loss: 0.0427 - val_accuracy: 0.8223 - val_loss: 0.7832\n",
      "Epoch 103/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9820 - loss: 0.0534 - val_accuracy: 0.6976 - val_loss: 1.4403\n",
      "Epoch 104/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.9829 - loss: 0.0548 - val_accuracy: 0.7177 - val_loss: 1.2841\n",
      "Epoch 105/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.9864 - loss: 0.0427 - val_accuracy: 0.8274 - val_loss: 0.7134\n",
      "Epoch 106/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.9857 - loss: 0.0466 - val_accuracy: 0.7497 - val_loss: 1.0947\n",
      "Epoch 107/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 88ms/step - accuracy: 0.9818 - loss: 0.0573 - val_accuracy: 0.8237 - val_loss: 0.6836\n",
      "Epoch 108/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.9861 - loss: 0.0425 - val_accuracy: 0.7225 - val_loss: 1.4435\n",
      "Epoch 109/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 89ms/step - accuracy: 0.9846 - loss: 0.0453 - val_accuracy: 0.7827 - val_loss: 0.9710\n",
      "Epoch 110/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 91ms/step - accuracy: 0.9827 - loss: 0.0548 - val_accuracy: 0.7542 - val_loss: 1.1570\n",
      "Epoch 111/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 91ms/step - accuracy: 0.9834 - loss: 0.0485 - val_accuracy: 0.8193 - val_loss: 0.7421\n",
      "Epoch 112/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9856 - loss: 0.0434 - val_accuracy: 0.8218 - val_loss: 0.7864\n",
      "Epoch 113/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 89ms/step - accuracy: 0.9850 - loss: 0.0483 - val_accuracy: 0.8097 - val_loss: 0.7733\n",
      "Epoch 114/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9828 - loss: 0.0501 - val_accuracy: 0.7205 - val_loss: 1.2325\n",
      "Epoch 115/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 90ms/step - accuracy: 0.9850 - loss: 0.0409 - val_accuracy: 0.8407 - val_loss: 0.6682\n",
      "Epoch 116/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9848 - loss: 0.0444 - val_accuracy: 0.7613 - val_loss: 1.1052\n",
      "Epoch 117/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 91ms/step - accuracy: 0.9864 - loss: 0.0386 - val_accuracy: 0.8244 - val_loss: 0.7797\n",
      "Epoch 118/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 91ms/step - accuracy: 0.9857 - loss: 0.0467 - val_accuracy: 0.7415 - val_loss: 1.1565\n",
      "Epoch 119/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 90ms/step - accuracy: 0.9840 - loss: 0.0530 - val_accuracy: 0.8242 - val_loss: 0.7151\n",
      "Epoch 120/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9866 - loss: 0.0389 - val_accuracy: 0.7893 - val_loss: 0.9531\n",
      "Epoch 121/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 91ms/step - accuracy: 0.9874 - loss: 0.0431 - val_accuracy: 0.8361 - val_loss: 0.6380\n",
      "Epoch 122/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9849 - loss: 0.0491 - val_accuracy: 0.8353 - val_loss: 0.6673\n",
      "Epoch 123/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9883 - loss: 0.0359 - val_accuracy: 0.7807 - val_loss: 0.9777\n",
      "Epoch 124/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 90ms/step - accuracy: 0.9851 - loss: 0.0436 - val_accuracy: 0.8153 - val_loss: 0.8189\n",
      "Epoch 125/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 93ms/step - accuracy: 0.9867 - loss: 0.0419 - val_accuracy: 0.7514 - val_loss: 1.0864\n",
      "Epoch 126/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 91ms/step - accuracy: 0.9870 - loss: 0.0432 - val_accuracy: 0.8477 - val_loss: 0.6669\n",
      "Epoch 127/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 91ms/step - accuracy: 0.9858 - loss: 0.0442 - val_accuracy: 0.8391 - val_loss: 0.6652\n",
      "Epoch 128/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9856 - loss: 0.0437 - val_accuracy: 0.7469 - val_loss: 1.1680\n",
      "Epoch 129/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9896 - loss: 0.0329 - val_accuracy: 0.7979 - val_loss: 0.9272\n",
      "Epoch 130/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 93ms/step - accuracy: 0.9862 - loss: 0.0415 - val_accuracy: 0.8091 - val_loss: 0.7695\n",
      "Epoch 131/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 91ms/step - accuracy: 0.9877 - loss: 0.0388 - val_accuracy: 0.8074 - val_loss: 0.7548\n",
      "Epoch 132/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 94ms/step - accuracy: 0.9890 - loss: 0.0350 - val_accuracy: 0.8069 - val_loss: 0.8666\n",
      "Epoch 133/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9866 - loss: 0.0398 - val_accuracy: 0.8242 - val_loss: 0.7680\n",
      "Epoch 134/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 93ms/step - accuracy: 0.9855 - loss: 0.0456 - val_accuracy: 0.7375 - val_loss: 1.2526\n",
      "Epoch 135/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 91ms/step - accuracy: 0.9872 - loss: 0.0390 - val_accuracy: 0.8285 - val_loss: 0.7024\n",
      "Epoch 136/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 93ms/step - accuracy: 0.9873 - loss: 0.0408 - val_accuracy: 0.8129 - val_loss: 0.7816\n",
      "Epoch 137/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9879 - loss: 0.0366 - val_accuracy: 0.8262 - val_loss: 0.7681\n",
      "Epoch 138/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 93ms/step - accuracy: 0.9891 - loss: 0.0339 - val_accuracy: 0.8231 - val_loss: 0.7631\n",
      "Epoch 139/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 93ms/step - accuracy: 0.9861 - loss: 0.0428 - val_accuracy: 0.8387 - val_loss: 0.7052\n",
      "Epoch 140/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9881 - loss: 0.0369 - val_accuracy: 0.7454 - val_loss: 1.1592\n",
      "Epoch 141/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 94ms/step - accuracy: 0.9888 - loss: 0.0348 - val_accuracy: 0.8480 - val_loss: 0.6146\n",
      "Epoch 142/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 93ms/step - accuracy: 0.9877 - loss: 0.0353 - val_accuracy: 0.7787 - val_loss: 0.9875\n",
      "Epoch 143/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 91ms/step - accuracy: 0.9890 - loss: 0.0367 - val_accuracy: 0.8312 - val_loss: 0.6765\n",
      "Epoch 144/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 94ms/step - accuracy: 0.9882 - loss: 0.0369 - val_accuracy: 0.7242 - val_loss: 1.3720\n",
      "Epoch 145/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9871 - loss: 0.0383 - val_accuracy: 0.8547 - val_loss: 0.5834\n",
      "Epoch 146/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 93ms/step - accuracy: 0.9898 - loss: 0.0345 - val_accuracy: 0.8411 - val_loss: 0.6330\n",
      "Epoch 147/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 93ms/step - accuracy: 0.9874 - loss: 0.0371 - val_accuracy: 0.7550 - val_loss: 1.0569\n",
      "Epoch 148/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9900 - loss: 0.0304 - val_accuracy: 0.7829 - val_loss: 0.9456\n",
      "Epoch 149/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 94ms/step - accuracy: 0.9895 - loss: 0.0354 - val_accuracy: 0.8338 - val_loss: 0.7249\n",
      "Epoch 150/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 91ms/step - accuracy: 0.9881 - loss: 0.0364 - val_accuracy: 0.8167 - val_loss: 0.7803\n",
      "Epoch 151/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 94ms/step - accuracy: 0.9905 - loss: 0.0290 - val_accuracy: 0.7891 - val_loss: 0.9536\n",
      "Epoch 152/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 94ms/step - accuracy: 0.9898 - loss: 0.0331 - val_accuracy: 0.8303 - val_loss: 0.7377\n",
      "Epoch 153/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 95ms/step - accuracy: 0.9891 - loss: 0.0350 - val_accuracy: 0.8305 - val_loss: 0.7417\n",
      "Epoch 154/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9900 - loss: 0.0321 - val_accuracy: 0.7794 - val_loss: 0.9864\n",
      "Epoch 155/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 94ms/step - accuracy: 0.9896 - loss: 0.0345 - val_accuracy: 0.8264 - val_loss: 0.7224\n",
      "Epoch 156/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.9880 - loss: 0.0417 - val_accuracy: 0.7782 - val_loss: 1.0435\n",
      "Epoch 157/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 93ms/step - accuracy: 0.9920 - loss: 0.0266 - val_accuracy: 0.7911 - val_loss: 0.9290\n",
      "Epoch 158/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 93ms/step - accuracy: 0.9893 - loss: 0.0341 - val_accuracy: 0.8261 - val_loss: 0.7407\n",
      "Epoch 159/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 94ms/step - accuracy: 0.9886 - loss: 0.0336 - val_accuracy: 0.8237 - val_loss: 0.7525\n",
      "Epoch 160/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 94ms/step - accuracy: 0.9905 - loss: 0.0332 - val_accuracy: 0.8168 - val_loss: 0.8055\n",
      "Epoch 161/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 94ms/step - accuracy: 0.9888 - loss: 0.0324 - val_accuracy: 0.7824 - val_loss: 0.9089\n",
      "Epoch 162/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 93ms/step - accuracy: 0.9895 - loss: 0.0359 - val_accuracy: 0.8137 - val_loss: 0.7914\n",
      "Epoch 163/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 93ms/step - accuracy: 0.9898 - loss: 0.0303 - val_accuracy: 0.7873 - val_loss: 0.9476\n",
      "Epoch 164/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 93ms/step - accuracy: 0.9898 - loss: 0.0301 - val_accuracy: 0.8383 - val_loss: 0.7097\n",
      "Epoch 165/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 96ms/step - accuracy: 0.9907 - loss: 0.0308 - val_accuracy: 0.8295 - val_loss: 0.7040\n",
      "Epoch 166/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 94ms/step - accuracy: 0.9900 - loss: 0.0301 - val_accuracy: 0.8221 - val_loss: 0.7311\n",
      "Epoch 167/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 95ms/step - accuracy: 0.9888 - loss: 0.0383 - val_accuracy: 0.8021 - val_loss: 0.8919\n",
      "Epoch 168/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 93ms/step - accuracy: 0.9925 - loss: 0.0275 - val_accuracy: 0.8425 - val_loss: 0.7249\n",
      "Epoch 169/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 94ms/step - accuracy: 0.9890 - loss: 0.0334 - val_accuracy: 0.8331 - val_loss: 0.7180\n",
      "Epoch 170/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 95ms/step - accuracy: 0.9898 - loss: 0.0308 - val_accuracy: 0.8099 - val_loss: 0.8270\n",
      "Epoch 171/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 93ms/step - accuracy: 0.9903 - loss: 0.0311 - val_accuracy: 0.8336 - val_loss: 0.6918\n",
      "Epoch 172/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 96ms/step - accuracy: 0.9899 - loss: 0.0319 - val_accuracy: 0.8119 - val_loss: 0.8136\n",
      "Epoch 173/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 94ms/step - accuracy: 0.9880 - loss: 0.0351 - val_accuracy: 0.8420 - val_loss: 0.6706\n",
      "Epoch 174/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 95ms/step - accuracy: 0.9902 - loss: 0.0307 - val_accuracy: 0.8412 - val_loss: 0.6627\n",
      "Epoch 175/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 96ms/step - accuracy: 0.9873 - loss: 0.0399 - val_accuracy: 0.8636 - val_loss: 0.5158\n",
      "Epoch 176/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 95ms/step - accuracy: 0.9898 - loss: 0.0321 - val_accuracy: 0.8287 - val_loss: 0.6866\n",
      "Epoch 177/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 95ms/step - accuracy: 0.9902 - loss: 0.0291 - val_accuracy: 0.7639 - val_loss: 1.1203\n",
      "Epoch 178/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 97ms/step - accuracy: 0.9900 - loss: 0.0316 - val_accuracy: 0.8425 - val_loss: 0.6197\n",
      "Epoch 179/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 95ms/step - accuracy: 0.9906 - loss: 0.0344 - val_accuracy: 0.8490 - val_loss: 0.6342\n",
      "Epoch 180/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 96ms/step - accuracy: 0.9903 - loss: 0.0323 - val_accuracy: 0.8366 - val_loss: 0.7340\n",
      "Epoch 181/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 96ms/step - accuracy: 0.9918 - loss: 0.0242 - val_accuracy: 0.8162 - val_loss: 0.8486\n",
      "Epoch 182/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 96ms/step - accuracy: 0.9906 - loss: 0.0327 - val_accuracy: 0.8567 - val_loss: 0.5826\n",
      "Epoch 183/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 95ms/step - accuracy: 0.9929 - loss: 0.0218 - val_accuracy: 0.6828 - val_loss: 1.7501\n",
      "Epoch 184/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 96ms/step - accuracy: 0.9906 - loss: 0.0337 - val_accuracy: 0.8002 - val_loss: 0.8654\n",
      "Epoch 185/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 96ms/step - accuracy: 0.9913 - loss: 0.0280 - val_accuracy: 0.8221 - val_loss: 0.8304\n",
      "Epoch 186/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 96ms/step - accuracy: 0.9914 - loss: 0.0297 - val_accuracy: 0.8384 - val_loss: 0.6445\n",
      "Epoch 187/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 97ms/step - accuracy: 0.9930 - loss: 0.0247 - val_accuracy: 0.7972 - val_loss: 1.0029\n",
      "Epoch 188/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 96ms/step - accuracy: 0.9905 - loss: 0.0307 - val_accuracy: 0.8110 - val_loss: 0.8296\n",
      "Epoch 189/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 98ms/step - accuracy: 0.9918 - loss: 0.0268 - val_accuracy: 0.8514 - val_loss: 0.6012\n",
      "Epoch 190/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 97ms/step - accuracy: 0.9910 - loss: 0.0280 - val_accuracy: 0.8399 - val_loss: 0.6182\n",
      "Epoch 191/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 97ms/step - accuracy: 0.9904 - loss: 0.0311 - val_accuracy: 0.8031 - val_loss: 0.8633\n",
      "Epoch 192/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 97ms/step - accuracy: 0.9907 - loss: 0.0282 - val_accuracy: 0.7957 - val_loss: 0.9063\n",
      "Epoch 193/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 97ms/step - accuracy: 0.9885 - loss: 0.0394 - val_accuracy: 0.8559 - val_loss: 0.5814\n",
      "Epoch 194/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 96ms/step - accuracy: 0.9904 - loss: 0.0265 - val_accuracy: 0.8191 - val_loss: 0.7973\n",
      "Epoch 195/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9903 - loss: 0.0330 - val_accuracy: 0.8356 - val_loss: 0.6947\n",
      "Epoch 196/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 97ms/step - accuracy: 0.9933 - loss: 0.0200 - val_accuracy: 0.8468 - val_loss: 0.6077\n",
      "Epoch 197/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 97ms/step - accuracy: 0.9905 - loss: 0.0293 - val_accuracy: 0.8198 - val_loss: 0.7738\n",
      "Epoch 198/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9923 - loss: 0.0251 - val_accuracy: 0.8071 - val_loss: 0.8938\n",
      "Epoch 199/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 97ms/step - accuracy: 0.9919 - loss: 0.0241 - val_accuracy: 0.8409 - val_loss: 0.6852\n",
      "Epoch 200/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 96ms/step - accuracy: 0.9913 - loss: 0.0268 - val_accuracy: 0.8262 - val_loss: 0.7512\n",
      "Epoch 201/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9914 - loss: 0.0259 - val_accuracy: 0.8496 - val_loss: 0.6063\n",
      "Epoch 202/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9896 - loss: 0.0342 - val_accuracy: 0.8142 - val_loss: 0.7825\n",
      "Epoch 203/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 97ms/step - accuracy: 0.9924 - loss: 0.0249 - val_accuracy: 0.8310 - val_loss: 0.7141\n",
      "Epoch 204/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 100ms/step - accuracy: 0.9919 - loss: 0.0300 - val_accuracy: 0.7594 - val_loss: 1.0412\n",
      "Epoch 205/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 97ms/step - accuracy: 0.9910 - loss: 0.0278 - val_accuracy: 0.8496 - val_loss: 0.6226\n",
      "Epoch 206/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 98ms/step - accuracy: 0.9927 - loss: 0.0216 - val_accuracy: 0.7967 - val_loss: 0.9693\n",
      "Epoch 207/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9930 - loss: 0.0225 - val_accuracy: 0.7479 - val_loss: 1.1601\n",
      "Epoch 208/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 97ms/step - accuracy: 0.9909 - loss: 0.0276 - val_accuracy: 0.8485 - val_loss: 0.6526\n",
      "Epoch 209/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9926 - loss: 0.0255 - val_accuracy: 0.8544 - val_loss: 0.5918\n",
      "Epoch 210/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 98ms/step - accuracy: 0.9929 - loss: 0.0209 - val_accuracy: 0.7888 - val_loss: 0.9902\n",
      "Epoch 211/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9904 - loss: 0.0301 - val_accuracy: 0.8320 - val_loss: 0.7192\n",
      "Epoch 212/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9920 - loss: 0.0264 - val_accuracy: 0.8473 - val_loss: 0.6307\n",
      "Epoch 213/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 100ms/step - accuracy: 0.9933 - loss: 0.0224 - val_accuracy: 0.6506 - val_loss: 1.6788\n",
      "Epoch 214/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 98ms/step - accuracy: 0.9913 - loss: 0.0278 - val_accuracy: 0.8203 - val_loss: 0.7417\n",
      "Epoch 215/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 98ms/step - accuracy: 0.9917 - loss: 0.0251 - val_accuracy: 0.8320 - val_loss: 0.7690\n",
      "Epoch 216/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9921 - loss: 0.0249 - val_accuracy: 0.8440 - val_loss: 0.6551\n",
      "Epoch 217/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9909 - loss: 0.0259 - val_accuracy: 0.8605 - val_loss: 0.5506\n",
      "Epoch 218/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 100ms/step - accuracy: 0.9918 - loss: 0.0258 - val_accuracy: 0.8262 - val_loss: 0.7550\n",
      "Epoch 219/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 100ms/step - accuracy: 0.9920 - loss: 0.0284 - val_accuracy: 0.7964 - val_loss: 0.9473\n",
      "Epoch 220/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9921 - loss: 0.0242 - val_accuracy: 0.8171 - val_loss: 0.7803\n",
      "Epoch 221/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9933 - loss: 0.0191 - val_accuracy: 0.8251 - val_loss: 0.7342\n",
      "Epoch 222/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 101ms/step - accuracy: 0.9912 - loss: 0.0271 - val_accuracy: 0.8386 - val_loss: 0.6289\n",
      "Epoch 223/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 100ms/step - accuracy: 0.9927 - loss: 0.0228 - val_accuracy: 0.8303 - val_loss: 0.6875\n",
      "Epoch 224/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9931 - loss: 0.0241 - val_accuracy: 0.8549 - val_loss: 0.5517\n",
      "Epoch 225/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 102ms/step - accuracy: 0.9934 - loss: 0.0208 - val_accuracy: 0.8597 - val_loss: 0.5668\n",
      "Epoch 226/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 99ms/step - accuracy: 0.9924 - loss: 0.0235 - val_accuracy: 0.8269 - val_loss: 0.7724\n",
      "Epoch 227/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 100ms/step - accuracy: 0.9917 - loss: 0.0264 - val_accuracy: 0.8059 - val_loss: 0.9265\n",
      "Epoch 228/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 102ms/step - accuracy: 0.9917 - loss: 0.0284 - val_accuracy: 0.8432 - val_loss: 0.6822\n",
      "Epoch 229/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 100ms/step - accuracy: 0.9939 - loss: 0.0218 - val_accuracy: 0.8575 - val_loss: 0.5797\n",
      "Epoch 230/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 101ms/step - accuracy: 0.9922 - loss: 0.0251 - val_accuracy: 0.8391 - val_loss: 0.6381\n",
      "Epoch 231/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 100ms/step - accuracy: 0.9924 - loss: 0.0254 - val_accuracy: 0.7586 - val_loss: 1.0740\n",
      "Epoch 232/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 101ms/step - accuracy: 0.9941 - loss: 0.0197 - val_accuracy: 0.8310 - val_loss: 0.7122\n",
      "Epoch 233/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 101ms/step - accuracy: 0.9929 - loss: 0.0231 - val_accuracy: 0.8430 - val_loss: 0.6665\n",
      "Epoch 234/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 101ms/step - accuracy: 0.9903 - loss: 0.0317 - val_accuracy: 0.8368 - val_loss: 0.6978\n",
      "Epoch 235/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 102ms/step - accuracy: 0.9927 - loss: 0.0232 - val_accuracy: 0.8269 - val_loss: 0.7435\n",
      "Epoch 236/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 100ms/step - accuracy: 0.9938 - loss: 0.0212 - val_accuracy: 0.8176 - val_loss: 0.7795\n",
      "Epoch 237/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 102ms/step - accuracy: 0.9927 - loss: 0.0232 - val_accuracy: 0.7669 - val_loss: 1.2047\n",
      "Epoch 238/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 100ms/step - accuracy: 0.9925 - loss: 0.0242 - val_accuracy: 0.8516 - val_loss: 0.6298\n",
      "Epoch 239/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 102ms/step - accuracy: 0.9935 - loss: 0.0199 - val_accuracy: 0.8694 - val_loss: 0.5108\n",
      "Epoch 240/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 103ms/step - accuracy: 0.9932 - loss: 0.0237 - val_accuracy: 0.7289 - val_loss: 1.3356\n",
      "Epoch 241/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 102ms/step - accuracy: 0.9913 - loss: 0.0243 - val_accuracy: 0.8462 - val_loss: 0.6560\n",
      "Epoch 242/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 101ms/step - accuracy: 0.9936 - loss: 0.0219 - val_accuracy: 0.7829 - val_loss: 1.0383\n",
      "Epoch 243/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 103ms/step - accuracy: 0.9925 - loss: 0.0227 - val_accuracy: 0.8493 - val_loss: 0.6552\n",
      "Epoch 244/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 102ms/step - accuracy: 0.9929 - loss: 0.0220 - val_accuracy: 0.8378 - val_loss: 0.6987\n",
      "Epoch 245/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 103ms/step - accuracy: 0.9933 - loss: 0.0202 - val_accuracy: 0.8132 - val_loss: 0.7799\n",
      "Epoch 246/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 102ms/step - accuracy: 0.9932 - loss: 0.0221 - val_accuracy: 0.8460 - val_loss: 0.6585\n",
      "Epoch 247/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 102ms/step - accuracy: 0.9923 - loss: 0.0246 - val_accuracy: 0.8383 - val_loss: 0.7118\n",
      "Epoch 248/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 103ms/step - accuracy: 0.9930 - loss: 0.0218 - val_accuracy: 0.7779 - val_loss: 1.0139\n",
      "Epoch 249/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 102ms/step - accuracy: 0.9932 - loss: 0.0217 - val_accuracy: 0.8435 - val_loss: 0.7047\n",
      "Epoch 250/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 103ms/step - accuracy: 0.9934 - loss: 0.0217 - val_accuracy: 0.8373 - val_loss: 0.7089\n",
      "Epoch 251/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 104ms/step - accuracy: 0.9931 - loss: 0.0212 - val_accuracy: 0.8386 - val_loss: 0.6616\n",
      "Epoch 252/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 102ms/step - accuracy: 0.9919 - loss: 0.0259 - val_accuracy: 0.8577 - val_loss: 0.5643\n",
      "Epoch 253/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 103ms/step - accuracy: 0.9930 - loss: 0.0225 - val_accuracy: 0.8152 - val_loss: 0.7858\n",
      "Epoch 254/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 104ms/step - accuracy: 0.9942 - loss: 0.0206 - val_accuracy: 0.8059 - val_loss: 0.8200\n",
      "Epoch 255/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 103ms/step - accuracy: 0.9935 - loss: 0.0199 - val_accuracy: 0.8114 - val_loss: 0.7815\n",
      "Epoch 256/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 103ms/step - accuracy: 0.9942 - loss: 0.0190 - val_accuracy: 0.8493 - val_loss: 0.5964\n",
      "Epoch 257/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 104ms/step - accuracy: 0.9936 - loss: 0.0219 - val_accuracy: 0.8635 - val_loss: 0.5298\n",
      "Epoch 258/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 104ms/step - accuracy: 0.9925 - loss: 0.0231 - val_accuracy: 0.7387 - val_loss: 1.1035\n",
      "Epoch 259/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 104ms/step - accuracy: 0.9934 - loss: 0.0234 - val_accuracy: 0.8005 - val_loss: 0.8004\n",
      "Epoch 260/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 103ms/step - accuracy: 0.9919 - loss: 0.0231 - val_accuracy: 0.8168 - val_loss: 0.8143\n",
      "Epoch 261/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 103ms/step - accuracy: 0.9923 - loss: 0.0267 - val_accuracy: 0.8435 - val_loss: 0.6320\n",
      "Epoch 262/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 105ms/step - accuracy: 0.9937 - loss: 0.0202 - val_accuracy: 0.6806 - val_loss: 1.4738\n",
      "Epoch 263/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 104ms/step - accuracy: 0.9924 - loss: 0.0246 - val_accuracy: 0.8485 - val_loss: 0.6156\n",
      "Epoch 264/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 105ms/step - accuracy: 0.9924 - loss: 0.0219 - val_accuracy: 0.8528 - val_loss: 0.5932\n",
      "Epoch 265/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 104ms/step - accuracy: 0.9948 - loss: 0.0170 - val_accuracy: 0.7594 - val_loss: 1.0762\n",
      "Epoch 266/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 104ms/step - accuracy: 0.9926 - loss: 0.0246 - val_accuracy: 0.8265 - val_loss: 0.7555\n",
      "Epoch 267/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 105ms/step - accuracy: 0.9941 - loss: 0.0172 - val_accuracy: 0.8529 - val_loss: 0.6129\n",
      "Epoch 268/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 104ms/step - accuracy: 0.9918 - loss: 0.0237 - val_accuracy: 0.8068 - val_loss: 0.9196\n",
      "Epoch 269/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 106ms/step - accuracy: 0.9933 - loss: 0.0205 - val_accuracy: 0.8368 - val_loss: 0.7283\n",
      "Epoch 270/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 104ms/step - accuracy: 0.9939 - loss: 0.0185 - val_accuracy: 0.8359 - val_loss: 0.6636\n",
      "Epoch 271/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 104ms/step - accuracy: 0.9928 - loss: 0.0214 - val_accuracy: 0.6526 - val_loss: 1.6927\n",
      "Epoch 272/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 106ms/step - accuracy: 0.9926 - loss: 0.0252 - val_accuracy: 0.8153 - val_loss: 0.8060\n",
      "Epoch 273/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 107ms/step - accuracy: 0.9933 - loss: 0.0203 - val_accuracy: 0.8424 - val_loss: 0.6396\n",
      "Epoch 274/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 105ms/step - accuracy: 0.9931 - loss: 0.0244 - val_accuracy: 0.8505 - val_loss: 0.6026\n",
      "Epoch 275/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 105ms/step - accuracy: 0.9928 - loss: 0.0217 - val_accuracy: 0.8326 - val_loss: 0.7178\n",
      "Epoch 276/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 106ms/step - accuracy: 0.9929 - loss: 0.0217 - val_accuracy: 0.6671 - val_loss: 1.5616\n",
      "Epoch 277/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 106ms/step - accuracy: 0.9943 - loss: 0.0195 - val_accuracy: 0.8465 - val_loss: 0.6633\n",
      "Epoch 278/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 107ms/step - accuracy: 0.9921 - loss: 0.0248 - val_accuracy: 0.8417 - val_loss: 0.6230\n",
      "Epoch 279/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 107ms/step - accuracy: 0.9939 - loss: 0.0193 - val_accuracy: 0.8531 - val_loss: 0.6132\n",
      "Epoch 280/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 107ms/step - accuracy: 0.9944 - loss: 0.0187 - val_accuracy: 0.8173 - val_loss: 0.7882\n",
      "Epoch 281/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 106ms/step - accuracy: 0.9944 - loss: 0.0194 - val_accuracy: 0.8094 - val_loss: 0.8948\n",
      "Epoch 282/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 107ms/step - accuracy: 0.9931 - loss: 0.0252 - val_accuracy: 0.8462 - val_loss: 0.6844\n",
      "Epoch 283/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 108ms/step - accuracy: 0.9936 - loss: 0.0205 - val_accuracy: 0.8663 - val_loss: 0.5321\n",
      "Epoch 284/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 107ms/step - accuracy: 0.9935 - loss: 0.0206 - val_accuracy: 0.8651 - val_loss: 0.5454\n",
      "Epoch 285/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 106ms/step - accuracy: 0.9940 - loss: 0.0191 - val_accuracy: 0.8336 - val_loss: 0.7879\n",
      "Epoch 286/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 108ms/step - accuracy: 0.9942 - loss: 0.0205 - val_accuracy: 0.8448 - val_loss: 0.6491\n",
      "Epoch 287/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 108ms/step - accuracy: 0.9955 - loss: 0.0172 - val_accuracy: 0.8376 - val_loss: 0.6640\n",
      "Epoch 288/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 107ms/step - accuracy: 0.9917 - loss: 0.0318 - val_accuracy: 0.8191 - val_loss: 0.7536\n",
      "Epoch 289/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 108ms/step - accuracy: 0.9953 - loss: 0.0143 - val_accuracy: 0.8452 - val_loss: 0.6372\n",
      "Epoch 290/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 107ms/step - accuracy: 0.9942 - loss: 0.0160 - val_accuracy: 0.7555 - val_loss: 0.9812\n",
      "Epoch 291/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 107ms/step - accuracy: 0.9942 - loss: 0.0190 - val_accuracy: 0.8310 - val_loss: 0.6905\n",
      "Epoch 292/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 107ms/step - accuracy: 0.9939 - loss: 0.0217 - val_accuracy: 0.8447 - val_loss: 0.6381\n",
      "Epoch 293/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 107ms/step - accuracy: 0.9934 - loss: 0.0207 - val_accuracy: 0.8536 - val_loss: 0.6297\n",
      "Epoch 294/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 108ms/step - accuracy: 0.9950 - loss: 0.0158 - val_accuracy: 0.7735 - val_loss: 0.9494\n",
      "Epoch 295/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 108ms/step - accuracy: 0.9915 - loss: 0.0271 - val_accuracy: 0.8336 - val_loss: 0.7173\n",
      "Epoch 296/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 107ms/step - accuracy: 0.9940 - loss: 0.0223 - val_accuracy: 0.8331 - val_loss: 0.7047\n",
      "Epoch 297/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 108ms/step - accuracy: 0.9922 - loss: 0.0237 - val_accuracy: 0.8455 - val_loss: 0.6339\n",
      "Epoch 298/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 109ms/step - accuracy: 0.9944 - loss: 0.0181 - val_accuracy: 0.8148 - val_loss: 0.9071\n",
      "Epoch 299/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 108ms/step - accuracy: 0.9944 - loss: 0.0173 - val_accuracy: 0.8559 - val_loss: 0.5879\n",
      "Epoch 300/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 108ms/step - accuracy: 0.9931 - loss: 0.0220 - val_accuracy: 0.8176 - val_loss: 0.7957\n",
      "Epoch 301/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 109ms/step - accuracy: 0.9948 - loss: 0.0201 - val_accuracy: 0.8481 - val_loss: 0.6343\n",
      "Epoch 302/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 108ms/step - accuracy: 0.9940 - loss: 0.0199 - val_accuracy: 0.8575 - val_loss: 0.5907\n",
      "Epoch 303/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 109ms/step - accuracy: 0.9941 - loss: 0.0199 - val_accuracy: 0.8389 - val_loss: 0.6868\n",
      "Epoch 304/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 109ms/step - accuracy: 0.9936 - loss: 0.0216 - val_accuracy: 0.7947 - val_loss: 0.8887\n",
      "Epoch 305/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 108ms/step - accuracy: 0.9945 - loss: 0.0172 - val_accuracy: 0.7515 - val_loss: 1.1930\n",
      "Epoch 306/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 110ms/step - accuracy: 0.9937 - loss: 0.0178 - val_accuracy: 0.8531 - val_loss: 0.5564\n",
      "Epoch 307/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 109ms/step - accuracy: 0.9929 - loss: 0.0185 - val_accuracy: 0.8191 - val_loss: 0.7833\n",
      "Epoch 308/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 109ms/step - accuracy: 0.9947 - loss: 0.0170 - val_accuracy: 0.8371 - val_loss: 0.6959\n",
      "Epoch 309/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 110ms/step - accuracy: 0.9928 - loss: 0.0222 - val_accuracy: 0.8102 - val_loss: 0.8122\n",
      "Epoch 310/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 110ms/step - accuracy: 0.9938 - loss: 0.0166 - val_accuracy: 0.8369 - val_loss: 0.6678\n",
      "Epoch 311/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 109ms/step - accuracy: 0.9936 - loss: 0.0180 - val_accuracy: 0.8424 - val_loss: 0.6627\n",
      "Epoch 312/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 110ms/step - accuracy: 0.9939 - loss: 0.0194 - val_accuracy: 0.7962 - val_loss: 0.8106\n",
      "Epoch 313/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 111ms/step - accuracy: 0.9957 - loss: 0.0146 - val_accuracy: 0.8186 - val_loss: 0.7535\n",
      "Epoch 314/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 109ms/step - accuracy: 0.9951 - loss: 0.0162 - val_accuracy: 0.8180 - val_loss: 0.8548\n",
      "Epoch 315/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 112ms/step - accuracy: 0.9942 - loss: 0.0172 - val_accuracy: 0.6493 - val_loss: 1.8500\n",
      "Epoch 316/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 111ms/step - accuracy: 0.9927 - loss: 0.0227 - val_accuracy: 0.8607 - val_loss: 0.5879\n",
      "Epoch 317/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 112ms/step - accuracy: 0.9939 - loss: 0.0200 - val_accuracy: 0.8073 - val_loss: 0.8540\n",
      "Epoch 318/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 113ms/step - accuracy: 0.9945 - loss: 0.0175 - val_accuracy: 0.8673 - val_loss: 0.5248\n",
      "Epoch 319/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 112ms/step - accuracy: 0.9938 - loss: 0.0209 - val_accuracy: 0.8425 - val_loss: 0.6349\n",
      "Epoch 320/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 111ms/step - accuracy: 0.9954 - loss: 0.0147 - val_accuracy: 0.8201 - val_loss: 0.7714\n",
      "Epoch 321/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 112ms/step - accuracy: 0.9942 - loss: 0.0191 - val_accuracy: 0.8236 - val_loss: 0.6786\n",
      "Epoch 322/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 112ms/step - accuracy: 0.9935 - loss: 0.0249 - val_accuracy: 0.8185 - val_loss: 0.7151\n",
      "Epoch 323/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 112ms/step - accuracy: 0.9959 - loss: 0.0143 - val_accuracy: 0.8486 - val_loss: 0.6031\n",
      "Epoch 324/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 111ms/step - accuracy: 0.9940 - loss: 0.0228 - val_accuracy: 0.8364 - val_loss: 0.6318\n",
      "Epoch 325/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 112ms/step - accuracy: 0.9937 - loss: 0.0220 - val_accuracy: 0.8140 - val_loss: 0.7570\n",
      "Epoch 326/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 112ms/step - accuracy: 0.9947 - loss: 0.0164 - val_accuracy: 0.8232 - val_loss: 0.7314\n",
      "Epoch 327/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 114ms/step - accuracy: 0.9936 - loss: 0.0190 - val_accuracy: 0.8589 - val_loss: 0.5902\n",
      "Epoch 328/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 112ms/step - accuracy: 0.9947 - loss: 0.0161 - val_accuracy: 0.8691 - val_loss: 0.5097\n",
      "Epoch 329/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 113ms/step - accuracy: 0.9948 - loss: 0.0148 - val_accuracy: 0.8536 - val_loss: 0.6363\n",
      "Epoch 330/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 112ms/step - accuracy: 0.9942 - loss: 0.0179 - val_accuracy: 0.7685 - val_loss: 1.0556\n",
      "Epoch 331/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 112ms/step - accuracy: 0.9949 - loss: 0.0177 - val_accuracy: 0.8447 - val_loss: 0.6667\n",
      "Epoch 332/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 115ms/step - accuracy: 0.9932 - loss: 0.0197 - val_accuracy: 0.8506 - val_loss: 0.6069\n",
      "Epoch 333/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 113ms/step - accuracy: 0.9946 - loss: 0.0176 - val_accuracy: 0.8142 - val_loss: 0.7748\n",
      "Epoch 334/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 112ms/step - accuracy: 0.9953 - loss: 0.0160 - val_accuracy: 0.8655 - val_loss: 0.5330\n",
      "Epoch 335/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 114ms/step - accuracy: 0.9946 - loss: 0.0175 - val_accuracy: 0.8383 - val_loss: 0.6853\n",
      "Epoch 336/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 115ms/step - accuracy: 0.9949 - loss: 0.0155 - val_accuracy: 0.8547 - val_loss: 0.6426\n",
      "Epoch 337/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 113ms/step - accuracy: 0.9951 - loss: 0.0155 - val_accuracy: 0.8561 - val_loss: 0.5798\n",
      "Epoch 338/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 116ms/step - accuracy: 0.9937 - loss: 0.0220 - val_accuracy: 0.8584 - val_loss: 0.5190\n",
      "Epoch 339/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 116ms/step - accuracy: 0.9960 - loss: 0.0133 - val_accuracy: 0.8521 - val_loss: 0.5904\n",
      "Epoch 340/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 115ms/step - accuracy: 0.9940 - loss: 0.0184 - val_accuracy: 0.7819 - val_loss: 0.9506\n",
      "Epoch 341/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 116ms/step - accuracy: 0.9958 - loss: 0.0135 - val_accuracy: 0.8673 - val_loss: 0.5241\n",
      "Epoch 342/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 116ms/step - accuracy: 0.9949 - loss: 0.0211 - val_accuracy: 0.8353 - val_loss: 0.6596\n",
      "Epoch 343/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 116ms/step - accuracy: 0.9939 - loss: 0.0181 - val_accuracy: 0.8358 - val_loss: 0.6711\n",
      "Epoch 344/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 116ms/step - accuracy: 0.9943 - loss: 0.0185 - val_accuracy: 0.8541 - val_loss: 0.5626\n",
      "Epoch 345/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 117ms/step - accuracy: 0.9933 - loss: 0.0187 - val_accuracy: 0.8127 - val_loss: 0.8289\n",
      "Epoch 346/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 117ms/step - accuracy: 0.9958 - loss: 0.0153 - val_accuracy: 0.8188 - val_loss: 0.7348\n",
      "Epoch 347/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 117ms/step - accuracy: 0.9933 - loss: 0.0240 - val_accuracy: 0.7993 - val_loss: 0.7968\n",
      "Epoch 348/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 116ms/step - accuracy: 0.9946 - loss: 0.0197 - val_accuracy: 0.8341 - val_loss: 0.6769\n",
      "Epoch 349/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 117ms/step - accuracy: 0.9943 - loss: 0.0189 - val_accuracy: 0.8536 - val_loss: 0.6133\n",
      "Epoch 350/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 119ms/step - accuracy: 0.9952 - loss: 0.0171 - val_accuracy: 0.8579 - val_loss: 0.5754\n",
      "Epoch 351/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 119ms/step - accuracy: 0.9945 - loss: 0.0154 - val_accuracy: 0.8582 - val_loss: 0.6117\n",
      "Epoch 352/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 118ms/step - accuracy: 0.9941 - loss: 0.0193 - val_accuracy: 0.7743 - val_loss: 0.9982\n",
      "Epoch 353/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 118ms/step - accuracy: 0.9948 - loss: 0.0168 - val_accuracy: 0.8165 - val_loss: 0.7745\n",
      "Epoch 354/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 117ms/step - accuracy: 0.9946 - loss: 0.0172 - val_accuracy: 0.8514 - val_loss: 0.6015\n",
      "Epoch 355/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 118ms/step - accuracy: 0.9957 - loss: 0.0142 - val_accuracy: 0.8671 - val_loss: 0.5293\n",
      "Epoch 356/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 119ms/step - accuracy: 0.9959 - loss: 0.0153 - val_accuracy: 0.8345 - val_loss: 0.6690\n",
      "Epoch 357/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 118ms/step - accuracy: 0.9950 - loss: 0.0195 - val_accuracy: 0.8190 - val_loss: 0.7296\n",
      "Epoch 358/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 120ms/step - accuracy: 0.9953 - loss: 0.0168 - val_accuracy: 0.8373 - val_loss: 0.6542\n",
      "Epoch 359/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 119ms/step - accuracy: 0.9954 - loss: 0.0170 - val_accuracy: 0.8483 - val_loss: 0.5953\n",
      "Epoch 360/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 118ms/step - accuracy: 0.9945 - loss: 0.0222 - val_accuracy: 0.8467 - val_loss: 0.5838\n",
      "Epoch 361/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 120ms/step - accuracy: 0.9933 - loss: 0.0221 - val_accuracy: 0.7370 - val_loss: 1.1702\n",
      "Epoch 362/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 118ms/step - accuracy: 0.9942 - loss: 0.0180 - val_accuracy: 0.8506 - val_loss: 0.5908\n",
      "Epoch 363/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 118ms/step - accuracy: 0.9944 - loss: 0.0176 - val_accuracy: 0.8569 - val_loss: 0.6067\n",
      "Epoch 364/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 119ms/step - accuracy: 0.9947 - loss: 0.0158 - val_accuracy: 0.8486 - val_loss: 0.6243\n",
      "Epoch 365/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 120ms/step - accuracy: 0.9954 - loss: 0.0156 - val_accuracy: 0.8567 - val_loss: 0.6605\n",
      "Epoch 366/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 119ms/step - accuracy: 0.9958 - loss: 0.0144 - val_accuracy: 0.7708 - val_loss: 0.9115\n",
      "Epoch 367/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 119ms/step - accuracy: 0.9929 - loss: 0.0235 - val_accuracy: 0.8480 - val_loss: 0.5796\n",
      "Epoch 368/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 119ms/step - accuracy: 0.9951 - loss: 0.0157 - val_accuracy: 0.8414 - val_loss: 0.6251\n",
      "Epoch 369/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 122ms/step - accuracy: 0.9961 - loss: 0.0150 - val_accuracy: 0.8364 - val_loss: 0.6888\n",
      "Epoch 370/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 119ms/step - accuracy: 0.9943 - loss: 0.0184 - val_accuracy: 0.8562 - val_loss: 0.5885\n",
      "Epoch 371/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 121ms/step - accuracy: 0.9954 - loss: 0.0178 - val_accuracy: 0.8488 - val_loss: 0.6050\n",
      "Epoch 372/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 120ms/step - accuracy: 0.9947 - loss: 0.0158 - val_accuracy: 0.8472 - val_loss: 0.6378\n",
      "Epoch 373/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 120ms/step - accuracy: 0.9952 - loss: 0.0157 - val_accuracy: 0.8325 - val_loss: 0.7392\n",
      "Epoch 374/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 121ms/step - accuracy: 0.9956 - loss: 0.0158 - val_accuracy: 0.8198 - val_loss: 0.7760\n",
      "Epoch 375/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 122ms/step - accuracy: 0.9955 - loss: 0.0166 - val_accuracy: 0.8722 - val_loss: 0.5005\n",
      "Epoch 376/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 121ms/step - accuracy: 0.9946 - loss: 0.0166 - val_accuracy: 0.8419 - val_loss: 0.6500\n",
      "Epoch 377/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 120ms/step - accuracy: 0.9955 - loss: 0.0150 - val_accuracy: 0.8246 - val_loss: 0.6939\n",
      "Epoch 378/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 120ms/step - accuracy: 0.9946 - loss: 0.0198 - val_accuracy: 0.8490 - val_loss: 0.5907\n",
      "Epoch 379/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 121ms/step - accuracy: 0.9956 - loss: 0.0156 - val_accuracy: 0.8679 - val_loss: 0.4803\n",
      "Epoch 380/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 122ms/step - accuracy: 0.9959 - loss: 0.0162 - val_accuracy: 0.8470 - val_loss: 0.5985\n",
      "Epoch 381/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 122ms/step - accuracy: 0.9956 - loss: 0.0138 - val_accuracy: 0.8610 - val_loss: 0.5647\n",
      "Epoch 382/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 122ms/step - accuracy: 0.9948 - loss: 0.0207 - val_accuracy: 0.8463 - val_loss: 0.5858\n",
      "Epoch 383/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 124ms/step - accuracy: 0.9939 - loss: 0.0189 - val_accuracy: 0.8028 - val_loss: 0.8225\n",
      "Epoch 384/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 122ms/step - accuracy: 0.9958 - loss: 0.0133 - val_accuracy: 0.8383 - val_loss: 0.6581\n",
      "Epoch 385/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 121ms/step - accuracy: 0.9954 - loss: 0.0148 - val_accuracy: 0.8622 - val_loss: 0.5255\n",
      "Epoch 386/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 123ms/step - accuracy: 0.9963 - loss: 0.0124 - val_accuracy: 0.8061 - val_loss: 0.8548\n",
      "Epoch 387/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 123ms/step - accuracy: 0.9934 - loss: 0.0187 - val_accuracy: 0.8575 - val_loss: 0.5972\n",
      "Epoch 388/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 122ms/step - accuracy: 0.9947 - loss: 0.0186 - val_accuracy: 0.8000 - val_loss: 0.8187\n",
      "Epoch 389/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 124ms/step - accuracy: 0.9961 - loss: 0.0130 - val_accuracy: 0.8221 - val_loss: 0.7590\n",
      "Epoch 390/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 124ms/step - accuracy: 0.9956 - loss: 0.0149 - val_accuracy: 0.8425 - val_loss: 0.6493\n",
      "Epoch 391/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 123ms/step - accuracy: 0.9949 - loss: 0.0158 - val_accuracy: 0.8379 - val_loss: 0.6562\n",
      "Epoch 392/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 124ms/step - accuracy: 0.9949 - loss: 0.0176 - val_accuracy: 0.8585 - val_loss: 0.5352\n",
      "Epoch 393/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 125ms/step - accuracy: 0.9959 - loss: 0.0148 - val_accuracy: 0.8625 - val_loss: 0.5243\n",
      "Epoch 394/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 123ms/step - accuracy: 0.9959 - loss: 0.0125 - val_accuracy: 0.8575 - val_loss: 0.5884\n",
      "Epoch 395/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 124ms/step - accuracy: 0.9951 - loss: 0.0159 - val_accuracy: 0.8549 - val_loss: 0.6149\n",
      "Epoch 396/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 124ms/step - accuracy: 0.9943 - loss: 0.0218 - val_accuracy: 0.8610 - val_loss: 0.5558\n",
      "Epoch 397/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 125ms/step - accuracy: 0.9951 - loss: 0.0162 - val_accuracy: 0.8391 - val_loss: 0.6402\n",
      "Epoch 398/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 125ms/step - accuracy: 0.9944 - loss: 0.0166 - val_accuracy: 0.8552 - val_loss: 0.5769\n",
      "Epoch 399/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 125ms/step - accuracy: 0.9956 - loss: 0.0153 - val_accuracy: 0.8584 - val_loss: 0.5915\n",
      "Epoch 400/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 125ms/step - accuracy: 0.9956 - loss: 0.0128 - val_accuracy: 0.8668 - val_loss: 0.5388\n",
      "Epoch 401/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 125ms/step - accuracy: 0.9965 - loss: 0.0123 - val_accuracy: 0.8622 - val_loss: 0.5699\n",
      "Epoch 402/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 125ms/step - accuracy: 0.9952 - loss: 0.0160 - val_accuracy: 0.8521 - val_loss: 0.5710\n",
      "Epoch 403/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 124ms/step - accuracy: 0.9957 - loss: 0.0149 - val_accuracy: 0.8005 - val_loss: 0.8703\n",
      "Epoch 404/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 126ms/step - accuracy: 0.9958 - loss: 0.0143 - val_accuracy: 0.8655 - val_loss: 0.5660\n",
      "Epoch 405/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 125ms/step - accuracy: 0.9955 - loss: 0.0152 - val_accuracy: 0.8569 - val_loss: 0.5953\n",
      "Epoch 406/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 126ms/step - accuracy: 0.9947 - loss: 0.0175 - val_accuracy: 0.8381 - val_loss: 0.7365\n",
      "Epoch 407/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 127ms/step - accuracy: 0.9950 - loss: 0.0165 - val_accuracy: 0.8338 - val_loss: 0.6555\n",
      "Epoch 408/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 126ms/step - accuracy: 0.9951 - loss: 0.0152 - val_accuracy: 0.8295 - val_loss: 0.7094\n",
      "Epoch 409/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 126ms/step - accuracy: 0.9954 - loss: 0.0168 - val_accuracy: 0.8196 - val_loss: 0.7516\n",
      "Epoch 410/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 127ms/step - accuracy: 0.9945 - loss: 0.0196 - val_accuracy: 0.8539 - val_loss: 0.5536\n",
      "Epoch 411/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 127ms/step - accuracy: 0.9957 - loss: 0.0152 - val_accuracy: 0.8536 - val_loss: 0.5675\n",
      "Epoch 412/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 127ms/step - accuracy: 0.9955 - loss: 0.0139 - val_accuracy: 0.8427 - val_loss: 0.6192\n",
      "Epoch 413/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 127ms/step - accuracy: 0.9958 - loss: 0.0125 - val_accuracy: 0.8480 - val_loss: 0.6325\n",
      "Epoch 414/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 128ms/step - accuracy: 0.9946 - loss: 0.0160 - val_accuracy: 0.8181 - val_loss: 0.8104\n",
      "Epoch 415/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 128ms/step - accuracy: 0.9956 - loss: 0.0159 - val_accuracy: 0.8082 - val_loss: 0.8313\n",
      "Epoch 416/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 128ms/step - accuracy: 0.9945 - loss: 0.0190 - val_accuracy: 0.8295 - val_loss: 0.6796\n",
      "Epoch 417/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 128ms/step - accuracy: 0.9954 - loss: 0.0137 - val_accuracy: 0.8605 - val_loss: 0.5739\n",
      "Epoch 418/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 128ms/step - accuracy: 0.9952 - loss: 0.0147 - val_accuracy: 0.8480 - val_loss: 0.6305\n",
      "Epoch 419/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 129ms/step - accuracy: 0.9962 - loss: 0.0138 - val_accuracy: 0.8274 - val_loss: 0.7002\n",
      "Epoch 420/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 130ms/step - accuracy: 0.9952 - loss: 0.0180 - val_accuracy: 0.8730 - val_loss: 0.4741\n",
      "Epoch 421/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 128ms/step - accuracy: 0.9951 - loss: 0.0156 - val_accuracy: 0.8458 - val_loss: 0.6802\n",
      "Epoch 422/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 129ms/step - accuracy: 0.9944 - loss: 0.0199 - val_accuracy: 0.8493 - val_loss: 0.6183\n",
      "Epoch 423/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 129ms/step - accuracy: 0.9954 - loss: 0.0142 - val_accuracy: 0.8420 - val_loss: 0.6206\n",
      "Epoch 424/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 129ms/step - accuracy: 0.9961 - loss: 0.0128 - val_accuracy: 0.7866 - val_loss: 0.9606\n",
      "Epoch 425/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 131ms/step - accuracy: 0.9956 - loss: 0.0147 - val_accuracy: 0.8569 - val_loss: 0.5780\n",
      "Epoch 426/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 129ms/step - accuracy: 0.9959 - loss: 0.0148 - val_accuracy: 0.8392 - val_loss: 0.6609\n",
      "Epoch 427/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 130ms/step - accuracy: 0.9955 - loss: 0.0154 - val_accuracy: 0.8481 - val_loss: 0.6013\n",
      "Epoch 428/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 130ms/step - accuracy: 0.9958 - loss: 0.0151 - val_accuracy: 0.8445 - val_loss: 0.6048\n",
      "Epoch 429/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 130ms/step - accuracy: 0.9954 - loss: 0.0137 - val_accuracy: 0.8429 - val_loss: 0.6329\n",
      "Epoch 430/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 130ms/step - accuracy: 0.9950 - loss: 0.0173 - val_accuracy: 0.7820 - val_loss: 0.9777\n",
      "Epoch 431/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 130ms/step - accuracy: 0.9960 - loss: 0.0138 - val_accuracy: 0.8483 - val_loss: 0.6601\n",
      "Epoch 432/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 131ms/step - accuracy: 0.9939 - loss: 0.0193 - val_accuracy: 0.8274 - val_loss: 0.7541\n",
      "Epoch 433/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 131ms/step - accuracy: 0.9962 - loss: 0.0133 - val_accuracy: 0.8420 - val_loss: 0.6676\n",
      "Epoch 434/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 130ms/step - accuracy: 0.9976 - loss: 0.0079 - val_accuracy: 0.8374 - val_loss: 0.7175\n",
      "Epoch 435/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 131ms/step - accuracy: 0.9966 - loss: 0.0115 - val_accuracy: 0.8115 - val_loss: 0.7946\n",
      "Epoch 436/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 131ms/step - accuracy: 0.9960 - loss: 0.0135 - val_accuracy: 0.8455 - val_loss: 0.6635\n",
      "Epoch 437/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 131ms/step - accuracy: 0.9948 - loss: 0.0173 - val_accuracy: 0.8559 - val_loss: 0.5831\n",
      "Epoch 438/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 132ms/step - accuracy: 0.9950 - loss: 0.0164 - val_accuracy: 0.8180 - val_loss: 0.7754\n",
      "Epoch 439/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 132ms/step - accuracy: 0.9959 - loss: 0.0150 - val_accuracy: 0.7934 - val_loss: 0.8514\n",
      "Epoch 440/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 131ms/step - accuracy: 0.9943 - loss: 0.0177 - val_accuracy: 0.8440 - val_loss: 0.6932\n",
      "Epoch 441/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 133ms/step - accuracy: 0.9968 - loss: 0.0109 - val_accuracy: 0.8000 - val_loss: 0.8982\n",
      "Epoch 442/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 133ms/step - accuracy: 0.9950 - loss: 0.0153 - val_accuracy: 0.8109 - val_loss: 0.8196\n",
      "Epoch 443/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 133ms/step - accuracy: 0.9954 - loss: 0.0161 - val_accuracy: 0.8806 - val_loss: 0.4446\n",
      "Epoch 444/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 133ms/step - accuracy: 0.9946 - loss: 0.0164 - val_accuracy: 0.8442 - val_loss: 0.6315\n",
      "Epoch 445/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 133ms/step - accuracy: 0.9955 - loss: 0.0142 - val_accuracy: 0.8448 - val_loss: 0.6389\n",
      "Epoch 446/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 135ms/step - accuracy: 0.9970 - loss: 0.0106 - val_accuracy: 0.8475 - val_loss: 0.6568\n",
      "Epoch 447/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 133ms/step - accuracy: 0.9963 - loss: 0.0139 - val_accuracy: 0.8173 - val_loss: 0.8176\n",
      "Epoch 448/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 135ms/step - accuracy: 0.9955 - loss: 0.0147 - val_accuracy: 0.8496 - val_loss: 0.6053\n",
      "Epoch 449/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 134ms/step - accuracy: 0.9967 - loss: 0.0100 - val_accuracy: 0.7650 - val_loss: 1.1251\n",
      "Epoch 450/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 133ms/step - accuracy: 0.9962 - loss: 0.0112 - val_accuracy: 0.8519 - val_loss: 0.6810\n",
      "Epoch 451/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 134ms/step - accuracy: 0.9956 - loss: 0.0140 - val_accuracy: 0.8419 - val_loss: 0.6706\n",
      "Epoch 452/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 135ms/step - accuracy: 0.9957 - loss: 0.0136 - val_accuracy: 0.7992 - val_loss: 0.8181\n",
      "Epoch 453/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 135ms/step - accuracy: 0.9939 - loss: 0.0222 - val_accuracy: 0.7214 - val_loss: 1.3441\n",
      "Epoch 454/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 134ms/step - accuracy: 0.9951 - loss: 0.0170 - val_accuracy: 0.8480 - val_loss: 0.5900\n",
      "Epoch 455/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 135ms/step - accuracy: 0.9961 - loss: 0.0133 - val_accuracy: 0.8505 - val_loss: 0.5717\n",
      "Epoch 456/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 135ms/step - accuracy: 0.9964 - loss: 0.0128 - val_accuracy: 0.8295 - val_loss: 0.6928\n",
      "Epoch 457/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 136ms/step - accuracy: 0.9971 - loss: 0.0093 - val_accuracy: 0.8528 - val_loss: 0.6148\n",
      "Epoch 458/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 137ms/step - accuracy: 0.9964 - loss: 0.0130 - val_accuracy: 0.8480 - val_loss: 0.6919\n",
      "Epoch 459/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 135ms/step - accuracy: 0.9960 - loss: 0.0137 - val_accuracy: 0.8538 - val_loss: 0.6284\n",
      "Epoch 460/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 135ms/step - accuracy: 0.9949 - loss: 0.0175 - val_accuracy: 0.8350 - val_loss: 0.6385\n",
      "Epoch 461/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 138ms/step - accuracy: 0.9946 - loss: 0.0179 - val_accuracy: 0.8480 - val_loss: 0.5901\n",
      "Epoch 462/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 138ms/step - accuracy: 0.9952 - loss: 0.0158 - val_accuracy: 0.8302 - val_loss: 0.6982\n",
      "Epoch 463/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 138ms/step - accuracy: 0.9959 - loss: 0.0126 - val_accuracy: 0.8496 - val_loss: 0.6371\n",
      "Epoch 464/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 137ms/step - accuracy: 0.9963 - loss: 0.0127 - val_accuracy: 0.8392 - val_loss: 0.6795\n",
      "Epoch 465/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 136ms/step - accuracy: 0.9956 - loss: 0.0143 - val_accuracy: 0.8574 - val_loss: 0.5815\n",
      "Epoch 466/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 138ms/step - accuracy: 0.9963 - loss: 0.0132 - val_accuracy: 0.8186 - val_loss: 0.7752\n",
      "Epoch 467/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 138ms/step - accuracy: 0.9965 - loss: 0.0141 - val_accuracy: 0.8605 - val_loss: 0.5722\n",
      "Epoch 468/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 137ms/step - accuracy: 0.9956 - loss: 0.0157 - val_accuracy: 0.8467 - val_loss: 0.6059\n",
      "Epoch 469/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 138ms/step - accuracy: 0.9966 - loss: 0.0115 - val_accuracy: 0.8256 - val_loss: 0.7344\n",
      "Epoch 470/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 138ms/step - accuracy: 0.9953 - loss: 0.0193 - val_accuracy: 0.8645 - val_loss: 0.4991\n",
      "Epoch 471/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 139ms/step - accuracy: 0.9958 - loss: 0.0140 - val_accuracy: 0.8462 - val_loss: 0.6482\n",
      "Epoch 472/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 138ms/step - accuracy: 0.9971 - loss: 0.0102 - val_accuracy: 0.8447 - val_loss: 0.6297\n",
      "Epoch 473/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 139ms/step - accuracy: 0.9959 - loss: 0.0144 - val_accuracy: 0.8534 - val_loss: 0.6119\n",
      "Epoch 474/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 139ms/step - accuracy: 0.9956 - loss: 0.0151 - val_accuracy: 0.8742 - val_loss: 0.4967\n",
      "Epoch 475/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 139ms/step - accuracy: 0.9961 - loss: 0.0139 - val_accuracy: 0.8406 - val_loss: 0.6373\n",
      "Epoch 476/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 140ms/step - accuracy: 0.9952 - loss: 0.0165 - val_accuracy: 0.8477 - val_loss: 0.6184\n",
      "Epoch 477/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 140ms/step - accuracy: 0.9973 - loss: 0.0092 - val_accuracy: 0.8572 - val_loss: 0.5606\n",
      "Epoch 478/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 142ms/step - accuracy: 0.9962 - loss: 0.0172 - val_accuracy: 0.7012 - val_loss: 1.3597\n",
      "Epoch 479/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 140ms/step - accuracy: 0.9956 - loss: 0.0161 - val_accuracy: 0.8343 - val_loss: 0.6703\n",
      "Epoch 480/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 141ms/step - accuracy: 0.9957 - loss: 0.0127 - val_accuracy: 0.8200 - val_loss: 0.7369\n",
      "Epoch 481/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 141ms/step - accuracy: 0.9967 - loss: 0.0098 - val_accuracy: 0.8498 - val_loss: 0.6116\n",
      "Epoch 482/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 141ms/step - accuracy: 0.9949 - loss: 0.0196 - val_accuracy: 0.7871 - val_loss: 0.9323\n",
      "Epoch 483/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 141ms/step - accuracy: 0.9966 - loss: 0.0105 - val_accuracy: 0.8697 - val_loss: 0.5341\n",
      "Epoch 484/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 142ms/step - accuracy: 0.9973 - loss: 0.0097 - val_accuracy: 0.8569 - val_loss: 0.6245\n",
      "Epoch 485/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 142ms/step - accuracy: 0.9959 - loss: 0.0122 - val_accuracy: 0.8284 - val_loss: 0.8237\n",
      "Epoch 486/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 142ms/step - accuracy: 0.9950 - loss: 0.0163 - val_accuracy: 0.8519 - val_loss: 0.6057\n",
      "Epoch 487/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 143ms/step - accuracy: 0.9971 - loss: 0.0111 - val_accuracy: 0.7890 - val_loss: 0.9271\n",
      "Epoch 488/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 142ms/step - accuracy: 0.9959 - loss: 0.0154 - val_accuracy: 0.8378 - val_loss: 0.6878\n",
      "Epoch 489/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 141ms/step - accuracy: 0.9963 - loss: 0.0117 - val_accuracy: 0.8391 - val_loss: 0.7196\n",
      "Epoch 490/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 142ms/step - accuracy: 0.9950 - loss: 0.0133 - val_accuracy: 0.8538 - val_loss: 0.5882\n",
      "Epoch 491/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 143ms/step - accuracy: 0.9957 - loss: 0.0126 - val_accuracy: 0.8374 - val_loss: 0.6466\n",
      "Epoch 492/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 143ms/step - accuracy: 0.9967 - loss: 0.0105 - val_accuracy: 0.8261 - val_loss: 0.7652\n",
      "Epoch 493/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 144ms/step - accuracy: 0.9972 - loss: 0.0095 - val_accuracy: 0.8364 - val_loss: 0.6819\n",
      "Epoch 494/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 143ms/step - accuracy: 0.9963 - loss: 0.0144 - val_accuracy: 0.8745 - val_loss: 0.4975\n",
      "Epoch 495/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 144ms/step - accuracy: 0.9954 - loss: 0.0151 - val_accuracy: 0.8514 - val_loss: 0.5804\n",
      "Epoch 496/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 144ms/step - accuracy: 0.9959 - loss: 0.0170 - val_accuracy: 0.8768 - val_loss: 0.4640\n",
      "Epoch 497/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 143ms/step - accuracy: 0.9965 - loss: 0.0142 - val_accuracy: 0.8524 - val_loss: 0.5788\n",
      "Epoch 498/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 144ms/step - accuracy: 0.9967 - loss: 0.0110 - val_accuracy: 0.8348 - val_loss: 0.6854\n",
      "Epoch 499/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 144ms/step - accuracy: 0.9964 - loss: 0.0126 - val_accuracy: 0.8289 - val_loss: 0.6516\n",
      "Epoch 500/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 145ms/step - accuracy: 0.9964 - loss: 0.0119 - val_accuracy: 0.8582 - val_loss: 0.5686\n",
      "Epoch 501/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 145ms/step - accuracy: 0.9957 - loss: 0.0156 - val_accuracy: 0.8458 - val_loss: 0.6601\n",
      "Epoch 502/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 145ms/step - accuracy: 0.9952 - loss: 0.0166 - val_accuracy: 0.8631 - val_loss: 0.5601\n",
      "Epoch 503/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 145ms/step - accuracy: 0.9954 - loss: 0.0132 - val_accuracy: 0.8706 - val_loss: 0.5400\n",
      "Epoch 504/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 145ms/step - accuracy: 0.9965 - loss: 0.0115 - val_accuracy: 0.8081 - val_loss: 0.8750\n",
      "Epoch 505/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 147ms/step - accuracy: 0.9965 - loss: 0.0128 - val_accuracy: 0.8450 - val_loss: 0.6523\n",
      "Epoch 506/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 146ms/step - accuracy: 0.9964 - loss: 0.0125 - val_accuracy: 0.6345 - val_loss: 1.7739\n",
      "Epoch 507/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 146ms/step - accuracy: 0.9966 - loss: 0.0083 - val_accuracy: 0.8688 - val_loss: 0.5703\n",
      "Epoch 508/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 147ms/step - accuracy: 0.9959 - loss: 0.0145 - val_accuracy: 0.7944 - val_loss: 0.9247\n",
      "Epoch 509/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 147ms/step - accuracy: 0.9954 - loss: 0.0179 - val_accuracy: 0.8277 - val_loss: 0.7113\n",
      "Epoch 510/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 147ms/step - accuracy: 0.9961 - loss: 0.0127 - val_accuracy: 0.8742 - val_loss: 0.4957\n",
      "Epoch 511/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 147ms/step - accuracy: 0.9960 - loss: 0.0124 - val_accuracy: 0.8455 - val_loss: 0.6263\n",
      "Epoch 512/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 148ms/step - accuracy: 0.9961 - loss: 0.0132 - val_accuracy: 0.7951 - val_loss: 0.8903\n",
      "Epoch 513/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 148ms/step - accuracy: 0.9958 - loss: 0.0144 - val_accuracy: 0.8508 - val_loss: 0.5532\n",
      "Epoch 514/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 148ms/step - accuracy: 0.9958 - loss: 0.0138 - val_accuracy: 0.8432 - val_loss: 0.6121\n",
      "Epoch 515/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 149ms/step - accuracy: 0.9976 - loss: 0.0080 - val_accuracy: 0.8048 - val_loss: 0.8343\n",
      "Epoch 516/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 148ms/step - accuracy: 0.9962 - loss: 0.0147 - val_accuracy: 0.8569 - val_loss: 0.5647\n",
      "Epoch 517/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 149ms/step - accuracy: 0.9950 - loss: 0.0182 - val_accuracy: 0.8269 - val_loss: 0.6271\n",
      "Epoch 518/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 149ms/step - accuracy: 0.9961 - loss: 0.0146 - val_accuracy: 0.8534 - val_loss: 0.5662\n",
      "Epoch 519/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 150ms/step - accuracy: 0.9964 - loss: 0.0127 - val_accuracy: 0.8437 - val_loss: 0.6458\n",
      "Epoch 520/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 148ms/step - accuracy: 0.9964 - loss: 0.0117 - val_accuracy: 0.8544 - val_loss: 0.5881\n",
      "Epoch 521/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 151ms/step - accuracy: 0.9963 - loss: 0.0125 - val_accuracy: 0.8620 - val_loss: 0.5808\n",
      "Epoch 522/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 149ms/step - accuracy: 0.9972 - loss: 0.0092 - val_accuracy: 0.8627 - val_loss: 0.5507\n",
      "Epoch 523/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 150ms/step - accuracy: 0.9970 - loss: 0.0095 - val_accuracy: 0.8331 - val_loss: 0.7512\n",
      "Epoch 524/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 149ms/step - accuracy: 0.9957 - loss: 0.0155 - val_accuracy: 0.8262 - val_loss: 0.7944\n",
      "Epoch 525/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 150ms/step - accuracy: 0.9964 - loss: 0.0140 - val_accuracy: 0.8425 - val_loss: 0.6815\n",
      "Epoch 526/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 151ms/step - accuracy: 0.9959 - loss: 0.0134 - val_accuracy: 0.8310 - val_loss: 0.7282\n",
      "Epoch 527/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 150ms/step - accuracy: 0.9942 - loss: 0.0144 - val_accuracy: 0.8371 - val_loss: 0.6874\n",
      "Epoch 528/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 152ms/step - accuracy: 0.9953 - loss: 0.0154 - val_accuracy: 0.8615 - val_loss: 0.5908\n",
      "Epoch 529/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 152ms/step - accuracy: 0.9954 - loss: 0.0150 - val_accuracy: 0.8567 - val_loss: 0.6150\n",
      "Epoch 530/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 152ms/step - accuracy: 0.9960 - loss: 0.0123 - val_accuracy: 0.8752 - val_loss: 0.4858\n",
      "Epoch 531/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 152ms/step - accuracy: 0.9960 - loss: 0.0133 - val_accuracy: 0.8506 - val_loss: 0.6190\n",
      "Epoch 532/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 152ms/step - accuracy: 0.9963 - loss: 0.0130 - val_accuracy: 0.8597 - val_loss: 0.5693\n",
      "Epoch 533/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 153ms/step - accuracy: 0.9977 - loss: 0.0074 - val_accuracy: 0.8157 - val_loss: 0.8046\n",
      "Epoch 534/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 153ms/step - accuracy: 0.9956 - loss: 0.0125 - val_accuracy: 0.7753 - val_loss: 0.9566\n",
      "Epoch 535/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 153ms/step - accuracy: 0.9956 - loss: 0.0132 - val_accuracy: 0.8651 - val_loss: 0.5229\n",
      "Epoch 536/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 153ms/step - accuracy: 0.9968 - loss: 0.0106 - val_accuracy: 0.8171 - val_loss: 0.6936\n",
      "Epoch 537/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 153ms/step - accuracy: 0.9967 - loss: 0.0095 - val_accuracy: 0.8641 - val_loss: 0.4923\n",
      "Epoch 538/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 153ms/step - accuracy: 0.9965 - loss: 0.0119 - val_accuracy: 0.8671 - val_loss: 0.4918\n",
      "Epoch 539/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 153ms/step - accuracy: 0.9975 - loss: 0.0092 - val_accuracy: 0.7434 - val_loss: 1.1729\n",
      "Epoch 540/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 154ms/step - accuracy: 0.9956 - loss: 0.0140 - val_accuracy: 0.8554 - val_loss: 0.6175\n",
      "Epoch 541/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 154ms/step - accuracy: 0.9950 - loss: 0.0157 - val_accuracy: 0.8638 - val_loss: 0.5202\n",
      "Epoch 542/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 154ms/step - accuracy: 0.9969 - loss: 0.0108 - val_accuracy: 0.8633 - val_loss: 0.5268\n",
      "Epoch 543/1000\n",
      "\u001b[1m738/738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 154ms/step - accuracy: 0.9955 - loss: 0.0149 - val_accuracy: 0.8557 - val_loss: 0.5393\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnnhistory = model.fit(x_traincnn, y_train, batch_size=32, epochs=1000, validation_data=(x_testcnn, y_test), callbacks=[early_stopping]) #test 22062024 - 2 #incorporado el \"earlystopping\" para que pare cuando varia poquito.\n",
    "#cnnhistory = model.fit(x_traincnn, y_train, batch_size=32, epochs=500, validation_data=(x_testcnn, y_test))\n",
    "\n",
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at c:\\Users\\diego\\Desktop\\testnotebook\\proyecto3\\Proyecto-3\\saved_models\\Emotion_Voice_Detection_Model_test2.h5 \n"
     ]
    }
   ],
   "source": [
    "#Se guarda el modelo y valores entrenados en el archivo \"Emotion_Voice_Detection_Model.h5\":\n",
    "model_name = 'Emotion_Voice_Detection_Model_test2.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se guarda la arquitectura del modelo en el archivo \"model.json\":\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se carga el modelo obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "compile_metrics: 88.06%\n"
     ]
    }
   ],
   "source": [
    "# Se carga y crea el modelo desde el archivo \"model.json\":\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# Se cargan las métricas en el modelo:\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Voice_Detection_Model_test2.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso de predicción de emociones mediante los datos de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step\n"
     ]
    }
   ],
   "source": [
    "#Se realizan predicciones sobre el conjunto de datos:\n",
    "preds = loaded_model.predict(x_testcnn, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.45713441e-09, 1.75595487e-12, 1.57116486e-10, ...,\n",
       "        5.08547612e-15, 5.24297741e-14, 6.12721392e-23],\n",
       "       [1.23486048e-08, 9.99999762e-01, 9.83372317e-08, ...,\n",
       "        2.12440319e-14, 1.10737569e-12, 8.17510122e-15],\n",
       "       [1.70513928e-01, 1.41280606e-01, 1.22186458e-02, ...,\n",
       "        2.32437196e-06, 8.88168051e-06, 7.50015261e-06],\n",
       "       ...,\n",
       "       [3.46941226e-10, 1.23906345e-11, 2.56455365e-07, ...,\n",
       "        1.42401698e-11, 7.87096191e-13, 1.51287592e-13],\n",
       "       [1.09859123e-07, 1.17244312e-08, 9.99997973e-01, ...,\n",
       "        1.69504397e-10, 7.24047124e-12, 6.15011988e-14],\n",
       "       [7.16754175e-06, 5.69373915e-05, 4.47961327e-04, ...,\n",
       "        1.32686990e-08, 2.57540160e-05, 8.91873424e-05]], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se determina la clase con la mayor probabilidad para cada muestra:\n",
    "preds1=preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 3, ..., 6, 2, 9], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se asegura que todos los elementos de \"preds1\" sean de tipo entero y se reconvierte en un arreglo unidimensional:\n",
    "abc = preds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se reconvierten los índices de clases predichos \"abc\" a las etiquetas originales:\n",
    "predictions = (lb.inverse_transform((abc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>female_neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    predictedvalues\n",
       "0        female_sad\n",
       "1    female_disgust\n",
       "2      female_happy\n",
       "3      male_neutral\n",
       "4        female_sad\n",
       "..              ...\n",
       "822        male_sad\n",
       "823  female_fearful\n",
       "824    female_happy\n",
       "825    male_fearful\n",
       "826  female_neutral\n",
       "\n",
       "[827 rows x 1 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se crea un DataFrame con las predicciones del modelo:\n",
    "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
    "preddf[:827]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se toman las etiquetas reales del conjunto de datos de prueba, se convierten en sus valores originales y se almacenan:\n",
    "actual=y_test.argmax(axis=1)\n",
    "abc123 = actual.astype(int).flatten()\n",
    "actualvalues = (lb.inverse_transform((abc123)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>female_neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       actualvalues\n",
       "0        female_sad\n",
       "1    female_disgust\n",
       "2      female_happy\n",
       "3          male_sad\n",
       "4        female_sad\n",
       "..              ...\n",
       "822        male_sad\n",
       "823  female_fearful\n",
       "824    female_happy\n",
       "825    male_fearful\n",
       "826  female_neutral\n",
       "\n",
       "[827 rows x 1 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se crea un DataFrame que contiene las etiquetas reales del conjunto de datos de test:\n",
    "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
    "actualdf[:827]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se combinan los dos dataframes:\n",
    "finaldf = actualdf.join(preddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparativa de los valores Actual vs Predictivo de las emociones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_sad</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_disgust</td>\n",
       "      <td>female_disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female_happy</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_sad</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_sad</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>male_sad</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>female_fearful</td>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>female_happy</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>male_fearful</td>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>female_neutral</td>\n",
       "      <td>female_neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       actualvalues predictedvalues\n",
       "0        female_sad      female_sad\n",
       "1    female_disgust  female_disgust\n",
       "2      female_happy    female_happy\n",
       "3          male_sad    male_neutral\n",
       "4        female_sad      female_sad\n",
       "..              ...             ...\n",
       "822        male_sad        male_sad\n",
       "823  female_fearful  female_fearful\n",
       "824    female_happy    female_happy\n",
       "825    male_fearful    male_fearful\n",
       "826  female_neutral  female_neutral\n",
       "\n",
       "[827 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf[:827]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actualvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female_angry</th>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_disgust</th>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_fearful</th>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_happy</th>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_neutral</th>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_sad</th>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_surprised</th>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_angry</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_disgust</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_fearful</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_happy</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_neutral</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_sad</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_surprised</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  predictedvalues\n",
       "actualvalues                     \n",
       "female_angry                  722\n",
       "female_disgust                717\n",
       "female_fearful                680\n",
       "female_happy                  715\n",
       "female_neutral                788\n",
       "female_sad                    727\n",
       "female_surprised              703\n",
       "male_angry                    154\n",
       "male_disgust                  137\n",
       "male_fearful                  124\n",
       "male_happy                    139\n",
       "male_neutral                  203\n",
       "male_sad                      113\n",
       "male_surprised                143"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se agrupa y muestra cuántas veces aparece cada valor único real:\n",
    "finaldf.groupby('actualvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictedvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female_angry</th>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_disgust</th>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_fearful</th>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_happy</th>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_neutral</th>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_sad</th>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_surprised</th>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_angry</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_disgust</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_fearful</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_happy</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_neutral</th>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_sad</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_surprised</th>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  actualvalues\n",
       "predictedvalues               \n",
       "female_angry               696\n",
       "female_disgust             682\n",
       "female_fearful             700\n",
       "female_happy               737\n",
       "female_neutral             842\n",
       "female_sad                 755\n",
       "female_surprised           689\n",
       "male_angry                 130\n",
       "male_disgust               139\n",
       "male_fearful               119\n",
       "male_happy                 120\n",
       "male_neutral               235\n",
       "male_sad                    70\n",
       "male_surprised             151"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se agrupa y muestra cuántas veces aparece cada valor único predicho:\n",
    "finaldf.groupby('predictedvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se guarda el dataframe comparativo en el archivo \"predictions.csv\":\n",
    "finaldf.to_csv('Predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
